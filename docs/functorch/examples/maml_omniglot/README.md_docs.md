# Documentation: README.md

## File Metadata
- **Path**: `functorch/examples/maml_omniglot/README.md`
- **Size**: 832 bytes
- **Lines**: 11
- **Extension**: .md
- **Type**: Regular file

## Original Source

```md
# Omniglot MAML examples

In this directory we've provided some examples of training omniglot that reproduce the experiments from [the original MAML paper](https://arxiv.org/abs/1703.03400).

They can be run via `python {filename}`.

`maml-omniglot-higher.py` uses the [facebookresearch/higher](https://github.com/facebookresearch/higher) metalearning package and is the reference implementation. It runs all of its tasks sequentially.

`maml-omniglot-transforms.py` uses functorch. It runs all of its tasks in parallel. In theory this should lead to some speedups, but we haven't finished implementing all the rules for vmap that would actually make training faster.

`maml-omniglot-ptonly.py` is an implementation of `maml-omniglot-transforms.py` that runs all of its tasks sequentially (and also doesn't use the higher package).

```

## High-Level Overview

This file is part of the PyTorch repository. It is a documentation file written in Markdown or reStructuredText.

## Detailed Walkthrough


## Key Components

The file contains 103 words across 11 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 832 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
