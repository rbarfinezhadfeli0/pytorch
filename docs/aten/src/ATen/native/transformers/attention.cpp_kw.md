# Keywords: attention.cpp

## Keyword Index

### A

- **API**: Identifier found in `attention.cpp`
- **AT_PER_OPERATOR_HEADERS**: Identifier found in `attention.cpp`
- **ATen**: Identifier found in `attention.cpp`
- **Accept**: Identifier found in `attention.cpp`
- **AccumulateType**: Identifier found in `attention.cpp`
- **Args**: Identifier found in `attention.cpp`
- **Attention**: Identifier found in `attention.cpp`
- **a_0213**: Identifier found in `attention.cpp`
- **about**: Identifier found in `attention.cpp`
- **accumulate_dtype**: Identifier found in `attention.cpp`
- **accuracy**: Identifier found in `attention.cpp`
- **add_**: Identifier found in `attention.cpp`
- **added**: Identifier found in `attention.cpp`
- **additive**: Identifier found in `attention.cpp`
- **after**: Identifier found in `attention.cpp`
- **alias**: Identifier found in `attention.cpp`
- **aligned_tensor**: Identifier found in `attention.cpp`
- **alignment**: Identifier found in `attention.cpp`
- **alignment_size**: Identifier found in `attention.cpp`
- **all_contiguous**: Identifier found in `attention.cpp`
- **all_equal**: Identifier found in `attention.cpp`
- **allow**: Identifier found in `attention.cpp`
- **allowFP16BF16ReductionMathSDP**: Identifier found in `attention.cpp`
- **allowing**: Identifier found in `attention.cpp`
- **alternate**: Identifier found in `attention.cpp`
- **always**: Identifier found in `attention.cpp`
- **any_inputs_require_grad**: Identifier found in `attention.cpp`
- **any_nested**: Identifier found in `attention.cpp`
- **applied**: Identifier found in `attention.cpp`
- **apply**: Identifier found in `attention.cpp`
- **applying**: Identifier found in `attention.cpp`
- **areAnyTensorSubclassLike**: Identifier found in `attention.cpp`
- **array**: Identifier found in `attention.cpp`
- **assume**: Identifier found in `attention.cpp`
- **assumes**: Identifier found in `attention.cpp`
- **attention**: Identifier found in `attention.cpp`
- **attn**: Identifier found in `attention.cpp`
- **attn_bias**: Identifier found in `attention.cpp`
- **attn_ctx**: Identifier found in `attention.cpp`
- **attn_mask**: Identifier found in `attention.cpp`
- **attn_mask_**: Identifier found in `attention.cpp`
- **attn_scores**: Identifier found in `attention.cpp`
- **auto**: Identifier found in `attention.cpp`
- **autograd**: Identifier found in `attention.cpp`
- **automatically**: Identifier found in `attention.cpp`
- **average_attn_weights**: Identifier found in `attention.cpp`
- **avoid**: Identifier found in `attention.cpp`

### B

- **BF16**: Identifier found in `attention.cpp`
- **Batch**: Identifier found in `attention.cpp`
- **backend**: Identifier found in `attention.cpp`
- **backends**: Identifier found in `attention.cpp`
- **backward**: Identifier found in `attention.cpp`
- **based**: Identifier found in `attention.cpp`
- **batch**: Identifier found in `attention.cpp`
- **batchSize**: Identifier found in `attention.cpp`
- **because**: Identifier found in `attention.cpp`
- **before**: Identifier found in `attention.cpp`
- **bias**: Identifier found in `attention.cpp`
- **block**: Identifier found in `attention.cpp`
- **bmm_nn**: Identifier found in `attention.cpp`
- **bmm_nt**: Identifier found in `attention.cpp`
- **bmm_out**: Identifier found in `attention.cpp`
- **bool**: Identifier found in `attention.cpp`
- **boolean**: Identifier found in `attention.cpp`
- **borrowed**: Identifier found in `attention.cpp`
- **both**: Identifier found in `attention.cpp`
- **broadcastable**: Identifier found in `attention.cpp`
- **buffer**: Identifier found in `attention.cpp`

### C

- **C10_LOG_API_USAGE_ONCE**: Identifier found in `attention.cpp`
- **CPU**: Identifier found in `attention.cpp`
- **CUDA**: Identifier found in `attention.cpp`
- **Computes**: Identifier found in `attention.cpp`
- **Consider**: Identifier found in `attention.cpp`
- **Convert**: Identifier found in `attention.cpp`
- **Currently**: Identifier found in `attention.cpp`
- **caffe2**: Identifier found in `attention.cpp`
- **calculate**: Identifier found in `attention.cpp`
- **calculate_scale**: Identifier found in `attention.cpp`
- **called**: Identifier found in `attention.cpp`
- **cannot**: Identifier found in `attention.cpp`
- **case**: Identifier found in `attention.cpp`
- **cases**: Identifier found in `attention.cpp`
- **causal**: Identifier found in `attention.cpp`
- **causes**: Identifier found in `attention.cpp`
- **cerr**: Identifier found in `attention.cpp`
- **choice_int**: Identifier found in `attention.cpp`
- **chunk**: Identifier found in `attention.cpp`
- **chunk_native**: Identifier found in `attention.cpp`
- **compare**: Identifier found in `attention.cpp`
- **compilation**: Identifier found in `attention.cpp`
- **composite**: Identifier found in `attention.cpp`
- **compute**: Identifier found in `attention.cpp`
- **compute_logsumexp**: Identifier found in `attention.cpp`
- **const**: Identifier found in `attention.cpp`
- **const_data_ptr**: Identifier found in `attention.cpp`
- **constexpr**: Identifier found in `attention.cpp`
- **consumed**: Identifier found in `attention.cpp`
- **contain**: Identifier found in `attention.cpp`
- **contiguous**: Identifier found in `attention.cpp`
- **convert_attn_func**: Identifier found in `attention.cpp`
- **convert_boolean_attn_mask**: Identifier found in `attention.cpp`
- **convert_boolean_attn_mask_**: Identifier found in `attention.cpp`
- **convert_boolean_attn_mask_cudnn**: Identifier found in `attention.cpp`
- **core**: Identifier found in `attention.cpp`
- **correctness**: Identifier found in `attention.cpp`
- **cuDNN**: Identifier found in `attention.cpp`
- **cudnn_attention**: Identifier found in `attention.cpp`
- **cum_seq_k**: Identifier found in `attention.cpp`
- **cum_seq_q**: Identifier found in `attention.cpp`

### D

- **DEBUG_PRINT_EACH_STEP**: Identifier found in `attention.cpp`
- **DEFAULT**: Identifier found in `attention.cpp`
- **DEFINE_DISPATCH**: Identifier found in `attention.cpp`
- **DeviceType**: Identifier found in `attention.cpp`
- **Dispatch**: Identifier found in `attention.cpp`
- **DispatchKey**: Identifier found in `attention.cpp`
- **DispatchKeySet**: Identifier found in `attention.cpp`
- **DispatchStub**: Identifier found in `attention.cpp`
- **Dropout**: Identifier found in `attention.cpp`
- **data**: Identifier found in `attention.cpp`
- **data_ptr**: Identifier found in `attention.cpp`
- **dead**: Identifier found in `attention.cpp`
- **debug_assert_shape**: Identifier found in `attention.cpp`
- **decoder**: Identifier found in `attention.cpp`
- **default**: Identifier found in `attention.cpp`
- **define**: Identifier found in `attention.cpp`
- **defined**: Identifier found in `attention.cpp`
- **delete**: Identifier found in `attention.cpp`
- **device**: Identifier found in `attention.cpp`
- **didn**: Identifier found in `attention.cpp`
- **dim_per_head**: Identifier found in `attention.cpp`
- **dimension**: Identifier found in `attention.cpp`
- **dimensional**: Identifier found in `attention.cpp`
- **dimensions**: Identifier found in `attention.cpp`
- **dims**: Identifier found in `attention.cpp`
- **directly**: Identifier found in `attention.cpp`
- **disable**: Identifier found in `attention.cpp`
- **disabled**: Identifier found in `attention.cpp`
- **divide**: Identifier found in `attention.cpp`
- **divisible**: Identifier found in `attention.cpp`
- **done**: Identifier found in `attention.cpp`
- **double**: Identifier found in `attention.cpp`
- **dropout**: Identifier found in `attention.cpp`
- **dropout_mask**: Identifier found in `attention.cpp`
- **dropout_p**: Identifier found in `attention.cpp`
- **dropout_scaling**: Identifier found in `attention.cpp`
- **dtype**: Identifier found in `attention.cpp`

### E

- **Efficient**: Identifier found in `attention.cpp`
- **Embedding**: Identifier found in `attention.cpp`
- **Expected**: Identifier found in `attention.cpp`
- **Explicit**: Identifier found in `attention.cpp`
- **efficient**: Identifier found in `attention.cpp`
- **efficient_attention**: Identifier found in `attention.cpp`
- **element**: Identifier found in `attention.cpp`
- **elements**: Identifier found in `attention.cpp`
- **else**: Identifier found in `attention.cpp`
- **embed_Dim**: Identifier found in `attention.cpp`
- **embed_dim**: Identifier found in `attention.cpp`
- **empty**: Identifier found in `attention.cpp`
- **empty_like**: Identifier found in `attention.cpp`
- **enable_gqa**: Identifier found in `attention.cpp`
- **encoder**: Identifier found in `attention.cpp`
- **endif**: Identifier found in `attention.cpp`
- **endl**: Identifier found in `attention.cpp`
- **equal**: Identifier found in `attention.cpp`
- **error**: Identifier found in `attention.cpp`
- **evenly**: Identifier found in `attention.cpp`
- **expand_symint**: Identifier found in `attention.cpp`
- **expect_contiguous**: Identifier found in `attention.cpp`
- **expected**: Identifier found in `attention.cpp`
- **explicit**: Identifier found in `attention.cpp`

### F

- **FP16**: Identifier found in `attention.cpp`
- **FP32**: Identifier found in `attention.cpp`
- **FP64**: Identifier found in `attention.cpp`
- **FlashAttentionV2**: Identifier found in `attention.cpp`
- **Functions**: Identifier found in `attention.cpp`
- **Fuse**: Identifier found in `attention.cpp`
- **false**: Identifier found in `attention.cpp`
- **first**: Identifier found in `attention.cpp`
- **fixed**: Identifier found in `attention.cpp`
- **flag**: Identifier found in `attention.cpp`
- **flash_attention**: Identifier found in `attention.cpp`
- **flash_attention_backward_kernel**: Identifier found in `attention.cpp`
- **flash_attention_kernel**: Identifier found in `attention.cpp`
- **float**: Identifier found in `attention.cpp`
- **format**: Identifier found in `attention.cpp`
- **found**: Identifier found in `attention.cpp`
- **free**: Identifier found in `attention.cpp`
- **freed**: Identifier found in `attention.cpp`
- **from**: Identifier found in `attention.cpp`
- **full**: Identifier found in `attention.cpp`
- **function**: Identifier found in `attention.cpp`
- **fused**: Identifier found in `attention.cpp`

### G

- **GQA**: Identifier found in `attention.cpp`
- **GradMode**: Identifier found in `attention.cpp`
- **gemm_nt**: Identifier found in `attention.cpp`
- **get_nested_sizes**: Identifier found in `attention.cpp`
- **get_nested_tensor_impl**: Identifier found in `attention.cpp`
- **github**: Identifier found in `attention.cpp`
- **globalContext**: Identifier found in `attention.cpp`
- **grad_input_mask**: Identifier found in `attention.cpp`
- **grad_k**: Identifier found in `attention.cpp`
- **grad_out**: Identifier found in `attention.cpp`
- **grad_out_t**: Identifier found in `attention.cpp`
- **grad_q**: Identifier found in `attention.cpp`
- **grad_v**: Identifier found in `attention.cpp`
- **gradmode_enabled**: Identifier found in `attention.cpp`
- **greater**: Identifier found in `attention.cpp`
- **guard_float**: Identifier found in `attention.cpp`
- **guards**: Identifier found in `attention.cpp`

### H

- **HIP**: Identifier found in `attention.cpp`
- **HPU**: Identifier found in `attention.cpp`
- **handling**: Identifier found in `attention.cpp`
- **has_cuda**: Identifier found in `attention.cpp`
- **has_hpu**: Identifier found in `attention.cpp`
- **has_rocm**: Identifier found in `attention.cpp`
- **has_value**: Identifier found in `attention.cpp`
- **have**: Identifier found in `attention.cpp`
- **head**: Identifier found in `attention.cpp`
- **head_dimensions**: Identifier found in `attention.cpp`
- **heads**: Identifier found in `attention.cpp`
- **helpful**: Identifier found in `attention.cpp`
- **here**: Identifier found in `attention.cpp`
- **high**: Identifier found in `attention.cpp`
- **however**: Identifier found in `attention.cpp`
- **https**: Identifier found in `attention.cpp`

### I

- **IntArrayRef**: Identifier found in `attention.cpp`
- **if**: Identifier found in `attention.cpp`
- **ifdef**: Identifier found in `attention.cpp`
- **ifndef**: Identifier found in `attention.cpp`
- **implement**: Identifier found in `attention.cpp`
- **implementation**: Identifier found in `attention.cpp`
- **implemented**: Identifier found in `attention.cpp`
- **include**: Identifier found in `attention.cpp`
- **indicate**: Identifier found in `attention.cpp`
- **indicates**: Identifier found in `attention.cpp`
- **infinity**: Identifier found in `attention.cpp`
- **inline**: Identifier found in `attention.cpp`
- **input**: Identifier found in `attention.cpp`
- **inputs**: Identifier found in `attention.cpp`
- **inside**: Identifier found in `attention.cpp`
- **instead**: Identifier found in `attention.cpp`
- **int64_t**: Identifier found in `attention.cpp`
- **invert**: Identifier found in `attention.cpp`
- **irange**: Identifier found in `attention.cpp`
- **isFloatingType**: Identifier found in `attention.cpp`
- **is_causal**: Identifier found in `attention.cpp`
- **is_contiguous**: Identifier found in `attention.cpp`
- **is_contiguous_or_false**: Identifier found in `attention.cpp`
- **is_device_supported**: Identifier found in `attention.cpp`
- **is_enabled**: Identifier found in `attention.cpp`
- **is_macos_13_or_newer**: Identifier found in `attention.cpp`
- **is_negative_scaling**: Identifier found in `attention.cpp`
- **is_nested**: Identifier found in `attention.cpp`
- **is_same**: Identifier found in `attention.cpp`
- **isneginf**: Identifier found in `attention.cpp`
- **issue**: Identifier found in `attention.cpp`
- **issues**: Identifier found in `attention.cpp`

### J

- **just**: Identifier found in `attention.cpp`

### K

- **Keep**: Identifier found in `attention.cpp`
- **kBFloat16**: Identifier found in `attention.cpp`
- **kBool**: Identifier found in `attention.cpp`
- **kCPU**: Identifier found in `attention.cpp`
- **kCUDA**: Identifier found in `attention.cpp`
- **kFloat**: Identifier found in `attention.cpp`
- **kHIP**: Identifier found in `attention.cpp`
- **kHalf**: Identifier found in `attention.cpp`
- **k_bias**: Identifier found in `attention.cpp`
- **k_heads**: Identifier found in `attention.cpp`
- **k_num_heads**: Identifier found in `attention.cpp`
- **kernel**: Identifier found in `attention.cpp`
- **kernel_params**: Identifier found in `attention.cpp`
- **kernels**: Identifier found in `attention.cpp`
- **key_acc**: Identifier found in `attention.cpp`
- **key_divisible**: Identifier found in `attention.cpp`
- **key_expanded**: Identifier found in `attention.cpp`
- **key_padded**: Identifier found in `attention.cpp`
- **key_repeated**: Identifier found in `attention.cpp`
- **key_set**: Identifier found in `attention.cpp`

### L

- **Logging**: Identifier found in `attention.cpp`
- **last**: Identifier found in `attention.cpp`
- **last_dim_size**: Identifier found in `attention.cpp`
- **leaner**: Identifier found in `attention.cpp`
- **least**: Identifier found in `attention.cpp`
- **legend**: Identifier found in `attention.cpp`
- **length**: Identifier found in `attention.cpp`
- **level**: Identifier found in `attention.cpp`
- **likely**: Identifier found in `attention.cpp`
- **limits**: Identifier found in `attention.cpp`
- **line**: Identifier found in `attention.cpp`
- **linear**: Identifier found in `attention.cpp`
- **linear_native**: Identifier found in `attention.cpp`
- **local**: Identifier found in `attention.cpp`
- **logical_not**: Identifier found in `attention.cpp`
- **logsumexp**: Identifier found in `attention.cpp`
- **long**: Identifier found in `attention.cpp`
- **lower**: Identifier found in `attention.cpp`
- **lse_t**: Identifier found in `attention.cpp`

### M

- **MACOS_VER_15_0_PLUS**: Identifier found in `attention.cpp`
- **MPS**: Identifier found in `attention.cpp`
- **MPSDevice**: Identifier found in `attention.cpp`
- **MQA**: Identifier found in `attention.cpp`
- **MacOSVersion**: Identifier found in `attention.cpp`
- **MaybeOwned**: Identifier found in `attention.cpp`
- **Memory**: Identifier found in `attention.cpp`
- **make**: Identifier found in `attention.cpp`
- **make_tuple**: Identifier found in `attention.cpp`
- **mask**: Identifier found in `attention.cpp`
- **mask_dtype**: Identifier found in `attention.cpp`
- **mask_type**: Identifier found in `attention.cpp`
- **masked**: Identifier found in `attention.cpp`
- **masked_fill**: Identifier found in `attention.cpp`
- **masked_rows**: Identifier found in `attention.cpp`
- **masked_softmax**: Identifier found in `attention.cpp`
- **masking**: Identifier found in `attention.cpp`
- **masks**: Identifier found in `attention.cpp`
- **match**: Identifier found in `attention.cpp`
- **math**: Identifier found in `attention.cpp`
- **math_fallback**: Identifier found in `attention.cpp`
- **matmul**: Identifier found in `attention.cpp`
- **matmul_native**: Identifier found in `attention.cpp`
- **max_k**: Identifier found in `attention.cpp`
- **max_q**: Identifier found in `attention.cpp`
- **maybe**: Identifier found in `attention.cpp`
- **maybe_as_int**: Identifier found in `attention.cpp`
- **mem_eff_alignment**: Identifier found in `attention.cpp`
- **memory**: Identifier found in `attention.cpp`
- **more**: Identifier found in `attention.cpp`
- **move**: Identifier found in `attention.cpp`
- **much**: Identifier found in `attention.cpp`
- **multiple**: Identifier found in `attention.cpp`
- **must**: Identifier found in `attention.cpp`

### N

- **NDEBUG**: Identifier found in `attention.cpp`
- **N_heads**: Identifier found in `attention.cpp`
- **Naive**: Identifier found in `attention.cpp`
- **NativeFunctions**: Identifier found in `attention.cpp`
- **Nested**: Identifier found in `attention.cpp`
- **NestedTensor**: Identifier found in `attention.cpp`
- **NestedTensorImpl**: Identifier found in `attention.cpp`
- **NestedTensorTransformerFunctions**: Identifier found in `attention.cpp`
- **NestedTensor_matmul**: Identifier found in `attention.cpp`
- **NestedTensor_times_Tensor_plus_Tensor_addmm**: Identifier found in `attention.cpp`
- **Number**: Identifier found in `attention.cpp`
- **namespace**: Identifier found in `attention.cpp`
- **native**: Identifier found in `attention.cpp`
- **native_multi_head_attention_cpu**: Identifier found in `attention.cpp`
- **need**: Identifier found in `attention.cpp`
- **need_attn_weights**: Identifier found in `attention.cpp`
- **need_weights**: Identifier found in `attention.cpp`
- **needed**: Identifier found in `attention.cpp`
- **neg_inf**: Identifier found in `attention.cpp`
- **nested**: Identifier found in `attention.cpp`
- **nested_a**: Identifier found in `attention.cpp`
- **newAShape**: Identifier found in `attention.cpp`
- **newBShape**: Identifier found in `attention.cpp`
- **nullopt**: Identifier found in `attention.cpp`
- **num_head**: Identifier found in `attention.cpp`
- **num_heads**: Identifier found in `attention.cpp`
- **number**: Identifier found in `attention.cpp`
- **numel**: Identifier found in `attention.cpp`
- **numeric_limits**: Identifier found in `attention.cpp`

### O

- **Only**: Identifier found in `attention.cpp`
- **OpMathType**: Identifier found in `attention.cpp`
- **Otherwise**: Identifier found in `attention.cpp`
- **og_scale**: Identifier found in `attention.cpp`
- **og_size**: Identifier found in `attention.cpp`
- **ones**: Identifier found in `attention.cpp`
- **ones_symint**: Identifier found in `attention.cpp`
- **only**: Identifier found in `attention.cpp`
- **operator**: Identifier found in `attention.cpp`
- **optional**: Identifier found in `attention.cpp`
- **options**: Identifier found in `attention.cpp`
- **order**: Identifier found in `attention.cpp`
- **origin_dtype**: Identifier found in `attention.cpp`
- **original**: Identifier found in `attention.cpp`
- **other**: Identifier found in `attention.cpp`
- **otherwise**: Identifier found in `attention.cpp`
- **out_**: Identifier found in `attention.cpp`
- **out_and_lse**: Identifier found in `attention.cpp`
- **out_lse_softmax**: Identifier found in `attention.cpp`
- **output**: Identifier found in `attention.cpp`
- **override**: Identifier found in `attention.cpp`
- **overrideable**: Identifier found in `attention.cpp`
- **owned**: Identifier found in `attention.cpp`

### P

- **Pass**: Identifier found in `attention.cpp`
- **Probably**: Identifier found in `attention.cpp`
- **packed**: Identifier found in `attention.cpp`
- **pad_bias**: Identifier found in `attention.cpp`
- **pad_count**: Identifier found in `attention.cpp`
- **pad_last_dim**: Identifier found in `attention.cpp`
- **pad_symint**: Identifier found in `attention.cpp`
- **padded**: Identifier found in `attention.cpp`
- **padded_bias**: Identifier found in `attention.cpp`
- **padding**: Identifier found in `attention.cpp`
- **pads**: Identifier found in `attention.cpp`
- **part**: Identifier found in `attention.cpp`
- **passed**: Identifier found in `attention.cpp`
- **performance**: Identifier found in `attention.cpp`
- **permute**: Identifier found in `attention.cpp`
- **philox_offset**: Identifier found in `attention.cpp`
- **philox_seed**: Identifier found in `attention.cpp`
- **please**: Identifier found in `attention.cpp`
- **possible**: Identifier found in `attention.cpp`
- **post_process_flash_output**: Identifier found in `attention.cpp`
- **pre_process_group_query_attention_input**: Identifier found in `attention.cpp`
- **precision**: Identifier found in `attention.cpp`
- **preprocess_mask**: Identifier found in `attention.cpp`
- **previously**: Identifier found in `attention.cpp`
- **privateuse1**: Identifier found in `attention.cpp`
- **probability**: Identifier found in `attention.cpp`
- **produce**: Identifier found in `attention.cpp`
- **produced**: Identifier found in `attention.cpp`
- **product**: Identifier found in `attention.cpp`
- **proj**: Identifier found in `attention.cpp`
- **proj_bias**: Identifier found in `attention.cpp`
- **proj_weight**: Identifier found in `attention.cpp`
- **promoting**: Identifier found in `attention.cpp`
- **public**: Identifier found in `attention.cpp`
- **purposes**: Identifier found in `attention.cpp`
- **pytorch**: Identifier found in `attention.cpp`

### Q

- **Query**: Identifier found in `attention.cpp`
- **qSize**: Identifier found in `attention.cpp`
- **q_bias**: Identifier found in `attention.cpp`
- **q_heads**: Identifier found in `attention.cpp`
- **q_k_v**: Identifier found in `attention.cpp`
- **q_k_v_s**: Identifier found in `attention.cpp`
- **q_k_v_weight_s**: Identifier found in `attention.cpp`
- **q_kv_weight_s**: Identifier found in `attention.cpp`
- **q_num_heads**: Identifier found in `attention.cpp`
- **qkv_**: Identifier found in `attention.cpp`
- **qkv_bias**: Identifier found in `attention.cpp`
- **qkv_bias_contig**: Identifier found in `attention.cpp`
- **qkv_contig**: Identifier found in `attention.cpp`
- **qkv_projection**: Identifier found in `attention.cpp`
- **qkv_weight**: Identifier found in `attention.cpp`
- **query**: Identifier found in `attention.cpp`
- **query_**: Identifier found in `attention.cpp`
- **query_acc**: Identifier found in `attention.cpp`
- **query_device_type**: Identifier found in `attention.cpp`
- **query_key_set**: Identifier found in `attention.cpp`
- **query_padded**: Identifier found in `attention.cpp`

### R

- **REGISTER_ARCH_DISPATCH**: Identifier found in `attention.cpp`
- **REGISTER_AVX2_DISPATCH**: Identifier found in `attention.cpp`
- **REGISTER_AVX512_DISPATCH**: Identifier found in `attention.cpp`
- **REGISTER_HPU_DISPATCH**: Identifier found in `attention.cpp`
- **REGISTER_SVE256_DISPATCH**: Identifier found in `attention.cpp`
- **REGISTER_VSX_DISPATCH**: Identifier found in `attention.cpp`
- **REGISTER_ZVECTOR_DISPATCH**: Identifier found in `attention.cpp`
- **Remove**: Identifier found in `attention.cpp`
- **Replace**: Identifier found in `attention.cpp`
- **Returns**: Identifier found in `attention.cpp`
- **redispatch**: Identifier found in `attention.cpp`
- **region**: Identifier found in `attention.cpp`
- **removing**: Identifier found in `attention.cpp`
- **repeat_factor**: Identifier found in `attention.cpp`
- **repeat_interleave**: Identifier found in `attention.cpp`
- **repeat_interleave_symint**: Identifier found in `attention.cpp`
- **repeat_key_shape**: Identifier found in `attention.cpp`
- **repeat_value_shape**: Identifier found in `attention.cpp`
- **repeated_key**: Identifier found in `attention.cpp`
- **repeated_value**: Identifier found in `attention.cpp`

### S

- **SDPA**: Identifier found in `attention.cpp`
- **SDPBackend**: Identifier found in `attention.cpp`
- **ScalarType**: Identifier found in `attention.cpp`
- **Scale**: Identifier found in `attention.cpp`
- **Scaled_dot_product_attention**: Identifier found in `attention.cpp`
- **Shape**: Identifier found in `attention.cpp`
- **Source**: Identifier found in `attention.cpp`
- **SymFloat**: Identifier found in `attention.cpp`
- **SymInt**: Identifier found in `attention.cpp`
- **SymIntArrayRef**: Identifier found in `attention.cpp`

### T

- **TODO**: Identifier found in `attention.cpp`
- **TORCH_ASSERT_ONLY_METHOD_OPERATORS**: Identifier found in `attention.cpp`
- **TORCH_CHECK**: Identifier found in `attention.cpp`
- **TORCH_CHECK_NOT_IMPLEMENTED**: Identifier found in `attention.cpp`
- **TORCH_INTERNAL_ASSERT_DEBUG_ONLY**: Identifier found in `attention.cpp`
- **TORCH_LIBRARY_IMPL**: Identifier found in `attention.cpp`
- **TORCH_WARN_ONCE**: Identifier found in `attention.cpp`
- **Target**: Identifier found in `attention.cpp`
- **Tensor**: Identifier found in `attention.cpp`
- **TensorBody**: Identifier found in `attention.cpp`
- **TensorIndexing**: Identifier found in `attention.cpp`
- **TensorOperators**: Identifier found in `attention.cpp`
- **TensorOptions**: Identifier found in `attention.cpp`
- **TensorSubclassLikeUtils**: Identifier found in `attention.cpp`
- **Then**: Identifier found in `attention.cpp`
- **This**: Identifier found in `attention.cpp`
- **Triton**: Identifier found in `attention.cpp`
- **True**: Identifier found in `attention.cpp`
- **TypeMeta**: Identifier found in `attention.cpp`

### U

- **USE_MPS**: Identifier found in `attention.cpp`
- **USE_ROCM**: Identifier found in `attention.cpp`

### V

- **Value**: Identifier found in `attention.cpp`

### _

- **_fused_sdp_choice_cpp**: Identifier found in `attention.cpp`
- **_fused_sdp_choice_meta**: Identifier found in `attention.cpp`
- **_safe_softmax**: Identifier found in `attention.cpp`
- **_scaled_dot_product_attention_math**: Identifier found in `attention.cpp`
- **_scaled_dot_product_flash_attention_cpu**: Identifier found in `attention.cpp`
- **_scaled_dot_product_flash_attention_cpu_backward**: Identifier found in `attention.cpp`
- **_scaled_dot_product_fused_attention_overrideable**: Identifier found in `attention.cpp`
- **_scaled_dot_product_fused_attention_overrideable_backward**: Identifier found in `attention.cpp`

