# Documentation: aten/src/ATen/native/transformers/cuda/mem_eff_attention/kernels

## Purpose

This directory contains 50 file(s) and 0 subdirectory(ies).

## Contents

### Files

- `cutlassB.h`
- `cutlassB_bf16_aligned_k128.cu`
- `cutlassB_bf16_aligned_k128_dropout.cu`
- `cutlassB_bf16_aligned_k32.cu`
- `cutlassB_bf16_aligned_k32_dropout.cu`
- `cutlassB_bf16_aligned_k64.cu`
- `cutlassB_bf16_aligned_k64_dropout.cu`
- `cutlassB_bf16_aligned_k65536.cu`
- `cutlassB_bf16_aligned_k65536_dropout.cu`
- `cutlassB_bf16_aligned_k96.cu`
- `cutlassB_f16_aligned_k128.cu`
- `cutlassB_f16_aligned_k128_dropout.cu`
- `cutlassB_f16_aligned_k32.cu`
- `cutlassB_f16_aligned_k32_dropout.cu`
- `cutlassB_f16_aligned_k64.cu`
- `cutlassB_f16_aligned_k64_dropout.cu`
- `cutlassB_f16_aligned_k65536.cu`
- `cutlassB_f16_aligned_k65536_dropout.cu`
- `cutlassB_f16_aligned_k96.cu`
- `cutlassB_f16_notaligned_k128.cu`
- `cutlassB_f16_notaligned_k128_dropout.cu`
- `cutlassB_f16_notaligned_k32.cu`
- `cutlassB_f16_notaligned_k32_dropout.cu`
- `cutlassB_f16_notaligned_k64.cu`
- `cutlassB_f16_notaligned_k64_dropout.cu`
- `cutlassB_f16_notaligned_k65536.cu`
- `cutlassB_f16_notaligned_k65536_dropout.cu`
- `cutlassB_f32_aligned_k128.cu`
- `cutlassB_f32_aligned_k128_dropout.cu`
- `cutlassB_f32_aligned_k32.cu`
- `cutlassB_f32_aligned_k32_dropout.cu`
- `cutlassB_f32_aligned_k64.cu`
- `cutlassB_f32_aligned_k64_dropout.cu`
- `cutlassB_f32_aligned_k65536.cu`
- `cutlassB_f32_aligned_k65536_dropout.cu`
- `cutlassB_f32_notaligned_k128.cu`
- `cutlassB_f32_notaligned_k128_dropout.cu`
- `cutlassB_f32_notaligned_k32.cu`
- `cutlassB_f32_notaligned_k32_dropout.cu`
- `cutlassB_f32_notaligned_k64.cu`
- `cutlassB_f32_notaligned_k64_dropout.cu`
- `cutlassB_f32_notaligned_k65536.cu`
- `cutlassB_f32_notaligned_k65536_dropout.cu`
- `cutlassF.h`
- `cutlassF_bf16_aligned.cu`
- `cutlassF_f16_aligned.cu`
- `cutlassF_f16_notaligned.cu`
- `cutlassF_f32_aligned.cu`
- `cutlassF_f32_notaligned.cu`
- `generate_kernels.py`

---
*Generated by Repo Book Generator v1.0*
