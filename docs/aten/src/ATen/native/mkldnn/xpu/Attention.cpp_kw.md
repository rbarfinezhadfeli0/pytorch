# Keywords: Attention.cpp

## Keyword Index

### A

- **ATen**: Identifier found in `Attention.cpp`
- **Aborting**: Identifier found in `Attention.cpp`
- **Accept**: Identifier found in `Attention.cpp`
- **Array**: Identifier found in `Attention.cpp`
- **Attention**: Identifier found in `Attention.cpp`
- **alloc_with_matching_layout**: Identifier found in `Attention.cpp`
- **any_inputs_require_grad**: Identifier found in `Attention.cpp`
- **array**: Identifier found in `Attention.cpp`
- **array_of**: Identifier found in `Attention.cpp`
- **attention**: Identifier found in `Attention.cpp`
- **attn_bias**: Identifier found in `Attention.cpp`
- **attn_mask_**: Identifier found in `Attention.cpp`
- **auto**: Identifier found in `Attention.cpp`
- **available**: Identifier found in `Attention.cpp`

### B

- **Backward**: Identifier found in `Attention.cpp`
- **Because**: Identifier found in `Attention.cpp`
- **back**: Identifier found in `Attention.cpp`
- **backend**: Identifier found in `Attention.cpp`
- **backends**: Identifier found in `Attention.cpp`
- **batch**: Identifier found in `Attention.cpp`
- **batch_size**: Identifier found in `Attention.cpp`
- **because**: Identifier found in `Attention.cpp`
- **bool**: Identifier found in `Attention.cpp`
- **both**: Identifier found in `Attention.cpp`
- **break**: Identifier found in `Attention.cpp`

### C

- **Context**: Identifier found in `Attention.cpp`
- **CuDNN**: Identifier found in `Attention.cpp`
- **Currently**: Identifier found in `Attention.cpp`
- **can_use_cudnn_attention**: Identifier found in `Attention.cpp`
- **can_use_flash_attention**: Identifier found in `Attention.cpp`
- **can_use_mem_efficien_attention**: Identifier found in `Attention.cpp`
- **can_use_overridable_attention**: Identifier found in `Attention.cpp`
- **can_use_overrideable_attention**: Identifier found in `Attention.cpp`
- **cannot**: Identifier found in `Attention.cpp`
- **case**: Identifier found in `Attention.cpp`
- **check_attn_mask_shape**: Identifier found in `Attention.cpp`
- **check_batch_size_and_num_heads_dense**: Identifier found in `Attention.cpp`
- **check_for_dropout**: Identifier found in `Attention.cpp`
- **check_head_dim_size_xpu**: Identifier found in `Attention.cpp`
- **check_last_dim_stride_equals_1_dense**: Identifier found in `Attention.cpp`
- **check_nested_tensor**: Identifier found in `Attention.cpp`
- **check_no_grad**: Identifier found in `Attention.cpp`
- **check_nonzero_sequence_lengths_dense**: Identifier found in `Attention.cpp`
- **check_tensor_dtype**: Identifier found in `Attention.cpp`
- **check_tensor_shapes**: Identifier found in `Attention.cpp`
- **checks**: Identifier found in `Attention.cpp`
- **condition**: Identifier found in `Attention.cpp`
- **const**: Identifier found in `Attention.cpp`
- **constexpr**: Identifier found in `Attention.cpp`
- **constraint**: Identifier found in `Attention.cpp`
- **constraints**: Identifier found in `Attention.cpp`
- **cudnn**: Identifier found in `Attention.cpp`
- **cudnn_attention**: Identifier found in `Attention.cpp`
- **cum_seq_k**: Identifier found in `Attention.cpp`
- **cum_seq_q**: Identifier found in `Attention.cpp`

### D

- **Define**: Identifier found in `Attention.cpp`
- **debug**: Identifier found in `Attention.cpp`
- **debug_attn_mask**: Identifier found in `Attention.cpp`
- **default**: Identifier found in `Attention.cpp`
- **defines**: Identifier found in `Attention.cpp`
- **detail**: Identifier found in `Attention.cpp`
- **determine**: Identifier found in `Attention.cpp`
- **different**: Identifier found in `Attention.cpp`
- **dimension**: Identifier found in `Attention.cpp`
- **dims**: Identifier found in `Attention.cpp`
- **disabled**: Identifier found in `Attention.cpp`
- **divide**: Identifier found in `Attention.cpp`
- **double**: Identifier found in `Attention.cpp`
- **dropout**: Identifier found in `Attention.cpp`
- **dropout_p**: Identifier found in `Attention.cpp`
- **dtype**: Identifier found in `Attention.cpp`

### E

- **Efficient**: Identifier found in `Attention.cpp`
- **efficient**: Identifier found in `Attention.cpp`
- **efficient_attention**: Identifier found in `Attention.cpp`
- **empty**: Identifier found in `Attention.cpp`
- **enable_gqa**: Identifier found in `Attention.cpp`
- **enabled**: Identifier found in `Attention.cpp`
- **error**: Identifier found in `Attention.cpp`
- **execution**: Identifier found in `Attention.cpp`
- **explicitly**: Identifier found in `Attention.cpp`

### F

- **Flash**: Identifier found in `Attention.cpp`
- **fallback**: Identifier found in `Attention.cpp`
- **fallbacks**: Identifier found in `Attention.cpp`
- **falling**: Identifier found in `Attention.cpp`
- **false**: Identifier found in `Attention.cpp`
- **flash**: Identifier found in `Attention.cpp`
- **flash_attention**: Identifier found in `Attention.cpp`
- **for**: Identifier found in `Attention.cpp`
- **found**: Identifier found in `Attention.cpp`
- **function**: Identifier found in `Attention.cpp`
- **functions**: Identifier found in `Attention.cpp`

### G

- **GQA**: Identifier found in `Attention.cpp`
- **GradMode**: Identifier found in `Attention.cpp`
- **gate**: Identifier found in `Attention.cpp`
- **globalContext**: Identifier found in `Attention.cpp`
- **gotten**: Identifier found in `Attention.cpp`
- **grad**: Identifier found in `Attention.cpp`
- **gradmode_enabled**: Identifier found in `Attention.cpp`

### H

- **happened**: Identifier found in `Attention.cpp`
- **has_value**: Identifier found in `Attention.cpp`
- **have**: Identifier found in `Attention.cpp`
- **head**: Identifier found in `Attention.cpp`
- **head_dim**: Identifier found in `Attention.cpp`
- **head_dim_qk**: Identifier found in `Attention.cpp`
- **head_dim_v**: Identifier found in `Attention.cpp`
- **heads**: Identifier found in `Attention.cpp`

### I

- **Invalid**: Identifier found in `Attention.cpp`
- **ideal**: Identifier found in `Attention.cpp`
- **if**: Identifier found in `Attention.cpp`
- **ignore_singleton_dim**: Identifier found in `Attention.cpp`
- **implementation**: Identifier found in `Attention.cpp`
- **include**: Identifier found in `Attention.cpp`
- **inputs**: Identifier found in `Attention.cpp`
- **instead**: Identifier found in `Attention.cpp`
- **int64_t**: Identifier found in `Attention.cpp`
- **is_causal**: Identifier found in `Attention.cpp`
- **is_enabled**: Identifier found in `Attention.cpp`

### K

- **kBFloat16**: Identifier found in `Attention.cpp`
- **kFloat**: Identifier found in `Attention.cpp`
- **kHalf**: Identifier found in `Attention.cpp`
- **kLong**: Identifier found in `Attention.cpp`
- **kernel**: Identifier found in `Attention.cpp`
- **kernel_params**: Identifier found in `Attention.cpp`
- **kernels**: Identifier found in `Attention.cpp`
- **key_size_last**: Identifier found in `Attention.cpp`

### L

- **last**: Identifier found in `Attention.cpp`
- **less**: Identifier found in `Attention.cpp`
- **library**: Identifier found in `Attention.cpp`
- **likely**: Identifier found in `Attention.cpp`
- **linked**: Identifier found in `Attention.cpp`
- **logsumexp**: Identifier found in `Attention.cpp`

### M

- **MAX_HEAD_DIM**: Identifier found in `Attention.cpp`
- **Math**: Identifier found in `Attention.cpp`
- **Memory**: Identifier found in `Attention.cpp`
- **make_tuple**: Identifier found in `Attention.cpp`
- **math**: Identifier found in `Attention.cpp`
- **max_size_last**: Identifier found in `Attention.cpp`
- **mkldnn**: Identifier found in `Attention.cpp`
- **must**: Identifier found in `Attention.cpp`

### N

- **namespace**: Identifier found in `Attention.cpp`
- **native**: Identifier found in `Attention.cpp`
- **negate**: Identifier found in `Attention.cpp`
- **num_backends**: Identifier found in `Attention.cpp`
- **num_head**: Identifier found in `Attention.cpp`
- **num_head_kv**: Identifier found in `Attention.cpp`
- **num_head_q**: Identifier found in `Attention.cpp`
- **number**: Identifier found in `Attention.cpp`

### O

- **OVERRIDEABLE**: Identifier found in `Attention.cpp`
- **OneDNN**: Identifier found in `Attention.cpp`
- **Overrideable**: Identifier found in `Attention.cpp`
- **oneDNN**: Identifier found in `Attention.cpp`
- **onednn**: Identifier found in `Attention.cpp`
- **only**: Identifier found in `Attention.cpp`
- **optional**: Identifier found in `Attention.cpp`
- **order**: Identifier found in `Attention.cpp`
- **ordering**: Identifier found in `Attention.cpp`
- **output**: Identifier found in `Attention.cpp`
- **output_shape**: Identifier found in `Attention.cpp`
- **overridable**: Identifier found in `Attention.cpp`
- **overrideable**: Identifier found in `Attention.cpp`

### P

- **params**: Identifier found in `Attention.cpp`
- **philox_offset**: Identifier found in `Attention.cpp`
- **philox_seed**: Identifier found in `Attention.cpp`
- **point**: Identifier found in `Attention.cpp`
- **present**: Identifier found in `Attention.cpp`
- **print**: Identifier found in `Attention.cpp`
- **print_debug**: Identifier found in `Attention.cpp`
- **printed**: Identifier found in `Attention.cpp`
- **priority**: Identifier found in `Attention.cpp`
- **priority_order**: Identifier found in `Attention.cpp`
- **priority_order_init**: Identifier found in `Attention.cpp`

### Q

- **Query**: Identifier found in `Attention.cpp`
- **query**: Identifier found in `Attention.cpp`
- **query_**: Identifier found in `Attention.cpp`
- **query_size_last**: Identifier found in `Attention.cpp`

### R

- **REGISTER_XPU_DISPATCH**: Identifier found in `Attention.cpp`
- **reason**: Identifier found in `Attention.cpp`
- **requires**: Identifier found in `Attention.cpp`
- **requires_grad**: Identifier found in `Attention.cpp`
- **return**: Identifier found in `Attention.cpp`
- **return_debug_mask**: Identifier found in `Attention.cpp`

### S

- **SDPA**: Identifier found in `Attention.cpp`
- **SDPBackend**: Identifier found in `Attention.cpp`
- **ScalarType**: Identifier found in `Attention.cpp`
- **SymInt**: Identifier found in `Attention.cpp`
- **sDPPriorityOrder**: Identifier found in `Attention.cpp`
- **same**: Identifier found in `Attention.cpp`
- **satisfy**: Identifier found in `Attention.cpp`
- **scale**: Identifier found in `Attention.cpp`
- **scaled_dot_product_attention**: Identifier found in `Attention.cpp`
- **scaled_dot_product_fused_attention_overrideable_xpu**: Identifier found in `Attention.cpp`
- **sdp_params**: Identifier found in `Attention.cpp`
- **sdp_utils**: Identifier found in `Attention.cpp`
- **sdp_utils_cpp**: Identifier found in `Attention.cpp`
- **sdpa**: Identifier found in `Attention.cpp`
- **select_sdp_backend_xpu**: Identifier found in `Attention.cpp`
- **selected**: Identifier found in `Attention.cpp`
- **seq_len_kv**: Identifier found in `Attention.cpp`
- **seq_len_q**: Identifier found in `Attention.cpp`
- **setSDPPriorityOrder**: Identifier found in `Attention.cpp`
- **shape**: Identifier found in `Attention.cpp`
- **should**: Identifier found in `Attention.cpp`
- **size**: Identifier found in `Attention.cpp`
- **sqrt**: Identifier found in `Attention.cpp`
- **statements**: Identifier found in `Attention.cpp`
- **static_cast**: Identifier found in `Attention.cpp`
- **support**: Identifier found in `Attention.cpp`
- **supported**: Identifier found in `Attention.cpp`
- **supported_dtypes**: Identifier found in `Attention.cpp`
- **supports**: Identifier found in `Attention.cpp`
- **switch**: Identifier found in `Attention.cpp`
- **sym_size**: Identifier found in `Attention.cpp`

### T

- **TORCHCHECK**: Identifier found in `Attention.cpp`
- **TORCH_CHECK**: Identifier found in `Attention.cpp`
- **TORCH_INTERNAL_ASSERT**: Identifier found in `Attention.cpp`
- **TORCH_WARN**: Identifier found in `Attention.cpp`
- **TORCH_WARN_ONCE**: Identifier found in `Attention.cpp`
- **Tensor**: Identifier found in `Attention.cpp`
- **This**: Identifier found in `Attention.cpp`
- **than**: Identifier found in `Attention.cpp`
- **that**: Identifier found in `Attention.cpp`
- **then**: Identifier found in `Attention.cpp`
- **things**: Identifier found in `Attention.cpp`
- **this**: Identifier found in `Attention.cpp`
- **torch**: Identifier found in `Attention.cpp`
- **transformers**: Identifier found in `Attention.cpp`
- **true**: Identifier found in `Attention.cpp`
- **tuple**: Identifier found in `Attention.cpp`
- **turning**: Identifier found in `Attention.cpp`

### U

- **used**: Identifier found in `Attention.cpp`
- **user**: Identifier found in `Attention.cpp`
- **userEnabledCuDNNSDP**: Identifier found in `Attention.cpp`
- **userEnabledFlashSDP**: Identifier found in `Attention.cpp`
- **userEnabledMathSDP**: Identifier found in `Attention.cpp`
- **userEnabledMemEfficientSDP**: Identifier found in `Attention.cpp`
- **userEnabledOverrideableSDP**: Identifier found in `Attention.cpp`
- **util**: Identifier found in `Attention.cpp`

### V

- **value**: Identifier found in `Attention.cpp`
- **value_size_last**: Identifier found in `Attention.cpp`
- **vector**: Identifier found in `Attention.cpp`
- **viable**: Identifier found in `Attention.cpp`

### W

- **when**: Identifier found in `Attention.cpp`
- **will**: Identifier found in `Attention.cpp`
- **with**: Identifier found in `Attention.cpp`

### X

- **XPU**: Identifier found in `Attention.cpp`

### _

- **_fused_sdp_choice_xpu**: Identifier found in `Attention.cpp`
- **_scaled_dot_product_fused_attention_overrideable_xpu**: Identifier found in `Attention.cpp`

