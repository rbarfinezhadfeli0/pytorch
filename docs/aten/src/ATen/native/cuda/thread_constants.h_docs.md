# Documentation: thread_constants.h

## File Metadata
- **Path**: `aten/src/ATen/native/cuda/thread_constants.h`
- **Size**: 660 bytes
- **Lines**: 25
- **Extension**: .h
- **Type**: Regular file

## Original Source

```h
#pragma once
#include <c10/macros/Macros.h>

// Marks a lambda as executable on both the host and device. The __host__
// attribute is important so that we can access static type information from
// the host, even if the function is typically only executed on the device.
#ifndef GPU_LAMBDA
#define GPU_LAMBDA __host__ __device__
#endif

#if defined(USE_ROCM)
constexpr int num_threads() {
  return 256;
}

constexpr int thread_work_size() { return 4; }
#else
constexpr uint32_t num_threads() {
  return C10_WARP_SIZE * 4;
}

constexpr int thread_work_size() { return 8; }
#endif

constexpr int block_work_size() { return thread_work_size() * num_threads(); }

```

## High-Level Overview

This file is part of the PyTorch repository. It is a C++/CUDA source/header file that may contain implementations, declarations, or kernel code.

## Detailed Walkthrough


## Key Components

The file contains 95 words across 25 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 660 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
