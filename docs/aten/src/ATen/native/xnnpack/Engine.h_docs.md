# Documentation: Engine.h

## File Metadata
- **Path**: `aten/src/ATen/native/xnnpack/Engine.h`
- **Size**: 1970 bytes
- **Lines**: 95
- **Extension**: .h
- **Type**: Regular file

## Original Source

```h
#pragma once

#include <ATen/core/Tensor.h>
#include <limits>

namespace at::native::xnnpack {

//
// Convolution
//

bool use_convolution2d(
    const Tensor& input,
    const Tensor& weight,
    const at::OptionalIntArrayRef bias_sizes_opt,
    const IntArrayRef padding,
    const IntArrayRef stride,
    const IntArrayRef dilation,
    const int64_t groups,
    const bool transposed);

Tensor convolution2d(
    const Tensor& input,
    const Tensor& weight,
    const Tensor& bias,
    const IntArrayRef padding,
    const IntArrayRef stride,
    const IntArrayRef dilation,
    const int64_t groups);

//
// Linear
//

bool use_linear(
  const Tensor& input,
  const Tensor& weight,
  const Tensor& bias);

Tensor linear(
  const Tensor& input,
  const Tensor& weight,
  const Tensor& bias);

//
// Max Pooling
//

bool use_max_pool2d(
    const Tensor& input,
    const IntArrayRef kernel,
    const IntArrayRef padding,
    IntArrayRef stride,
    const IntArrayRef dilation,
    const bool ceil_mode,
    const float output_min = -std::numeric_limits<float>::infinity(),
    const float output_max = +std::numeric_limits<float>::infinity());

Tensor max_pool2d(
    const Tensor& input,
    const IntArrayRef kernel,
    const IntArrayRef padding,
    IntArrayRef stride,
    const IntArrayRef dilation,
    const bool ceil_mode,
    const float output_min = -std::numeric_limits<float>::infinity(),
    const float output_max = +std::numeric_limits<float>::infinity());

//
// Global Average Pooling
//

bool use_global_average_pool(const Tensor& input);
Tensor global_average_pool(const Tensor& input);

//
// Channel Shuffle
//

bool use_channel_shuffle(
    const Tensor& input,
    const int64_t groups);

Tensor channel_shuffle(
    const Tensor& input,
    const int64_t groups);

//
// Activations
//
bool use_hardswish(const Tensor& input);
Tensor hardswish(const Tensor& input);
Tensor& hardswish_(Tensor& input);

} // namespace at::native::xnnpack

```

## High-Level Overview

This file is part of the PyTorch repository. It is a C++/CUDA source/header file that may contain implementations, declarations, or kernel code.

## Detailed Walkthrough


## Key Components

The file contains 205 words across 95 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 1970 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
