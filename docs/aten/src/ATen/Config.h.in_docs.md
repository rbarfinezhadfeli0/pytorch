# Documentation: Config.h.in

## File Metadata
- **Path**: `aten/src/ATen/Config.h.in`
- **Size**: 1093 bytes
- **Lines**: 23
- **Extension**: .in
- **Type**: Regular file

## Original Source

```in
#pragma once

// Test these using #if AT_MKL_ENABLED(), not #ifdef, so that it's
// obvious if you forgot to include Config.h
//    c.f. https://stackoverflow.com/questions/33759787/generating-an-error-if-checked-boolean-macro-is-not-defined
//
// DO NOT put the macros for CUDA libraries in this file; they belong in cuda/CUDAConfig.h

#define AT_MKLDNN_ENABLED() @AT_MKLDNN_ENABLED@
#define AT_MKLDNN_ACL_ENABLED() @AT_MKLDNN_ACL_ENABLED@
#define AT_MKL_ENABLED() @AT_MKL_ENABLED@
#define AT_MKL_SEQUENTIAL() @AT_MKL_SEQUENTIAL@
#define AT_POCKETFFT_ENABLED() @AT_POCKETFFT_ENABLED@
#define AT_NNPACK_ENABLED() @AT_NNPACK_ENABLED@
#define CAFFE2_STATIC_LINK_CUDA() @CAFFE2_STATIC_LINK_CUDA_INT@
#define AT_BUILD_WITH_BLAS() @AT_BUILD_WITH_BLAS@
#define AT_BUILD_WITH_LAPACK() @AT_BUILD_WITH_LAPACK@
#define AT_PARALLEL_OPENMP @AT_PARALLEL_OPENMP@
#define AT_PARALLEL_NATIVE @AT_PARALLEL_NATIVE@
#define AT_BLAS_F2C() @AT_BLAS_F2C@
#define AT_BLAS_USE_CBLAS_DOT() @AT_BLAS_USE_CBLAS_DOT@
#define AT_KLEIDIAI_ENABLED() @AT_KLEIDIAI_ENABLED@
#define AT_USE_EIGEN_SPARSE() @AT_USE_EIGEN_SPARSE@

```

## High-Level Overview

This file is part of the PyTorch repository. It is a source or configuration file.

## Detailed Walkthrough


## Key Components

The file contains 86 words across 23 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 1093 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
