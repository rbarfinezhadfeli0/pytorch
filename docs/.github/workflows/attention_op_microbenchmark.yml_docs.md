# Documentation: attention_op_microbenchmark.yml

## File Metadata
- **Path**: `.github/workflows/attention_op_microbenchmark.yml`
- **Size**: 2656 bytes
- **Lines**: 73
- **Extension**: .yml
- **Type**: Regular file

## Original Source

```yml
name: attention_op_microbenchmark

on:
  push:
    tags:
      - ciflow/op-benchmark/*
  workflow_dispatch:
  schedule:
    # Run at 06:00 UTC everyday
    - cron: 0 7 * * *

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref_name }}-${{ github.ref_type == 'branch' && github.sha }}-${{ github.event_name == 'workflow_dispatch' }}-${{ github.event_name == 'schedule' }}
  cancel-in-progress: true

permissions:
  id-token: write
  contents: read

jobs:
  attn-microbenchmark-build:
    if: github.repository_owner == 'pytorch'
    uses: ./.github/workflows/_linux-build.yml
    with:
      runner: linux.12xlarge.memory
      build-environment: linux-jammy-cuda12.8-py3.10-gcc9-sm80
      docker-image-name: ci-image:pytorch-linux-jammy-cuda12.8-cudnn9-py3-gcc11
      cuda-arch-list: '8.0 9.0'
      test-matrix: |
        { include: [
          { config: "attention_microbenchmark_test", shard: 1, num_shards: 1, runner: "linux.aws.a100" },
          { config: "attention_microbenchmark_test", shard: 1, num_shards: 1, runner: "linux.aws.h100" },
        ]}
    secrets: inherit

  attn-microbenchmark-test:
    name: attn-microbenchmark-test
    uses: ./.github/workflows/_linux-test.yml
    needs: attn-microbenchmark-build
    with:
      timeout-minutes: 500
      build-environment: linux-jammy-cuda12.8-py3.10-gcc9-sm80
      docker-image: ${{ needs.attn-microbenchmark-build.outputs.docker-image }}
      test-matrix: ${{ needs.attn-microbenchmark-build.outputs.test-matrix }}
    secrets: inherit

  # B200 runner
  opmicrobenchmark-build-b200:
    if: github.repository_owner == 'pytorch'
    name: opmicrobenchmark-build-b200
    uses: ./.github/workflows/_linux-build.yml
    with:
      runner: linux.12xlarge.memory
      build-environment: linux-jammy-cuda12.8-py3.10-gcc9-sm100
      docker-image-name: ci-image:pytorch-linux-jammy-cuda12.8-cudnn9-py3-gcc11
      cuda-arch-list: '10.0'
      test-matrix: |
        { include: [
          { config: "operator_microbenchmark_test", shard: 1, num_shards: 1, runner: "linux.dgx.b200" },
        ]}
    secrets: inherit

  opmicrobenchmark-test-b200:
    name: opmicrobenchmark-test-b200
    uses: ./.github/workflows/_linux-test.yml
    needs: opmicrobenchmark-build-b200
    with:
      timeout-minutes: 500
      build-environment: linux-jammy-cuda12.8-py3.10-gcc9-sm100
      docker-image: ${{ needs.opmicrobenchmark-build-b200.outputs.docker-image }}
      test-matrix: ${{ needs.opmicrobenchmark-build-b200.outputs.test-matrix }}
      aws-role-to-assume: arn:aws:iam::308535385114:role/gha_workflow_s3_and_ecr_read_only
    secrets: inherit

```

## High-Level Overview

This file is part of the PyTorch repository. It is a configuration file.

## Detailed Walkthrough


## Key Components

The file contains 183 words across 73 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 2656 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
