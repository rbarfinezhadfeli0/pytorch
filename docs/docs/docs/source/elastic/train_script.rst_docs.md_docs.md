# Documentation: `docs/docs/source/elastic/train_script.rst_docs.md`

## File Metadata

- **Path**: `docs/docs/source/elastic/train_script.rst_docs.md`
- **Size**: 4,107 bytes (4.01 KB)
- **Type**: Markdown Documentation
- **Extension**: `.md`

## File Purpose

This file is part of the **documentation**.

## Original Source

```markdown
# Documentation: `docs/source/elastic/train_script.rst`

## File Metadata

- **Path**: `docs/source/elastic/train_script.rst`
- **Size**: 1,926 bytes (1.88 KB)
- **Type**: Source File (.rst)
- **Extension**: `.rst`

## File Purpose

This file is part of the **documentation**.

## Original Source

```
.. _elastic_train_script:

Train script
-------------

If your train script works with ``torch.distributed.launch`` it will continue
working with ``torchrun`` with these differences:

1. No need to manually pass ``RANK``, ``WORLD_SIZE``,
   ``MASTER_ADDR``, and ``MASTER_PORT``.

2. ``rdzv_backend`` and ``rdzv_endpoint`` can be provided. For most users
   this will be set to ``c10d`` (see `rendezvous <rendezvous.html>`_). The default
   ``rdzv_backend`` creates a non-elastic rendezvous where ``rdzv_endpoint`` holds
   the master address.

3. Make sure you have a ``load_checkpoint(path)`` and
   ``save_checkpoint(path)`` logic in your script. When any number of
   workers fail we restart all the workers with the same program
   arguments so you will lose progress up to the most recent checkpoint
   (see `elastic launch <run.html>`_).

4. ``use_env`` flag has been removed. If you were parsing local rank by parsing
   the ``--local-rank`` option, you need to get the local rank from the
   environment variable ``LOCAL_RANK`` (e.g. ``int(os.environ["LOCAL_RANK"])``).

Below is an expository example of a training script that checkpoints on each
epoch, hence the worst-case progress lost on failure is one full epoch worth
of training.

.. code-block:: python

  def main():
       args = parse_args(sys.argv[1:])
       state = load_checkpoint(args.checkpoint_path)
       initialize(state)

       # torch.distributed.run ensures that this will work
       # by exporting all the env vars needed to initialize the process group
       torch.distributed.init_process_group(backend=args.backend)

       for i in range(state.epoch, state.total_num_epochs)
            for batch in iter(state.dataset)
                train(batch, state.model)

            state.epoch += 1
            save_checkpoint(state)

For concrete examples of torchelastic-compliant train scripts, visit
our `examples <examples.html>`_ page.

```



## High-Level Overview

This file is part of the PyTorch framework located at `docs/source/elastic`.

## Detailed Analysis

### Code Structure


*For complete code details, see the Original Source section above.*


## Architecture & Design

### Role in PyTorch Architecture

This file is located in `docs/source/elastic`, which is part of the PyTorch project infrastructure.



## Dependencies

### Import Dependencies

*Dependency analysis not applicable for this file type.*


## Code Patterns & Idioms

### Common Patterns

*No specific patterns automatically detected.*


## Performance Considerations

### Performance Notes


*Detailed performance analysis requires profiling and benchmarking.*


## Security & Safety

### Security Considerations

- No obvious security concerns detected in automated analysis.

*Manual security review is recommended for production code.*


## Testing & Usage

### Testing

Test files for this module may be located in the `test/` directory.

### Usage Examples

*See the source code and related test files for usage examples.*


## Related Files

### Related Files

Files in the same folder (`docs/source/elastic`):

- [`examples.rst_docs.md`](./examples.rst_docs.md)
- [`events.rst_docs.md`](./events.rst_docs.md)
- [`run.rst_docs.md`](./run.rst_docs.md)
- [`metrics.rst_docs.md`](./metrics.rst_docs.md)
- [`timer.rst_docs.md`](./timer.rst_docs.md)
- [`customization.rst_docs.md`](./customization.rst_docs.md)
- [`rendezvous.rst_docs.md`](./rendezvous.rst_docs.md)
- [`numa.rst_docs.md`](./numa.rst_docs.md)
- [`subprocess_handler.rst_docs.md`](./subprocess_handler.rst_docs.md)


## Cross-References

- **File Documentation**: `train_script.rst_docs.md`
- **Keyword Index**: `train_script.rst_kw.md`
- **Folder Index**: `index.md`
- **Folder Documentation**: `doc.md`

---

*Generated by PyTorch Repository Documentation System*

```



## High-Level Overview

This file is part of the PyTorch framework located at `docs/docs/source/elastic`.

## Detailed Analysis

### Code Structure


*For complete code details, see the Original Source section above.*


## Architecture & Design

### Role in PyTorch Architecture

This file is located in `docs/docs/source/elastic`, which is part of the PyTorch project infrastructure.



## Dependencies

### Import Dependencies

*Dependency analysis not applicable for this file type.*


## Code Patterns & Idioms

### Common Patterns

*No specific patterns automatically detected.*


## Performance Considerations

### Performance Notes

- Contains **benchmarking** code or performance tests.

*Detailed performance analysis requires profiling and benchmarking.*


## Security & Safety

### Security Considerations

- **Command Execution**: Executes system commands - validate inputs

*Manual security review is recommended for production code.*


## Testing & Usage

### Testing

Test files for this module may be located in the `test/` directory.

### Usage Examples

*See the source code and related test files for usage examples.*


## Related Files

### Related Files

Files in the same folder (`docs/docs/source/elastic`):

- [`subprocess_handler.rst_kw.md_docs.md`](./subprocess_handler.rst_kw.md_docs.md)
- [`multiprocessing.rst_kw.md_docs.md`](./multiprocessing.rst_kw.md_docs.md)
- [`customization.rst_docs.md_docs.md`](./customization.rst_docs.md_docs.md)
- [`kubernetes.rst_docs.md_docs.md`](./kubernetes.rst_docs.md_docs.md)
- [`metrics.rst_kw.md_docs.md`](./metrics.rst_kw.md_docs.md)
- [`control_plane.rst_docs.md_docs.md`](./control_plane.rst_docs.md_docs.md)
- [`run.rst_docs.md_docs.md`](./run.rst_docs.md_docs.md)
- [`events.rst_docs.md_docs.md`](./events.rst_docs.md_docs.md)
- [`timer.rst_docs.md_docs.md`](./timer.rst_docs.md_docs.md)
- [`metrics.rst_docs.md_docs.md`](./metrics.rst_docs.md_docs.md)


## Cross-References

- **File Documentation**: `train_script.rst_docs.md_docs.md`
- **Keyword Index**: `train_script.rst_docs.md_kw.md`
- **Folder Index**: `index.md`
- **Folder Documentation**: `doc.md`

---

*Generated by PyTorch Repository Documentation System*
