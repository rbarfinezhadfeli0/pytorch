# Documentation: dynamo_inline.py

## File Metadata
- **Path**: `benchmarks/dynamo/pr_time_benchmarks/benchmarks/dynamo_inline.py`
- **Size**: 2153 bytes
- **Lines**: 117
- **Extension**: .py
- **Type**: Regular file

## Original Source

```py
import sys

from benchmark_base import BenchmarkBase

import torch
import torch.nn as nn
from torch._inductor.utils import fresh_cache


# Create a chain of artificial nesting
def fn(x):
    return x + 1


def fn1(x):
    return fn(x)


def fn2(x):
    return fn1(x)


def fn3(x):
    return fn2(x)


def fn4(x):
    return fn3(x)


def fn5(x):
    return fn4(x)


def fn6(x):
    return fn5(x)


def fn7(x):
    return fn6(x)


def fn8(x):
    return fn7(x)


def fn9(x):
    return fn8(x)


class InlineMod(nn.Module):
    def __init__(self):
        super().__init__()
        self._n = 1000

    def forward(self, x):
        for _ in range(self._n):
            x = fn9(x)
        return x


class Benchmark(BenchmarkBase):
    def __init__(
        self,
        ModuleClass,
        backend="eager",
        is_gpu=False,
        dynamic=False,
    ):
        self.ModuleClass = ModuleClass
        self._name = ModuleClass.__name__
        self._is_gpu = is_gpu

        super().__init__(
            category="basic",
            backend=backend,
            device="cuda" if self._is_gpu else "cpu",
            dynamic=dynamic,
        )

    def name(self):
        prefix = f"{self.category()}_{self._name}_{self.backend()}"
        return prefix

    def _prepare_once(self):
        self.m = self.ModuleClass()
        torch.set_float32_matmul_precision("high")
        self.input = torch.ones(10, device=self.device())

    def _prepare(self):
        torch._dynamo.reset()

    def _work(self):
        # enable_cpp_symbolic_shape_guards has impact on this benchmark
        # Keep using False value for consistency.
        with (
            fresh_cache(),
        ):
            opt_m = torch.compile(backend=self.backend(), dynamic=self.is_dynamic())(
                self.m.cuda() if self._is_gpu else self.m
            )
            opt_m(self.input)


def main():
    result_path = sys.argv[1]
    benchmarks = [
        Benchmark(InlineMod),
    ]
    for b in benchmarks:
        b.enable_compile_time_instruction_count().collect_all().append_results(
            result_path
        )


if __name__ == "__main__":
    main()

```

## High-Level Overview

This file is part of the PyTorch repository. It is a Python source file that may contain classes, functions, and module-level code.

## Detailed Walkthrough

### Classes
This file defines 2 class(es): InlineMod, Benchmark

### Functions
This file defines 18 function(s): fn, fn1, fn2, fn3, fn4, fn5, fn6, fn7, fn8, fn9, __init__, forward, __init__, name, _prepare_once, _prepare, _work, main


## Key Components

The file contains 187 words across 117 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 2153 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
