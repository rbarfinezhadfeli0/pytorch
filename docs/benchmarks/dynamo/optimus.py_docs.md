# Documentation: optimus.py

## File Metadata
- **Path**: `benchmarks/dynamo/optimus.py`
- **Size**: 1977 bytes
- **Lines**: 62
- **Extension**: .py
- **Type**: Regular file

## Original Source

```py
import functools

import torch


def get_baseline_ctx(nopython, inductor_compile_mode):
    return functools.partial(
        torch.compile,
        backend="inductor",
        fullgraph=nopython,
        mode=inductor_compile_mode,
    )


def get_optimus_optimize_ctx(config, nopython, inductor_compile_mode):
    if config == "vertical_opt":
        optimus_inductor_config = {
            "pre_grad_fusion_options": {
                "normalization_pass": {},
                "merge_splits_pass": {},
                "split_cat_pass": {},
                "unbind_stack_pass": {},
                "unbind_cat_to_view_pass": {},
            }
        }
    elif config == "horizontal_opt":
        optimus_inductor_config = {
            "pre_grad_fusion_options": {
                "normalization_pass": {},
                "batch_linear": {},
                "batch_layernorm": {},
            },
        }
    elif config == "all":
        optimus_inductor_config = {
            "pre_grad_fusion_options": {
                "normalization_pass": {},
                "batch_linear": {},
                "batch_layernorm": {},
                "merge_splits_pass": {},
                "split_cat_pass": {},
                "unbind_stack_pass": {},
                "unbind_cat_to_view_pass": {},
            },
        }
    else:
        raise RuntimeError(f"Unknown optimus config: {config}")

    def _inner(fn):
        if "pre_grad_fusion_options" in optimus_inductor_config:
            torch._inductor.config.pre_grad_fusion_options = optimus_inductor_config[
                "pre_grad_fusion_options"
            ]
        if "post_grad_fusion_options" in optimus_inductor_config:
            torch._inductor.config.post_grad_fusion_options = optimus_inductor_config[
                "post_grad_fusion_options"
            ]
        return torch.compile(
            fn, backend="inductor", fullgraph=nopython, mode=inductor_compile_mode
        )

    return _inner

```

## High-Level Overview

This file is part of the PyTorch repository. It is a Python source file that may contain classes, functions, and module-level code.

## Detailed Walkthrough

### Functions
This file defines 3 function(s): get_baseline_ctx, get_optimus_optimize_ctx, _inner


## Key Components

The file contains 116 words across 62 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 1977 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
