# Keywords: attention_bias_benchmarks.py

## Keyword Index

### A

- **Average**: Identifier found in `attention_bias_benchmarks.py`
- **adaptive_autorange**: Identifier found in `attention_bias_benchmarks.py`
- **all_configs**: Identifier found in `attention_bias_benchmarks.py`
- **append**: Identifier found in `attention_bias_benchmarks.py`
- **argmax**: Identifier found in `attention_bias_benchmarks.py`
- **argmin**: Identifier found in `attention_bias_benchmarks.py`
- **args**: Identifier found in `attention_bias_benchmarks.py`
- **asdict**: Identifier found in `attention_bias_benchmarks.py`
- **assert**: Identifier found in `attention_bias_benchmarks.py`
- **assert_close**: Identifier found in `attention_bias_benchmarks.py`
- **attention**: Identifier found in `attention_bias_benchmarks.py`
- **attn**: Identifier found in `attention_bias_benchmarks.py`
- **attn_mask**: Identifier found in `attention_bias_benchmarks.py`
- **attn_mask_subclass_time**: Identifier found in `attention_bias_benchmarks.py`
- **attn_mask_tensor**: Identifier found in `attention_bias_benchmarks.py`

### B

- **batch_size**: Identifier found in `attention_bias_benchmarks.py`
- **batch_sizes**: Identifier found in `attention_bias_benchmarks.py`
- **benchmark**: Identifier found in `attention_bias_benchmarks.py`
- **benchmark_torch_function_in_microseconds**: Identifier found in `attention_bias_benchmarks.py`
- **bfloat16**: Identifier found in `attention_bias_benchmarks.py`
- **bias**: Identifier found in `attention_bias_benchmarks.py`

### C

- **Calculate**: Identifier found in `attention_bias_benchmarks.py`
- **Callable**: Identifier found in `attention_bias_benchmarks.py`
- **CausalBias**: Identifier found in `attention_bias_benchmarks.py`
- **CausalVariant**: Identifier found in `attention_bias_benchmarks.py`
- **CompositeMHA**: Identifier found in `attention_bias_benchmarks.py`
- **Create**: Identifier found in `attention_bias_benchmarks.py`
- **calculate_speedup**: Identifier found in `attention_bias_benchmarks.py`
- **class**: Identifier found in `attention_bias_benchmarks.py`
- **collections**: Identifier found in `attention_bias_benchmarks.py`
- **comparing**: Identifier found in `attention_bias_benchmarks.py`
- **composite_mha**: Identifier found in `attention_bias_benchmarks.py`
- **config**: Identifier found in `attention_bias_benchmarks.py`
- **constant_**: Identifier found in `attention_bias_benchmarks.py`
- **cuda**: Identifier found in `attention_bias_benchmarks.py`

### D

- **data**: Identifier found in `attention_bias_benchmarks.py`
- **dataclass**: Identifier found in `attention_bias_benchmarks.py`
- **dataclasses**: Identifier found in `attention_bias_benchmarks.py`
- **device**: Identifier found in `attention_bias_benchmarks.py`
- **dict**: Identifier found in `attention_bias_benchmarks.py`
- **dict_obj**: Identifier found in `attention_bias_benchmarks.py`
- **dictionaries**: Identifier found in `attention_bias_benchmarks.py`
- **divisible**: Identifier found in `attention_bias_benchmarks.py`
- **dropout_p**: Identifier found in `attention_bias_benchmarks.py`
- **dtype**: Identifier found in `attention_bias_benchmarks.py`
- **dtypes**: Identifier found in `attention_bias_benchmarks.py`

### E

- **Experiment**: Identifier found in `attention_bias_benchmarks.py`
- **ExperimentConfig**: Identifier found in `attention_bias_benchmarks.py`
- **ExperimentResults**: Identifier found in `attention_bias_benchmarks.py`
- **embed_dim**: Identifier found in `attention_bias_benchmarks.py`
- **embed_dims**: Identifier found in `attention_bias_benchmarks.py`
- **empty**: Identifier found in `attention_bias_benchmarks.py`
- **experiment**: Identifier found in `attention_bias_benchmarks.py`

### F

- **Find**: Identifier found in `attention_bias_benchmarks.py`
- **factory_kwargs**: Identifier found in `attention_bias_benchmarks.py`
- **float**: Identifier found in `attention_bias_benchmarks.py`
- **forward**: Identifier found in `attention_bias_benchmarks.py`
- **from**: Identifier found in `attention_bias_benchmarks.py`
- **fromkeys**: Identifier found in `attention_bias_benchmarks.py`
- **frozen**: Identifier found in `attention_bias_benchmarks.py`
- **func**: Identifier found in `attention_bias_benchmarks.py`
- **functional**: Identifier found in `attention_bias_benchmarks.py`
- **functools**: Identifier found in `attention_bias_benchmarks.py`

### G

- **generate_experiment_configs**: Identifier found in `attention_bias_benchmarks.py`
- **generate_inputs**: Identifier found in `attention_bias_benchmarks.py`
- **get_entries**: Identifier found in `attention_bias_benchmarks.py`
- **globals**: Identifier found in `attention_bias_benchmarks.py`

### H

- **head_dim**: Identifier found in `attention_bias_benchmarks.py`
- **headers**: Identifier found in `attention_bias_benchmarks.py`
- **heads**: Identifier found in `attention_bias_benchmarks.py`

### I

- **import**: Identifier found in `attention_bias_benchmarks.py`
- **indices**: Identifier found in `attention_bias_benchmarks.py`
- **init**: Identifier found in `attention_bias_benchmarks.py`
- **itertools**: Identifier found in `attention_bias_benchmarks.py`

### K

- **k_proj_weight**: Identifier found in `attention_bias_benchmarks.py`
- **k_seq_len**: Identifier found in `attention_bias_benchmarks.py`
- **key**: Identifier found in `attention_bias_benchmarks.py`
- **key_projected**: Identifier found in `attention_bias_benchmarks.py`
- **keys**: Identifier found in `attention_bias_benchmarks.py`
- **kv_seq_len**: Identifier found in `attention_bias_benchmarks.py`
- **kv_sequence_length**: Identifier found in `attention_bias_benchmarks.py`
- **kv_shape**: Identifier found in `attention_bias_benchmarks.py`
- **kwargs**: Identifier found in `attention_bias_benchmarks.py`

### L

- **LOWER_RIGHT**: Identifier found in `attention_bias_benchmarks.py`
- **linear**: Identifier found in `attention_bias_benchmarks.py`
- **list**: Identifier found in `attention_bias_benchmarks.py`

### M

- **MHA**: Identifier found in `attention_bias_benchmarks.py`
- **Match**: Identifier found in `attention_bias_benchmarks.py`
- **Module**: Identifier found in `attention_bias_benchmarks.py`
- **main**: Identifier found in `attention_bias_benchmarks.py`
- **make_kv**: Identifier found in `attention_bias_benchmarks.py`
- **make_q**: Identifier found in `attention_bias_benchmarks.py`
- **manual_seed**: Identifier found in `attention_bias_benchmarks.py`
- **mask**: Identifier found in `attention_bias_benchmarks.py`
- **materialized_mask_time**: Identifier found in `attention_bias_benchmarks.py`
- **max_config_dict**: Identifier found in `attention_bias_benchmarks.py`
- **max_speedup_index**: Identifier found in `attention_bias_benchmarks.py`
- **mean**: Identifier found in `attention_bias_benchmarks.py`
- **median**: Identifier found in `attention_bias_benchmarks.py`
- **min_config_dict**: Identifier found in `attention_bias_benchmarks.py`
- **min_run_time**: Identifier found in `attention_bias_benchmarks.py`
- **min_speedup_index**: Identifier found in `attention_bias_benchmarks.py`
- **must**: Identifier found in `attention_bias_benchmarks.py`

### N

- **None**: Identifier found in `attention_bias_benchmarks.py`
- **nn_mha**: Identifier found in `attention_bias_benchmarks.py`
- **num_heads**: Identifier found in `attention_bias_benchmarks.py`
- **numpy**: Identifier found in `attention_bias_benchmarks.py`

### O

- **out_proj**: Identifier found in `attention_bias_benchmarks.py`

### P

- **Parameter**: Identifier found in `attention_bias_benchmarks.py`
- **Print**: Identifier found in `attention_bias_benchmarks.py`
- **parameter**: Identifier found in `attention_bias_benchmarks.py`
- **partial**: Identifier found in `attention_bias_benchmarks.py`
- **pretty**: Identifier found in `attention_bias_benchmarks.py`
- **print**: Identifier found in `attention_bias_benchmarks.py`
- **print_results**: Identifier found in `attention_bias_benchmarks.py`
- **product**: Identifier found in `attention_bias_benchmarks.py`
- **property**: Identifier found in `attention_bias_benchmarks.py`

### Q

- **q_kv_seq_lens**: Identifier found in `attention_bias_benchmarks.py`
- **q_proj_weight**: Identifier found in `attention_bias_benchmarks.py`
- **q_seq_len**: Identifier found in `attention_bias_benchmarks.py`
- **q_sequence_length**: Identifier found in `attention_bias_benchmarks.py`
- **q_shape**: Identifier found in `attention_bias_benchmarks.py`
- **query**: Identifier found in `attention_bias_benchmarks.py`
- **query_projected**: Identifier found in `attention_bias_benchmarks.py`

### R

- **rand**: Identifier found in `attention_bias_benchmarks.py`
- **random**: Identifier found in `attention_bias_benchmarks.py`
- **range**: Identifier found in `attention_bias_benchmarks.py`
- **reset_parameters**: Identifier found in `attention_bias_benchmarks.py`
- **reshape**: Identifier found in `attention_bias_benchmarks.py`
- **results**: Identifier found in `attention_bias_benchmarks.py`
- **return**: Identifier found in `attention_bias_benchmarks.py`
- **run_single_experiment**: Identifier found in `attention_bias_benchmarks.py`

### S

- **Speedup**: Identifier found in `attention_bias_benchmarks.py`
- **scaled_dot_product_attention**: Identifier found in `attention_bias_benchmarks.py`
- **seed**: Identifier found in `attention_bias_benchmarks.py`
- **self**: Identifier found in `attention_bias_benchmarks.py`
- **signature**: Identifier found in `attention_bias_benchmarks.py`
- **size**: Identifier found in `attention_bias_benchmarks.py`
- **speedups**: Identifier found in `attention_bias_benchmarks.py`
- **stmt**: Identifier found in `attention_bias_benchmarks.py`
- **super**: Identifier found in `attention_bias_benchmarks.py`

### T

- **Tensor**: Identifier found in `attention_bias_benchmarks.py`
- **Timer**: Identifier found in `attention_bias_benchmarks.py`
- **True**: Identifier found in `attention_bias_benchmarks.py`
- **Type**: Identifier found in `attention_bias_benchmarks.py`
- **t0**: Identifier found in `attention_bias_benchmarks.py`
- **table**: Identifier found in `attention_bias_benchmarks.py`
- **table_data**: Identifier found in `attention_bias_benchmarks.py`
- **tablefmt**: Identifier found in `attention_bias_benchmarks.py`
- **tabulate**: Identifier found in `attention_bias_benchmarks.py`
- **testing**: Identifier found in `attention_bias_benchmarks.py`
- **timing**: Identifier found in `attention_bias_benchmarks.py`
- **torch**: Identifier found in `attention_bias_benchmarks.py`
- **tqdm**: Identifier found in `attention_bias_benchmarks.py`
- **transpose**: Identifier found in `attention_bias_benchmarks.py`
- **typing**: Identifier found in `attention_bias_benchmarks.py`

### U

- **Union**: Identifier found in `attention_bias_benchmarks.py`
- **utils**: Identifier found in `attention_bias_benchmarks.py`

### V

- **v_proj_weight**: Identifier found in `attention_bias_benchmarks.py`
- **value**: Identifier found in `attention_bias_benchmarks.py`
- **value_projected**: Identifier found in `attention_bias_benchmarks.py`
- **view**: Identifier found in `attention_bias_benchmarks.py`

### W

- **warmup**: Identifier found in `attention_bias_benchmarks.py`

### X

- **xavier_uniform_**: Identifier found in `attention_bias_benchmarks.py`

### _

- **__init__**: Identifier found in `attention_bias_benchmarks.py`
- **__name__**: Identifier found in `attention_bias_benchmarks.py`

