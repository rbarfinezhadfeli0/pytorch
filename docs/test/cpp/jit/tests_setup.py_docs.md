# Documentation: tests_setup.py

## File Metadata
- **Path**: `test/cpp/jit/tests_setup.py`
- **Size**: 2608 bytes
- **Lines**: 118
- **Extension**: .py
- **Type**: Regular file

## Original Source

```py
import os
import sys

import torch


class Setup:
    def setup(self):
        raise NotImplementedError

    def shutdown(self):
        raise NotImplementedError


class FileSetup:
    path = None

    def shutdown(self):
        if os.path.exists(self.path):
            os.remove(self.path)


class EvalModeForLoadedModule(FileSetup):
    path = "dropout_model.pt"

    def setup(self):
        class Model(torch.jit.ScriptModule):
            def __init__(self) -> None:
                super().__init__()
                self.dropout = torch.nn.Dropout(0.1)

            @torch.jit.script_method
            def forward(self, x):
                x = self.dropout(x)
                return x

        model = Model()
        model = model.train()
        model.save(self.path)


class SerializationInterop(FileSetup):
    path = "ivalue.pt"

    def setup(self):
        ones = torch.ones(2, 2)
        twos = torch.ones(3, 5) * 2

        value = (ones, twos)

        torch.save(value, self.path, _use_new_zipfile_serialization=True)


# See testTorchSaveError in test/cpp/jit/tests.h for usage
class TorchSaveError(FileSetup):
    path = "eager_value.pt"

    def setup(self):
        ones = torch.ones(2, 2)
        twos = torch.ones(3, 5) * 2

        value = (ones, twos)

        torch.save(value, self.path, _use_new_zipfile_serialization=False)


class TorchSaveJitStream_CUDA(FileSetup):
    path = "saved_stream_model.pt"

    def setup(self):
        if not torch.cuda.is_available():
            return

        class Model(torch.nn.Module):
            def forward(self):
                s = torch.cuda.Stream()
                a = torch.rand(3, 4, device="cuda")
                b = torch.rand(3, 4, device="cuda")

                with torch.cuda.stream(s):
                    is_stream_s = (
                        torch.cuda.current_stream(s.device_index()).id() == s.id()
                    )
                    c = torch.cat((a, b), 0).to("cuda")
                s.synchronize()
                return is_stream_s, a, b, c

        model = Model()

        # Script the model and save
        script_model = torch.jit.script(model)
        torch.jit.save(script_model, self.path)


tests = [
    EvalModeForLoadedModule(),
    SerializationInterop(),
    TorchSaveError(),
    TorchSaveJitStream_CUDA(),
]


def setup():
    for test in tests:
        test.setup()


def shutdown():
    for test in tests:
        test.shutdown()


if __name__ == "__main__":
    command = sys.argv[1]
    if command == "setup":
        setup()
    elif command == "shutdown":
        shutdown()

```

## High-Level Overview

This file is part of the PyTorch repository. It is a Python source file that may contain classes, functions, and module-level code.

## Detailed Walkthrough

### Classes
This file defines 8 class(es): Setup, FileSetup, EvalModeForLoadedModule, Model, SerializationInterop, TorchSaveError, TorchSaveJitStream_CUDA, Model

### Functions
This file defines 12 function(s): setup, shutdown, shutdown, setup, __init__, forward, setup, setup, setup, forward, setup, shutdown


## Key Components

The file contains 215 words across 118 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 2608 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
