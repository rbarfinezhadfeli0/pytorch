# Keyword Index: `test/inductor/test_flex_attention.py`

## File Information

- **Original File**: [test/inductor/test_flex_attention.py](../../../test/inductor/test_flex_attention.py)
- **Documentation**: [`test_flex_attention.py_docs.md`](./test_flex_attention.py_docs.md)
- **Folder**: `test/inductor`

## Keywords Extracted

This file contains the following key identifiers, symbols, and concepts:


### Classs

- **`ApplyMask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`AsStridedErrorTensor`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`Attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`DummyAttentionModule`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`FlexAttentionCPB`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`FlexAttentionModule`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`GraphModule`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`Model`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`Repro`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`SacModule`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`SimpleAttention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`SubstringSet`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`TestBlockMask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`TestFlexAttention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`TestLearnableBiases`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`TestModule`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`TestPagedAttention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`class`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`from`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`fw_graph0`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`joint_graph0`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`mask_fn_0`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`mask_graph0`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`methods`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`query`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`score_mod_0`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)

### Functions

- **`__contains__`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`__init__`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`__new__`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`__repr__`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`__str__`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`__tensor_flatten__`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`__tensor_unflatten__`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`__torch_dispatch__`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_alibi_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_causal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_causal_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_check_equal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_check_out`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_check_out_and_grad`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_check_outputs_and_grads`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_flex_attention_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_generate_alibi_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_gold_check`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_head_offset`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_init_tables`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_init_tensors`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_inverse_causal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_inverse_causal_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_mask_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_offsets_to_doc_ids_tensor`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_rel_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_rel_causal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_score_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_squared`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_test_block_mask_reuse_with_weird_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_test_flex_attention_with_dynamic_max_autotune`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_test_learnable_bias_inner`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_times_two`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_trig`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`_trig2`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`add_decomposed_rel_pos`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`all_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`allocate_page_cache`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`apply_multiplicative_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`backward`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`batch_flip_causal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`batch_mask_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`batch_reserve`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`bias_func`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`bias_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`causal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`causal_constructor`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`causal_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`causal_mask_slidewindow_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`causal_offset_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`cdiv`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`coerce_to_strides`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`column_major_tensor`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`composed_score_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`create_attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`create_block_mask_from_seqlens`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`create_block_mask_test`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`create_inputs`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`create_njt_wrapper`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`create_padded_dense_wrapper`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`debug_compile_fx_inner`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`decorator`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`doc_mask_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`document_masking_causal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`eager_sdpa_hop`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`euclidean_dist_pos_embed`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`f`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`flex_attention_as_strided_error_tensor`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`flex_attention_fn`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`flex_attention_lse_only`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`flex_attn_fn`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`forward`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`func`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`generate_doc_mask_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`generate_random_lengths`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`generate_score_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`generate_test_inputs`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`get_mask_mod_with_offset`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`get_params`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`get_x_y`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`global_causal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`head_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`index_multiple`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`index_weird1`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`index_weird2`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`large_tensor_test_class`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`length_to_offsets`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`make_tensor`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`mask_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`natten_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`neg_causal_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`njt_score_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`noop_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`paged_f`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`policy_fn`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`preprocess_paged_attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`query_key_value_clones`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`rel_pos_1d`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`rel_pos_2d`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`rel_pos_2d_transposed`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`rel_pos_3d_transposed`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`replace`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`replace_non_printable`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`rmse`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`roundup`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_automatic_dynamic_test`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_dynamic_test`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_paged_attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_test`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_test_with_call`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_test_with_paged_attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_with_head_count`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`score_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`score_mod_1`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`score_mod_2`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`score_mod_func`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`score_mod_scale`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`scoremod_1`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`scoremod_2`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`sdpa_hop`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`seq_mask_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`setUp`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`set_float32_matmul_precision_xpu`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`setup_context`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`silu_score`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`simple_score_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`skip_on_cpu`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`skip_on_cuda`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`skip_on_rocm`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`skip_on_xpu`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`sliding_window`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`sliding_window_causal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`temp_float32_matmul_precision`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_GQA`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_GQA_causal_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_absolute_2d_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_allocate`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_aot_eager_gradcheck`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_autograd_function_in_score_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_backprop_error_case`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_backward_error_with_none_q_indices`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_batch_head_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_block_mask_attributes`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_block_mask_device_change`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_block_mask_non_divisible`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_block_mask_operations_with_none_q_indices`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_block_mask_viz`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_block_mask_vs_sequence_lengths`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_block_size`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_block_size_changes`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_broadcasted_head_block_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_builtin_score_mods`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_builtin_score_mods_automatic_dynamic`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_builtin_score_mods_different_block_size`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_builtin_score_mods_different_seqlen`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_builtin_score_mods_dynamic`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_builtin_score_mods_seqlen_lt_custom_sparse_block_size`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_builtin_score_mods_seqlen_lt_default_sparse_block_size`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_cant_lower_error_message`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_captured_buffers_all_dims`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_captured_reduction`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_captured_scale`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_captured_score_mod_aot_eager_gradcheck`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_captured_wrong_device_error_message`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_causal_block`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_causal_block_non_divisible`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_causal_block_non_divisible_with_captured_buffer`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_causal_block_paged_attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_comparison_vs_sdpa_with_learnable_bias`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_compiling_create_block_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_compiling_create_block_mask_no_recompile`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_convert_logical_block_mask`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_convert_mask_mod`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_cpu_error_message_return_lse`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_create_is_cuda_graphable`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_custom_block_mask_generator`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_custom_score_mod_layout_freeze`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_debug_flag_disables_internal_compilation`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_dependent_causal_bidirectional`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_device_cuda_1`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_differentiable_logsumexp_compiled`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_differentiable_logsumexp_gradcheck`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_distinct_biases`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_doc_mask_clamped_repro`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_doc_mask_sparse`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_document_masking_edge_case`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_dynamic_captured_buffer`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_dynamic_divisibility_guards`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_dynamic_shapes_bug_dynamic_batch`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_dynamic_shapes_with_custom_kernel_options`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_dynamic_shapes_with_max_autotune`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_eager_backward_strides`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_eager_tracing_correctness`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_epilogue_fused`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_flex_attention_backward_stride_ordering`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_flex_attention_logging`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`test_flex_attention_poison_mod_bwd`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)

### Imports

- **`Callable`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`CompileCounterWithBackend`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`EagerAndRecordGraphs`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`FileCheck`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`GetAttrKey`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`HAS_GPU`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`HAS_WARP_SPEC`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`Optional`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`PLATFORM_SUPPORTS_BF16`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`PagedAttention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`SDPBackend`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`TestCase`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`collections`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`collections.abc`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`common_utils`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`compile_fx`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`config`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`contextlib`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`contextmanager`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`core_aten_decompositions`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`dataclass`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`dataclasses`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`expectedFailure`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`functools`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`get_stride_order`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`has_triton`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`itertools`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`json`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`make_fx`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`namedtuple`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`os`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`partial`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`patch`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`product`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`random`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`return_and_correct_aliasing`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_and_get_code`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`run_tests`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`string`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`tempfile`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch._decomp`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch._dynamo.testing`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch._higher_order_ops.flex_attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch._inductor`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch._inductor.ir`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch._inductor.runtime.triton_compat`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch._inductor.test_case`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch._inductor.utils`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.fx.experimental.proxy_tensor`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.nn`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.nn.attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.nn.attention.experimental._paged_attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.nn.attention.flex_attention`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.testing`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.testing._internal`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.testing._internal.common_cuda`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.testing._internal.common_device_type`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.testing._internal.inductor_utils`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.utils._python_dispatch`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.utils._pytree`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.utils._triton`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`torch.utils.checkpoint`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`typing`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`unittest`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`unittest.mock`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)
- **`warnings`**: [test_flex_attention.py_docs.md](./test_flex_attention.py_docs.md)


## Keyword â†’ Section Map

The following sections in the documentation cover these topics:

- **File Metadata**: Basic file information
- **Original Source**: Complete source code
- **High-Level Overview**: Purpose and role
- **Detailed Analysis**: In-depth code analysis
- **Architecture & Design**: Design patterns and structure
- **Dependencies**: Related modules and imports
- **Performance Considerations**: Efficiency and optimization
- **Security & Safety**: Security analysis
- **Testing & Usage**: How to use and test

---

*Generated by PyTorch Repository Documentation System*
