# Keywords: test_attention.py

## Keyword Index

### A

- **ALL_GATHER**: Identifier found in `test_attention.py`
- **ALL_TO_ALL**: Identifier found in `test_attention.py`
- **Args**: Identifier found in `test_attention.py`
- **AttentionType**: Identifier found in `test_attention.py`
- **AuxOutput**: Identifier found in `test_attention.py`
- **AuxRequest**: Identifier found in `test_attention.py`
- **above**: Identifier found in `test_attention.py`
- **affiliates**: Identifier found in `test_attention.py`
- **all_to_all_single**: Identifier found in `test_attention.py`
- **allgather**: Identifier found in `test_attention.py`
- **allowed**: Identifier found in `test_attention.py`
- **alltoall**: Identifier found in `test_attention.py`
- **aot_eager**: Identifier found in `test_attention.py`
- **append**: Identifier found in `test_attention.py`
- **applied**: Identifier found in `test_attention.py`
- **apply**: Identifier found in `test_attention.py`
- **arange**: Identifier found in `test_attention.py`
- **args**: Identifier found in `test_attention.py`
- **argument**: Identifier found in `test_attention.py`
- **assembling**: Identifier found in `test_attention.py`
- **assert**: Identifier found in `test_attention.py`
- **assertDictEqual**: Identifier found in `test_attention.py`
- **assertEqual**: Identifier found in `test_attention.py`
- **assertRaisesRegex**: Identifier found in `test_attention.py`
- **assert_close**: Identifier found in `test_attention.py`
- **atol**: Identifier found in `test_attention.py`
- **attention**: Identifier found in `test_attention.py`
- **attention_type**: Identifier found in `test_attention.py`
- **attentions**: Identifier found in `test_attention.py`
- **attn_gym**: Identifier found in `test_attention.py`
- **avoid**: Identifier found in `test_attention.py`

### B

- **B**: Identifier found in `test_attention.py`
- **Besides**: Identifier found in `test_attention.py`
- **BlockMask**: Identifier found in `test_attention.py`
- **backend**: Identifier found in `test_attention.py`
- **backends**: Identifier found in `test_attention.py`
- **backward**: Identifier found in `test_attention.py`
- **baked**: Identifier found in `test_attention.py`
- **balance**: Identifier found in `test_attention.py`
- **balancer**: Identifier found in `test_attention.py`
- **batch**: Identifier found in `test_attention.py`
- **batch_idx**: Identifier found in `test_attention.py`
- **batch_size**: Identifier found in `test_attention.py`
- **batch_size_list**: Identifier found in `test_attention.py`
- **batched**: Identifier found in `test_attention.py`
- **batches**: Identifier found in `test_attention.py`
- **because**: Identifier found in `test_attention.py`
- **behavior**: Identifier found in `test_attention.py`
- **bfloat16**: Identifier found in `test_attention.py`
- **blob**: Identifier found in `test_attention.py`
- **block_mask**: Identifier found in `test_attention.py`
- **block_size**: Identifier found in `test_attention.py`
- **bool**: Identifier found in `test_attention.py`
- **broadcast**: Identifier found in `test_attention.py`
- **bs**: Identifier found in `test_attention.py`
- **buffer_seq_dims**: Identifier found in `test_attention.py`
- **buffers**: Identifier found in `test_attention.py`

### C

- **CPFlexAttentionTest**: Identifier found in `test_attention.py`
- **CPFlexAttentionTestWithLocalTensor**: Identifier found in `test_attention.py`
- **CUDNN_ATTENTION**: Identifier found in `test_attention.py`
- **Callable**: Identifier found in `test_attention.py`
- **ClassVar**: Identifier found in `test_attention.py`
- **CommDebugMode**: Identifier found in `test_attention.py`
- **Compile**: Identifier found in `test_attention.py`
- **Compiler**: Identifier found in `test_attention.py`
- **Context**: Identifier found in `test_attention.py`
- **Converts**: Identifier found in `test_attention.py`
- **Copyright**: Identifier found in `test_attention.py`
- **c10d**: Identifier found in `test_attention.py`
- **c10d_functional**: Identifier found in `test_attention.py`
- **cache_size_limit**: Identifier found in `test_attention.py`
- **case**: Identifier found in `test_attention.py`
- **causal_mask**: Identifier found in `test_attention.py`
- **change**: Identifier found in `test_attention.py`
- **choose**: Identifier found in `test_attention.py`
- **chunk**: Identifier found in `test_attention.py`
- **chunk_size**: Identifier found in `test_attention.py`
- **chunks**: Identifier found in `test_attention.py`
- **class**: Identifier found in `test_attention.py`
- **clone**: Identifier found in `test_attention.py`
- **collections**: Identifier found in `test_attention.py`
- **comm_mode**: Identifier found in `test_attention.py`
- **common_cuda**: Identifier found in `test_attention.py`
- **common_distributed**: Identifier found in `test_attention.py`
- **common_dtensor**: Identifier found in `test_attention.py`
- **common_utils**: Identifier found in `test_attention.py`
- **compilations**: Identifier found in `test_attention.py`
- **compile**: Identifier found in `test_attention.py`
- **compiled**: Identifier found in `test_attention.py`
- **compiled_create_block_mask**: Identifier found in `test_attention.py`
- **compiled_flex_attention**: Identifier found in `test_attention.py`
- **config**: Identifier found in `test_attention.py`
- **contain**: Identifier found in `test_attention.py`
- **contains**: Identifier found in `test_attention.py`
- **context_parallel**: Identifier found in `test_attention.py`
- **context_parallel_unshard**: Identifier found in `test_attention.py`
- **copied**: Identifier found in `test_attention.py`
- **correctly**: Identifier found in `test_attention.py`
- **counts**: Identifier found in `test_attention.py`
- **cp_aux**: Identifier found in `test_attention.py`
- **cp_block_mask**: Identifier found in `test_attention.py`
- **cp_context**: Identifier found in `test_attention.py`
- **cp_dk**: Identifier found in `test_attention.py`
- **cp_dq**: Identifier found in `test_attention.py`
- **cp_dv**: Identifier found in `test_attention.py`
- **cp_grad**: Identifier found in `test_attention.py`
- **cp_k**: Identifier found in `test_attention.py`
- **cp_lse**: Identifier found in `test_attention.py`
- **cp_out**: Identifier found in `test_attention.py`
- **cp_plan**: Identifier found in `test_attention.py`
- **cp_q**: Identifier found in `test_attention.py`
- **cp_qkv**: Identifier found in `test_attention.py`
- **cp_qkv_grad**: Identifier found in `test_attention.py`
- **cp_v**: Identifier found in `test_attention.py`
- **create_block_mask**: Identifier found in `test_attention.py`
- **create_local_tensor_test_class**: Identifier found in `test_attention.py`
- **cuda**: Identifier found in `test_attention.py`
- **cumsum**: Identifier found in `test_attention.py`
- **cumulative**: Identifier found in `test_attention.py`

### D

- **DTensorTestBase**: Identifier found in `test_attention.py`
- **DeviceMesh**: Identifier found in `test_attention.py`
- **Does**: Identifier found in `test_attention.py`
- **data**: Identifier found in `test_attention.py`
- **debug**: Identifier found in `test_attention.py`
- **demonstrates**: Identifier found in `test_attention.py`
- **denoting**: Identifier found in `test_attention.py`
- **destroy_pg_upon_exit**: Identifier found in `test_attention.py`
- **detach**: Identifier found in `test_attention.py`
- **device**: Identifier found in `test_attention.py`
- **device_count**: Identifier found in `test_attention.py`
- **device_mesh**: Identifier found in `test_attention.py`
- **device_type**: Identifier found in `test_attention.py`
- **dict**: Identifier found in `test_attention.py`
- **different**: Identifier found in `test_attention.py`
- **dim**: Identifier found in `test_attention.py`
- **directly**: Identifier found in `test_attention.py`
- **dispatch**: Identifier found in `test_attention.py`
- **dist**: Identifier found in `test_attention.py`
- **distribute**: Identifier found in `test_attention.py`
- **distributed**: Identifier found in `test_attention.py`
- **distributed_c10d**: Identifier found in `test_attention.py`
- **divisible**: Identifier found in `test_attention.py`
- **doc_count**: Identifier found in `test_attention.py`
- **doc_id**: Identifier found in `test_attention.py`
- **doc_ids**: Identifier found in `test_attention.py`
- **doc_mask_mod**: Identifier found in `test_attention.py`
- **document**: Identifier found in `test_attention.py`
- **document_causal_mask**: Identifier found in `test_attention.py`
- **document_id**: Identifier found in `test_attention.py`
- **document_lengths**: Identifier found in `test_attention.py`
- **document_mask**: Identifier found in `test_attention.py`
- **documents**: Identifier found in `test_attention.py`
- **does**: Identifier found in `test_attention.py`
- **dtype**: Identifier found in `test_attention.py`
- **dynamic**: Identifier found in `test_attention.py`

### E

- **EFFICIENT_ATTENTION**: Identifier found in `test_attention.py`
- **Each**: Identifier found in `test_attention.py`
- **Ensure**: Identifier found in `test_attention.py`
- **each**: Identifier found in `test_attention.py`
- **efficient**: Identifier found in `test_attention.py`
- **elements**: Identifier found in `test_attention.py`
- **elif**: Identifier found in `test_attention.py`
- **else**: Identifier found in `test_attention.py`
- **enable_load_balance**: Identifier found in `test_attention.py`
- **ensure**: Identifier found in `test_attention.py`
- **enum**: Identifier found in `test_attention.py`
- **enumerate**: Identifier found in `test_attention.py`
- **error**: Identifier found in `test_attention.py`
- **example**: Identifier found in `test_attention.py`
- **examples_k_v**: Identifier found in `test_attention.py`
- **exceeds_recompile_limit**: Identifier found in `test_attention.py`
- **expect_all2all_count**: Identifier found in `test_attention.py`
- **expect_aux**: Identifier found in `test_attention.py`
- **expect_out**: Identifier found in `test_attention.py`
- **experimental**: Identifier found in `test_attention.py`

### F

- **FLASH_ATTENTION**: Identifier found in `test_attention.py`
- **FLEX**: Identifier found in `test_attention.py`
- **False**: Identifier found in `test_attention.py`
- **Flex**: Identifier found in `test_attention.py`
- **FlexAttentionWrapper**: Identifier found in `test_attention.py`
- **fake**: Identifier found in `test_attention.py`
- **flash**: Identifier found in `test_attention.py`
- **flex**: Identifier found in `test_attention.py`
- **flex_attention**: Identifier found in `test_attention.py`
- **flex_attention_wrapper_module**: Identifier found in `test_attention.py`
- **flex_cp_allgather**: Identifier found in `test_attention.py`
- **float32**: Identifier found in `test_attention.py`
- **fn_eval**: Identifier found in `test_attention.py`
- **form**: Identifier found in `test_attention.py`
- **format**: Identifier found in `test_attention.py`
- **forward**: Identifier found in `test_attention.py`
- **freqs_cis**: Identifier found in `test_attention.py`
- **freqs_cis_shard**: Identifier found in `test_attention.py`
- **friendly**: Identifier found in `test_attention.py`
- **from**: Identifier found in `test_attention.py`
- **fullgraph**: Identifier found in `test_attention.py`
- **fully**: Identifier found in `test_attention.py`
- **function**: Identifier found in `test_attention.py`
- **functional**: Identifier found in `test_attention.py`

### G

- **Generate**: Identifier found in `test_attention.py`
- **Generates**: Identifier found in `test_attention.py`
- **generate**: Identifier found in `test_attention.py`
- **generate_doc_mask_mod**: Identifier found in `test_attention.py`
- **generate_random_lengths**: Identifier found in `test_attention.py`
- **generate_random_lengths_in_chunks**: Identifier found in `test_attention.py`
- **get_comm_counts**: Identifier found in `test_attention.py`
- **get_group**: Identifier found in `test_attention.py`
- **github**: Identifier found in `test_attention.py`
- **global**: Identifier found in `test_attention.py`
- **grad**: Identifier found in `test_attention.py`
- **gradient**: Identifier found in `test_attention.py`
- **group_size**: Identifier found in `test_attention.py`

### H

- **H**: Identifier found in `test_attention.py`
- **have**: Identifier found in `test_attention.py`
- **https**: Identifier found in `test_attention.py`

### I

- **IS_CAUSAL**: Identifier found in `test_attention.py`
- **Initialize**: Identifier found in `test_attention.py`
- **i**: Identifier found in `test_attention.py`
- **implementation**: Identifier found in `test_attention.py`
- **import**: Identifier found in `test_attention.py`
- **increase**: Identifier found in `test_attention.py`
- **index**: Identifier found in `test_attention.py`
- **init_device_mesh**: Identifier found in `test_attention.py`
- **initialization**: Identifier found in `test_attention.py`
- **initialize**: Identifier found in `test_attention.py`
- **inner_mask**: Identifier found in `test_attention.py`
- **input**: Identifier found in `test_attention.py`
- **inputs**: Identifier found in `test_attention.py`
- **instead**: Identifier found in `test_attention.py`
- **int**: Identifier found in `test_attention.py`
- **int32**: Identifier found in `test_attention.py`
- **into**: Identifier found in `test_attention.py`
- **introduces**: Identifier found in `test_attention.py`
- **is_causal**: Identifier found in `test_attention.py`
- **isinstance**: Identifier found in `test_attention.py`
- **iters**: Identifier found in `test_attention.py`
- **itertools**: Identifier found in `test_attention.py`

### J

- **just**: Identifier found in `test_attention.py`

### K

- **KV_LEN**: Identifier found in `test_attention.py`
- **k**: Identifier found in `test_attention.py`
- **k_shard**: Identifier found in `test_attention.py`
- **kernels**: Identifier found in `test_attention.py`
- **kv_idx**: Identifier found in `test_attention.py`
- **kv_logical**: Identifier found in `test_attention.py`
- **kwargs**: Identifier found in `test_attention.py`

### L

- **lambda**: Identifier found in `test_attention.py`
- **large**: Identifier found in `test_attention.py`
- **lb**: Identifier found in `test_attention.py`
- **lb_type**: Identifier found in `test_attention.py`
- **least**: Identifier found in `test_attention.py`
- **length**: Identifier found in `test_attention.py`
- **length_to_offsets**: Identifier found in `test_attention.py`
- **lengths**: Identifier found in `test_attention.py`
- **lengths_in_batch**: Identifier found in `test_attention.py`
- **library**: Identifier found in `test_attention.py`
- **list**: Identifier found in `test_attention.py`
- **load**: Identifier found in `test_attention.py`
- **load_balance**: Identifier found in `test_attention.py`
- **load_balance_type**: Identifier found in `test_attention.py`
- **load_balance_type_list**: Identifier found in `test_attention.py`
- **load_balancer**: Identifier found in `test_attention.py`
- **local**: Identifier found in `test_attention.py`
- **logic**: Identifier found in `test_attention.py`
- **loop**: Identifier found in `test_attention.py`
- **lse**: Identifier found in `test_attention.py`

### M

- **Meta**: Identifier found in `test_attention.py`
- **Mismatched**: Identifier found in `test_attention.py`
- **Missing**: Identifier found in `test_attention.py`
- **Module**: Identifier found in `test_attention.py`
- **main**: Identifier found in `test_attention.py`
- **make**: Identifier found in `test_attention.py`
- **manual_seed**: Identifier found in `test_attention.py`
- **map_local_tensor_for_rank**: Identifier found in `test_attention.py`
- **mapping**: Identifier found in `test_attention.py`
- **mask**: Identifier found in `test_attention.py`
- **mask_mod**: Identifier found in `test_attention.py`
- **masking**: Identifier found in `test_attention.py`
- **masks**: Identifier found in `test_attention.py`
- **max_seq_len**: Identifier found in `test_attention.py`
- **max_seq_len_list**: Identifier found in `test_attention.py`
- **means**: Identifier found in `test_attention.py`
- **merge**: Identifier found in `test_attention.py`
- **mesh**: Identifier found in `test_attention.py`
- **mesh_dim_names**: Identifier found in `test_attention.py`
- **mesh_shape**: Identifier found in `test_attention.py`
- **meta**: Identifier found in `test_attention.py`
- **mode**: Identifier found in `test_attention.py`
- **model**: Identifier found in `test_attention.py`
- **mods**: Identifier found in `test_attention.py`
- **monkey**: Identifier found in `test_attention.py`
- **multiple**: Identifier found in `test_attention.py`
- **must**: Identifier found in `test_attention.py`

### N

- **NOTE**: Identifier found in `test_attention.py`
- **NOT_IS_CAUSAL**: Identifier found in `test_attention.py`
- **Need**: Identifier found in `test_attention.py`
- **None**: Identifier found in `test_attention.py`
- **NotImplementedError**: Identifier found in `test_attention.py`
- **Note**: Identifier found in `test_attention.py`
- **need**: Identifier found in `test_attention.py`
- **nheads**: Identifier found in `test_attention.py`
- **no_grad**: Identifier found in `test_attention.py`
- **num_chunks**: Identifier found in `test_attention.py`
- **num_chunks_per_document**: Identifier found in `test_attention.py`
- **num_documents**: Identifier found in `test_attention.py`
- **num_of_sub_test_runs**: Identifier found in `test_attention.py`
- **number**: Identifier found in `test_attention.py`
- **numerical**: Identifier found in `test_attention.py`

### O

- **Optional**: Identifier found in `test_attention.py`
- **Owner**: Identifier found in `test_attention.py`
- **object**: Identifier found in `test_attention.py`
- **offsets**: Identifier found in `test_attention.py`
- **oncall**: Identifier found in `test_attention.py`
- **ones**: Identifier found in `test_attention.py`
- **only**: Identifier found in `test_attention.py`
- **opcheck**: Identifier found in `test_attention.py`
- **order**: Identifier found in `test_attention.py`
- **out**: Identifier found in `test_attention.py`
- **output**: Identifier found in `test_attention.py`

### P

- **PLATFORM_SUPPORTS_CUDNN_ATTENTION**: Identifier found in `test_attention.py`
- **PLATFORM_SUPPORTS_FLASH_ATTENTION**: Identifier found in `test_attention.py`
- **PLATFORM_SUPPORTS_FUSED_ATTENTION**: Identifier found in `test_attention.py`
- **PLATFORM_SUPPORTS_MEM_EFF_ATTENTION**: Identifier found in `test_attention.py`
- **Parallel**: Identifier found in `test_attention.py`
- **Platforms**: Identifier found in `test_attention.py`
- **Prepare**: Identifier found in `test_attention.py`
- **parallel**: Identifier found in `test_attention.py`
- **parallelize_module**: Identifier found in `test_attention.py`
- **parameters**: Identifier found in `test_attention.py`
- **patching**: Identifier found in `test_attention.py`
- **product**: Identifier found in `test_attention.py`
- **proper**: Identifier found in `test_attention.py`
- **property**: Identifier found in `test_attention.py`
- **pytorch**: Identifier found in `test_attention.py`

### Q

- **Q_LEN**: Identifier found in `test_attention.py`
- **q**: Identifier found in `test_attention.py`
- **q_idx**: Identifier found in `test_attention.py`
- **q_logical**: Identifier found in `test_attention.py`
- **q_shard**: Identifier found in `test_attention.py`
- **qkv**: Identifier found in `test_attention.py`
- **qkv_grad**: Identifier found in `test_attention.py`
- **qkv_size**: Identifier found in `test_attention.py`

### R

- **Randomly**: Identifier found in `test_attention.py`
- **RingAttentionTest**: Identifier found in `test_attention.py`
- **RingAttentionTestWithLocalTensor**: Identifier found in `test_attention.py`
- **raise**: Identifier found in `test_attention.py`
- **rand**: Identifier found in `test_attention.py`
- **randint**: Identifier found in `test_attention.py`
- **randn**: Identifier found in `test_attention.py`
- **random**: Identifier found in `test_attention.py`
- **range**: Identifier found in `test_attention.py`
- **rank**: Identifier found in `test_attention.py`
- **ranks**: Identifier found in `test_attention.py`
- **reality**: Identifier found in `test_attention.py`
- **referenced**: Identifier found in `test_attention.py`
- **reliable**: Identifier found in `test_attention.py`
- **remaining**: Identifier found in `test_attention.py`
- **remaining_chunks**: Identifier found in `test_attention.py`
- **remaining_length**: Identifier found in `test_attention.py`
- **repeat_interleave**: Identifier found in `test_attention.py`
- **require_grad**: Identifier found in `test_attention.py`
- **required**: Identifier found in `test_attention.py`
- **requires_grad**: Identifier found in `test_attention.py`
- **reshape**: Identifier found in `test_attention.py`
- **resize_**: Identifier found in `test_attention.py`
- **return**: Identifier found in `test_attention.py`
- **return_aux**: Identifier found in `test_attention.py`
- **rewrite**: Identifier found in `test_attention.py`
- **rotate_method**: Identifier found in `test_attention.py`
- **rotater**: Identifier found in `test_attention.py`
- **rotater_enum_to_str**: Identifier found in `test_attention.py`
- **rtol**: Identifier found in `test_attention.py`
- **run_subtests**: Identifier found in `test_attention.py`
- **run_tests**: Identifier found in `test_attention.py`

### S

- **SDPA**: Identifier found in `test_attention.py`
- **SDPAWrapper**: Identifier found in `test_attention.py`
- **SDPBackend**: Identifier found in `test_attention.py`
- **SKIP**: Identifier found in `test_attention.py`
- **same**: Identifier found in `test_attention.py`
- **same_doc**: Identifier found in `test_attention.py`
- **scaled_dot_product_attention**: Identifier found in `test_attention.py`
- **scope**: Identifier found in `test_attention.py`
- **scores**: Identifier found in `test_attention.py`
- **sdpa**: Identifier found in `test_attention.py`
- **sdpa_kernel**: Identifier found in `test_attention.py`
- **seed**: Identifier found in `test_attention.py`
- **self**: Identifier found in `test_attention.py`
- **seq_dim**: Identifier found in `test_attention.py`
- **seq_dims**: Identifier found in `test_attention.py`
- **seq_len**: Identifier found in `test_attention.py`
- **seq_length**: Identifier found in `test_attention.py`
- **seq_length_list**: Identifier found in `test_attention.py`
- **sequence**: Identifier found in `test_attention.py`
- **sequences**: Identifier found in `test_attention.py`
- **set_rotate_method**: Identifier found in `test_attention.py`
- **shape**: Identifier found in `test_attention.py`
- **shard**: Identifier found in `test_attention.py`
- **should**: Identifier found in `test_attention.py`
- **single**: Identifier found in `test_attention.py`
- **size**: Identifier found in `test_attention.py`
- **skipIf**: Identifier found in `test_attention.py`
- **skipIfRocm**: Identifier found in `test_attention.py`
- **skip_if_lt_x_gpu**: Identifier found in `test_attention.py`
- **skipped_tests**: Identifier found in `test_attention.py`
- **small**: Identifier found in `test_attention.py`
- **some**: Identifier found in `test_attention.py`
- **src**: Identifier found in `test_attention.py`
- **stack**: Identifier found in `test_attention.py`
- **stacked**: Identifier found in `test_attention.py`
- **string**: Identifier found in `test_attention.py`
- **subtest**: Identifier found in `test_attention.py`
- **super**: Identifier found in `test_attention.py`
- **support**: Identifier found in `test_attention.py`
- **supported**: Identifier found in `test_attention.py`

### T

- **TODO**: Identifier found in `test_attention.py`
- **Tensor**: Identifier found in `test_attention.py`
- **TestCPCustomOps**: Identifier found in `test_attention.py`
- **TestCPCustomOpsWithLocalTensor**: Identifier found in `test_attention.py`
- **TestSharding**: Identifier found in `test_attention.py`
- **TestShardingWithLocalTensor**: Identifier found in `test_attention.py`
- **Theoretically**: Identifier found in `test_attention.py`
- **This**: Identifier found in `test_attention.py`
- **True**: Identifier found in `test_attention.py`
- **take**: Identifier found in `test_attention.py`
- **target**: Identifier found in `test_attention.py`
- **tensor**: Identifier found in `test_attention.py`
- **tensors**: Identifier found in `test_attention.py`
- **test**: Identifier found in `test_attention.py`
- **test_context_parallel_shard**: Identifier found in `test_attention.py`
- **test_cp_flex_attention_causal_mask**: Identifier found in `test_attention.py`
- **test_cp_flex_attention_document_mask**: Identifier found in `test_attention.py`
- **test_flex_cp_custom_op**: Identifier found in `test_attention.py`
- **test_forward_only**: Identifier found in `test_attention.py`
- **test_is_causal_behavior**: Identifier found in `test_attention.py`
- **test_ring_attention_sdpa**: Identifier found in `test_attention.py`
- **testing**: Identifier found in `test_attention.py`
- **that**: Identifier found in `test_attention.py`
- **them**: Identifier found in `test_attention.py`
- **then**: Identifier found in `test_attention.py`
- **this**: Identifier found in `test_attention.py`
- **together**: Identifier found in `test_attention.py`
- **token**: Identifier found in `test_attention.py`
- **tokens**: Identifier found in `test_attention.py`
- **torch**: Identifier found in `test_attention.py`
- **total**: Identifier found in `test_attention.py`
- **total_length**: Identifier found in `test_attention.py`
- **tuple**: Identifier found in `test_attention.py`
- **type**: Identifier found in `test_attention.py`
- **typing**: Identifier found in `test_attention.py`

### U

- **unittest**: Identifier found in `test_attention.py`
- **unshard**: Identifier found in `test_attention.py`
- **use_context**: Identifier found in `test_attention.py`
- **use_deterministic_algorithms**: Identifier found in `test_attention.py`
- **used**: Identifier found in `test_attention.py`

### V

- **ValueError**: Identifier found in `test_attention.py`
- **v**: Identifier found in `test_attention.py`
- **v_shard**: Identifier found in `test_attention.py`
- **vars**: Identifier found in `test_attention.py`

### W

- **What**: Identifier found in `test_attention.py`
- **When**: Identifier found in `test_attention.py`
- **well**: Identifier found in `test_attention.py`
- **when**: Identifier found in `test_attention.py`
- **which**: Identifier found in `test_attention.py`
- **will**: Identifier found in `test_attention.py`
- **with**: Identifier found in `test_attention.py`
- **with_comms**: Identifier found in `test_attention.py`
- **within**: Identifier found in `test_attention.py`
- **work**: Identifier found in `test_attention.py`
- **world_size**: Identifier found in `test_attention.py`

### _

- **__init__**: Identifier found in `test_attention.py`
- **__name__**: Identifier found in `test_attention.py`
- **_get_load_balancer**: Identifier found in `test_attention.py`
- **_offsets_to_doc_ids_tensor**: Identifier found in `test_attention.py`
- **_ring_attention_sdpa**: Identifier found in `test_attention.py`
- **_test_cp_flex_attention**: Identifier found in `test_attention.py`
- **_test_ring_attention_sdpa**: Identifier found in `test_attention.py`

