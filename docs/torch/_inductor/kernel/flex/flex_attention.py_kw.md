# Keywords: flex_attention.py

## Keyword Index

### 1

- **128**: Identifier found in `flex_attention.py`

### A

- **Args**: Identifier found in `flex_attention.py`
- **added**: Identifier found in `flex_attention.py`
- **additional**: Identifier found in `flex_attention.py`
- **all_joint_outputs**: Identifier found in `flex_attention.py`
- **allow**: Identifier found in `flex_attention.py`
- **also**: Identifier found in `flex_attention.py`
- **always**: Identifier found in `flex_attention.py`
- **analyze**: Identifier found in `flex_attention.py`
- **annotations**: Identifier found in `flex_attention.py`
- **apply**: Identifier found in `flex_attention.py`
- **args**: Identifier found in `flex_attention.py`
- **assert**: Identifier found in `flex_attention.py`
- **assignment**: Identifier found in `flex_attention.py`
- **aten**: Identifier found in `flex_attention.py`
- **atomic**: Identifier found in `flex_attention.py`
- **attempting**: Identifier found in `flex_attention.py`
- **attention**: Identifier found in `flex_attention.py`
- **attrib**: Identifier found in `flex_attention.py`
- **autotune_select_algorithm**: Identifier found in `flex_attention.py`
- **autotuning**: Identifier found in `flex_attention.py`
- **axis**: Identifier found in `flex_attention.py`

### B

- **B**: Identifier found in `flex_attention.py`
- **BLOCK_M**: Identifier found in `flex_attention.py`
- **BLOCK_M1**: Identifier found in `flex_attention.py`
- **BLOCK_M2**: Identifier found in `flex_attention.py`
- **BLOCK_N**: Identifier found in `flex_attention.py`
- **BLOCK_N1**: Identifier found in `flex_attention.py`
- **BLOCK_N2**: Identifier found in `flex_attention.py`
- **Backward**: Identifier found in `flex_attention.py`
- **Base**: Identifier found in `flex_attention.py`
- **Bkv**: Identifier found in `flex_attention.py`
- **Blocksparse**: Identifier found in `flex_attention.py`
- **Bq**: Identifier found in `flex_attention.py`
- **backends**: Identifier found in `flex_attention.py`
- **backward**: Identifier found in `flex_attention.py`
- **batch**: Identifier found in `flex_attention.py`
- **batch_size**: Identifier found in `flex_attention.py`
- **because**: Identifier found in `flex_attention.py`
- **before**: Identifier found in `flex_attention.py`
- **below**: Identifier found in `flex_attention.py`
- **bias**: Identifier found in `flex_attention.py`
- **bias1**: Identifier found in `flex_attention.py`
- **block**: Identifier found in `flex_attention.py`
- **block_m**: Identifier found in `flex_attention.py`
- **block_m1**: Identifier found in `flex_attention.py`
- **block_m2**: Identifier found in `flex_attention.py`
- **block_mask**: Identifier found in `flex_attention.py`
- **block_n**: Identifier found in `flex_attention.py`
- **block_n1**: Identifier found in `flex_attention.py`
- **block_n2**: Identifier found in `flex_attention.py`
- **blocks**: Identifier found in `flex_attention.py`
- **broadcast**: Identifier found in `flex_attention.py`
- **broadcastable**: Identifier found in `flex_attention.py`
- **broadcasted_grad_key**: Identifier found in `flex_attention.py`
- **broadcasted_grad_value**: Identifier found in `flex_attention.py`
- **buffer**: Identifier found in `flex_attention.py`
- **buffers**: Identifier found in `flex_attention.py`
- **build_subgraph_buffer**: Identifier found in `flex_attention.py`
- **build_subgraphs**: Identifier found in `flex_attention.py`
- **bwd_**: Identifier found in `flex_attention.py`

### C

- **CPP**: Identifier found in `flex_attention.py`
- **ComputedBuffer**: Identifier found in `flex_attention.py`
- **Construct**: Identifier found in `flex_attention.py`
- **Create**: Identifier found in `flex_attention.py`
- **Currently**: Identifier found in `flex_attention.py`
- **calculating**: Identifier found in `flex_attention.py`
- **call_function**: Identifier found in `flex_attention.py`
- **call_sizes**: Identifier found in `flex_attention.py`
- **captured**: Identifier found in `flex_attention.py`
- **captured_grads**: Identifier found in `flex_attention.py`
- **captured_grads_compute**: Identifier found in `flex_attention.py`
- **cdiv**: Identifier found in `flex_attention.py`
- **ceil_div**: Identifier found in `flex_attention.py`
- **checks**: Identifier found in `flex_attention.py`
- **choices**: Identifier found in `flex_attention.py`
- **class**: Identifier found in `flex_attention.py`
- **clone**: Identifier found in `flex_attention.py`
- **collections**: Identifier found in `flex_attention.py`
- **common**: Identifier found in `flex_attention.py`
- **compute**: Identifier found in `flex_attention.py`
- **computed**: Identifier found in `flex_attention.py`
- **conf**: Identifier found in `flex_attention.py`
- **config**: Identifier found in `flex_attention.py`
- **configs**: Identifier found in `flex_attention.py`
- **constraint**: Identifier found in `flex_attention.py`
- **containing**: Identifier found in `flex_attention.py`
- **continue**: Identifier found in `flex_attention.py`
- **copy**: Identifier found in `flex_attention.py`
- **create**: Identifier found in `flex_attention.py`
- **create_flex_decoding_kernel**: Identifier found in `flex_attention.py`
- **create_flex_flash_attention_kernel**: Identifier found in `flex_attention.py`
- **create_indices_fake**: Identifier found in `flex_attention.py`
- **create_num_blocks_fake_generator**: Identifier found in `flex_attention.py`
- **create_placeholder**: Identifier found in `flex_attention.py`
- **cuda**: Identifier found in `flex_attention.py`
- **cur_kernel_options**: Identifier found in `flex_attention.py`
- **currently**: Identifier found in `flex_attention.py`
- **custom**: Identifier found in `flex_attention.py`

### D

- **Decode**: Identifier found in `flex_attention.py`
- **Default**: Identifier found in `flex_attention.py`
- **Determine**: Identifier found in `flex_attention.py`
- **d_model**: Identifier found in `flex_attention.py`
- **data**: Identifier found in `flex_attention.py`
- **dataclass**: Identifier found in `flex_attention.py`
- **dataclasses**: Identifier found in `flex_attention.py`
- **default**: Identifier found in `flex_attention.py`
- **defs**: Identifier found in `flex_attention.py`
- **delete**: Identifier found in `flex_attention.py`
- **delta**: Identifier found in `flex_attention.py`
- **design**: Identifier found in `flex_attention.py`
- **device**: Identifier found in `flex_attention.py`
- **dict**: Identifier found in `flex_attention.py`
- **different**: Identifier found in `flex_attention.py`
- **dimension**: Identifier found in `flex_attention.py`
- **divisible**: Identifier found in `flex_attention.py`
- **does**: Identifier found in `flex_attention.py`
- **doesn**: Identifier found in `flex_attention.py`
- **dtype**: Identifier found in `flex_attention.py`
- **during**: Identifier found in `flex_attention.py`

### E

- **E**: Identifier found in `flex_attention.py`
- **Each**: Identifier found in `flex_attention.py`
- **Ev**: Identifier found in `flex_attention.py`
- **Expr**: Identifier found in `flex_attention.py`
- **ExternKernel**: Identifier found in `flex_attention.py`
- **either**: Identifier found in `flex_attention.py`
- **eliminate_dead_code**: Identifier found in `flex_attention.py`
- **else**: Identifier found in `flex_attention.py`
- **embedding**: Identifier found in `flex_attention.py`
- **empty**: Identifier found in `flex_attention.py`
- **empty_strided**: Identifier found in `flex_attention.py`
- **enable_gqa**: Identifier found in `flex_attention.py`
- **error**: Identifier found in `flex_attention.py`
- **errors**: Identifier found in `flex_attention.py`
- **evaluate_expr**: Identifier found in `flex_attention.py`
- **example**: Identifier found in `flex_attention.py`
- **explicitly**: Identifier found in `flex_attention.py`
- **extract**: Identifier found in `flex_attention.py`

### F

- **FLOAT32_PRECISION**: Identifier found in `flex_attention.py`
- **False**: Identifier found in `flex_attention.py`
- **FixedLayout**: Identifier found in `flex_attention.py`
- **Flex**: Identifier found in `flex_attention.py`
- **FlexBwDConfig**: Identifier found in `flex_attention.py`
- **FlexConfig**: Identifier found in `flex_attention.py`
- **factor**: Identifier found in `flex_attention.py`
- **false**: Identifier found in `flex_attention.py`
- **fill**: Identifier found in `flex_attention.py`
- **filter**: Identifier found in `flex_attention.py`
- **final**: Identifier found in `flex_attention.py`
- **flex**: Identifier found in `flex_attention.py`
- **flex_attention**: Identifier found in `flex_attention.py`
- **flex_attention_backward**: Identifier found in `flex_attention.py`
- **flex_attention_backward_grid**: Identifier found in `flex_attention.py`
- **flex_attention_backward_template**: Identifier found in `flex_attention.py`
- **flex_attention_grid**: Identifier found in `flex_attention.py`
- **flex_attention_template**: Identifier found in `flex_attention.py`
- **flex_backwards**: Identifier found in `flex_attention.py`
- **flex_cpu**: Identifier found in `flex_attention.py`
- **flex_decoding**: Identifier found in `flex_attention.py`
- **flex_flash_attention**: Identifier found in `flex_attention.py`
- **flex_lib**: Identifier found in `flex_attention.py`
- **float32**: Identifier found in `flex_attention.py`
- **forward**: Identifier found in `flex_attention.py`
- **fp32**: Identifier found in `flex_attention.py`
- **fp32_precision**: Identifier found in `flex_attention.py`
- **freeze_irnodes**: Identifier found in `flex_attention.py`
- **from**: Identifier found in `flex_attention.py`
- **frozen**: Identifier found in `flex_attention.py`
- **full_kv_indices**: Identifier found in `flex_attention.py`
- **full_kv_num_blocks**: Identifier found in `flex_attention.py`
- **full_q_indices**: Identifier found in `flex_attention.py`
- **full_q_num_blocks**: Identifier found in `flex_attention.py`
- **function**: Identifier found in `flex_attention.py`
- **fw_graph**: Identifier found in `flex_attention.py`
- **fw_subgraph_buffer**: Identifier found in `flex_attention.py`
- **fwd_**: Identifier found in `flex_attention.py`
- **fwd_placeholder_inps**: Identifier found in `flex_attention.py`

### G

- **GQA**: Identifier found in `flex_attention.py`
- **GQA_SHARED_HEADS**: Identifier found in `flex_attention.py`
- **Graph**: Identifier found in `flex_attention.py`
- **getLogger**: Identifier found in `flex_attention.py`
- **get_buffer**: Identifier found in `flex_attention.py`
- **get_bwd_subgraph_outputs**: Identifier found in `flex_attention.py`
- **get_device**: Identifier found in `flex_attention.py`
- **get_dtype**: Identifier found in `flex_attention.py`
- **get_flex_attention_bwd_configs**: Identifier found in `flex_attention.py`
- **get_flex_attention_fwd_configs**: Identifier found in `flex_attention.py`
- **get_float32_matmul_precision**: Identifier found in `flex_attention.py`
- **get_float32_precision**: Identifier found in `flex_attention.py`
- **get_fwd_subgraph_outputs**: Identifier found in `flex_attention.py`
- **get_out**: Identifier found in `flex_attention.py`
- **get_size**: Identifier found in `flex_attention.py`
- **get_stride**: Identifier found in `flex_attention.py`
- **getattr**: Identifier found in `flex_attention.py`
- **gqa_shared_heads**: Identifier found in `flex_attention.py`
- **grab**: Identifier found in `flex_attention.py`
- **grad**: Identifier found in `flex_attention.py`
- **grad_input**: Identifier found in `flex_attention.py`
- **grad_key**: Identifier found in `flex_attention.py`
- **grad_logsumexp**: Identifier found in `flex_attention.py`
- **grad_lse_exp2**: Identifier found in `flex_attention.py`
- **grad_out**: Identifier found in `flex_attention.py`
- **grad_query**: Identifier found in `flex_attention.py`
- **grad_query_strides**: Identifier found in `flex_attention.py`
- **grad_score_mod**: Identifier found in `flex_attention.py`
- **grad_value**: Identifier found in `flex_attention.py`
- **gradients**: Identifier found in `flex_attention.py`
- **grads_compute**: Identifier found in `flex_attention.py`
- **grads_out**: Identifier found in `flex_attention.py`
- **graph**: Identifier found in `flex_attention.py`
- **graph_module**: Identifier found in `flex_attention.py`
- **graphs**: Identifier found in `flex_attention.py`
- **greater**: Identifier found in `flex_attention.py`
- **grid**: Identifier found in `flex_attention.py`
- **guard_int**: Identifier found in `flex_attention.py`
- **guards**: Identifier found in `flex_attention.py`

### H

- **HAS_FULL_BLOCKS**: Identifier found in `flex_attention.py`
- **HOP**: Identifier found in `flex_attention.py`
- **happens**: Identifier found in `flex_attention.py`
- **hard**: Identifier found in `flex_attention.py`
- **has_full_blocks**: Identifier found in `flex_attention.py`
- **hasattr**: Identifier found in `flex_attention.py`
- **have**: Identifier found in `flex_attention.py`
- **head_dim**: Identifier found in `flex_attention.py`
- **heads_ratio**: Identifier found in `flex_attention.py`
- **here**: Identifier found in `flex_attention.py`
- **heuristics**: Identifier found in `flex_attention.py`
- **higher_order**: Identifier found in `flex_attention.py`
- **highest**: Identifier found in `flex_attention.py`

### I

- **IRNode**: Identifier found in `flex_attention.py`
- **IS_DIVISIBLE**: Identifier found in `flex_attention.py`
- **Implementation**: Identifier found in `flex_attention.py`
- **Inside**: Identifier found in `flex_attention.py`
- **ieee**: Identifier found in `flex_attention.py`
- **ignore**: Identifier found in `flex_attention.py`
- **implicitly**: Identifier found in `flex_attention.py`
- **import**: Identifier found in `flex_attention.py`
- **indexed**: Identifier found in `flex_attention.py`
- **indexing**: Identifier found in `flex_attention.py`
- **infer_dense_strides**: Identifier found in `flex_attention.py`
- **inlining**: Identifier found in `flex_attention.py`
- **input**: Identifier found in `flex_attention.py`
- **input_gen_fns**: Identifier found in `flex_attention.py`
- **input_nodes**: Identifier found in `flex_attention.py`
- **inputs**: Identifier found in `flex_attention.py`
- **inputs_for_autotuning**: Identifier found in `flex_attention.py`
- **int32**: Identifier found in `flex_attention.py`
- **into**: Identifier found in `flex_attention.py`
- **invariant**: Identifier found in `flex_attention.py`
- **is_available**: Identifier found in `flex_attention.py`
- **isinstance**: Identifier found in `flex_attention.py`
- **items**: Identifier found in `flex_attention.py`
- **iterable**: Identifier found in `flex_attention.py`
- **iterating**: Identifier found in `flex_attention.py`

### J

- **JointOutputResult**: Identifier found in `flex_attention.py`
- **joint**: Identifier found in `flex_attention.py`
- **joint_buffer**: Identifier found in `flex_attention.py`
- **joint_graph**: Identifier found in `flex_attention.py`
- **joint_output_buffers**: Identifier found in `flex_attention.py`
- **joint_outputs**: Identifier found in `flex_attention.py`
- **joint_placeholder_inps**: Identifier found in `flex_attention.py`
- **joint_subgraph_buffer**: Identifier found in `flex_attention.py`

### K

- **KV_BLOCK_SIZE**: Identifier found in `flex_attention.py`
- **Kernel**: Identifier found in `flex_attention.py`
- **k_head_dim**: Identifier found in `flex_attention.py`
- **keepdims**: Identifier found in `flex_attention.py`
- **kernargs**: Identifier found in `flex_attention.py`
- **kernel**: Identifier found in `flex_attention.py`
- **kernel_options**: Identifier found in `flex_attention.py`
- **kernels**: Identifier found in `flex_attention.py`
- **key_size**: Identifier found in `flex_attention.py`
- **key_strides**: Identifier found in `flex_attention.py`
- **key_value_block_size**: Identifier found in `flex_attention.py`
- **keys**: Identifier found in `flex_attention.py`
- **kpack**: Identifier found in `flex_attention.py`
- **kv_block_size**: Identifier found in `flex_attention.py`
- **kv_heads**: Identifier found in `flex_attention.py`
- **kv_idx**: Identifier found in `flex_attention.py`
- **kv_indices**: Identifier found in `flex_attention.py`
- **kv_length**: Identifier found in `flex_attention.py`
- **kv_num_blocks**: Identifier found in `flex_attention.py`
- **kwargs**: Identifier found in `flex_attention.py`

### L

- **List**: Identifier found in `flex_attention.py`
- **Lowering**: Identifier found in `flex_attention.py`
- **layout**: Identifier found in `flex_attention.py`
- **layout_broadcasted_k**: Identifier found in `flex_attention.py`
- **least**: Identifier found in `flex_attention.py`
- **length**: Identifier found in `flex_attention.py`
- **less**: Identifier found in `flex_attention.py`
- **lets**: Identifier found in `flex_attention.py`
- **like**: Identifier found in `flex_attention.py`
- **list**: Identifier found in `flex_attention.py`
- **load_flex_template**: Identifier found in `flex_attention.py`
- **log**: Identifier found in `flex_attention.py`
- **logging**: Identifier found in `flex_attention.py`
- **logsumexp**: Identifier found in `flex_attention.py`
- **logsumexp_shape**: Identifier found in `flex_attention.py`
- **lower**: Identifier found in `flex_attention.py`
- **lower_cpu**: Identifier found in `flex_attention.py`
- **lowering**: Identifier found in `flex_attention.py`
- **lowerings**: Identifier found in `flex_attention.py`

### M

- **Mark**: Identifier found in `flex_attention.py`
- **main**: Identifier found in `flex_attention.py`
- **mask_graph**: Identifier found in `flex_attention.py`
- **mask_graph_buffer**: Identifier found in `flex_attention.py`
- **mask_graph_placeholder_inps**: Identifier found in `flex_attention.py`
- **mask_mod_other_buffers**: Identifier found in `flex_attention.py`
- **masking**: Identifier found in `flex_attention.py`
- **match**: Identifier found in `flex_attention.py`
- **matching**: Identifier found in `flex_attention.py`
- **math**: Identifier found in `flex_attention.py`
- **matmul**: Identifier found in `flex_attention.py`
- **matrix_instr_nonkdim**: Identifier found in `flex_attention.py`
- **max_scores**: Identifier found in `flex_attention.py`
- **maybe_append_choice**: Identifier found in `flex_attention.py`
- **maybe_realize**: Identifier found in `flex_attention.py`
- **memory**: Identifier found in `flex_attention.py`
- **messages**: Identifier found in `flex_attention.py`
- **meta**: Identifier found in `flex_attention.py`
- **mtia**: Identifier found in `flex_attention.py`
- **mul_delta**: Identifier found in `flex_attention.py`
- **multiple**: Identifier found in `flex_attention.py`
- **must**: Identifier found in `flex_attention.py`
- **mutated_grads**: Identifier found in `flex_attention.py`
- **mutated_inputs**: Identifier found in `flex_attention.py`
- **mypy**: Identifier found in `flex_attention.py`

### N

- **NOTE**: Identifier found in `flex_attention.py`
- **NYI**: Identifier found in `flex_attention.py`
- **Need**: Identifier found in `flex_attention.py`
- **None**: Identifier found in `flex_attention.py`
- **NotImplementedError**: Identifier found in `flex_attention.py`
- **Note**: Identifier found in `flex_attention.py`
- **n_kv**: Identifier found in `flex_attention.py`
- **n_queries**: Identifier found in `flex_attention.py`
- **name**: Identifier found in `flex_attention.py`
- **need**: Identifier found in `flex_attention.py`
- **needed**: Identifier found in `flex_attention.py`
- **nice**: Identifier found in `flex_attention.py`
- **nicer**: Identifier found in `flex_attention.py`
- **node**: Identifier found in `flex_attention.py`
- **nodes**: Identifier found in `flex_attention.py`
- **none**: Identifier found in `flex_attention.py`
- **num_buffers_warp_spec**: Identifier found in `flex_attention.py`
- **num_consumer_groups**: Identifier found in `flex_attention.py`
- **num_heads**: Identifier found in `flex_attention.py`
- **num_key_value**: Identifier found in `flex_attention.py`
- **num_placeholders**: Identifier found in `flex_attention.py`
- **num_queries**: Identifier found in `flex_attention.py`
- **num_score_mod_placeholders**: Identifier found in `flex_attention.py`
- **num_stages**: Identifier found in `flex_attention.py`
- **num_warps**: Identifier found in `flex_attention.py`
- **number**: Identifier found in `flex_attention.py`

### O

- **Optional**: Identifier found in `flex_attention.py`
- **okay**: Identifier found in `flex_attention.py`
- **only**: Identifier found in `flex_attention.py`
- **op**: Identifier found in `flex_attention.py`
- **operation**: Identifier found in `flex_attention.py`
- **operations**: Identifier found in `flex_attention.py`
- **options**: Identifier found in `flex_attention.py`
- **order**: Identifier found in `flex_attention.py`
- **original_kernel_options**: Identifier found in `flex_attention.py`
- **other_buffer_grads**: Identifier found in `flex_attention.py`
- **other_grads**: Identifier found in `flex_attention.py`
- **out**: Identifier found in `flex_attention.py`
- **out_size**: Identifier found in `flex_attention.py`
- **out_strides**: Identifier found in `flex_attention.py`
- **outer_grads**: Identifier found in `flex_attention.py`
- **output**: Identifier found in `flex_attention.py`
- **outputs**: Identifier found in `flex_attention.py`
- **over**: Identifier found in `flex_attention.py`

### P

- **Performance**: Identifier found in `flex_attention.py`
- **Process**: Identifier found in `flex_attention.py`
- **parallelize**: Identifier found in `flex_attention.py`
- **parallelized**: Identifier found in `flex_attention.py`
- **parallelizing**: Identifier found in `flex_attention.py`
- **parameters**: Identifier found in `flex_attention.py`
- **partial**: Identifier found in `flex_attention.py`
- **pass**: Identifier found in `flex_attention.py`
- **path**: Identifier found in `flex_attention.py`
- **placeholder**: Identifier found in `flex_attention.py`
- **placeholder_inps**: Identifier found in `flex_attention.py`
- **prefix**: Identifier found in `flex_attention.py`
- **probably**: Identifier found in `flex_attention.py`
- **process_joint_outputs**: Identifier found in `flex_attention.py`
- **processed**: Identifier found in `flex_attention.py`
- **processing**: Identifier found in `flex_attention.py`
- **pyrefly**: Identifier found in `flex_attention.py`

### Q

- **Q_BLOCK_SIZE**: Identifier found in `flex_attention.py`
- **Query**: Identifier found in `flex_attention.py`
- **q_heads**: Identifier found in `flex_attention.py`
- **q_idx**: Identifier found in `flex_attention.py`
- **q_indices**: Identifier found in `flex_attention.py`
- **q_length**: Identifier found in `flex_attention.py`
- **q_num_blocks**: Identifier found in `flex_attention.py`
- **q_strides**: Identifier found in `flex_attention.py`
- **qk_head_dim**: Identifier found in `flex_attention.py`
- **query**: Identifier found in `flex_attention.py`
- **query_block_size**: Identifier found in `flex_attention.py`
- **query_size**: Identifier found in `flex_attention.py`

### R

- **ROCm**: Identifier found in `flex_attention.py`
- **Remove**: Identifier found in `flex_attention.py`
- **Results**: Identifier found in `flex_attention.py`
- **Returns**: Identifier found in `flex_attention.py`
- **raise**: Identifier found in `flex_attention.py`
- **range**: Identifier found in `flex_attention.py`
- **regardless**: Identifier found in `flex_attention.py`
- **register_lowering**: Identifier found in `flex_attention.py`
- **require**: Identifier found in `flex_attention.py`
- **require_contiguous**: Identifier found in `flex_attention.py`
- **requires**: Identifier found in `flex_attention.py`
- **responsible**: Identifier found in `flex_attention.py`
- **return**: Identifier found in `flex_attention.py`

### S

- **SM_SCALE**: Identifier found in `flex_attention.py`
- **SPARSE_KV_BLOCK_SIZE**: Identifier found in `flex_attention.py`
- **SPARSE_Q_BLOCK_SIZE**: Identifier found in `flex_attention.py`
- **Same**: Identifier found in `flex_attention.py`
- **Sequence**: Identifier found in `flex_attention.py`
- **Sometimes**: Identifier found in `flex_attention.py`
- **SubgraphResults**: Identifier found in `flex_attention.py`
- **Symbol**: Identifier found in `flex_attention.py`
- **SymbolicGridFn**: Identifier found in `flex_attention.py`
- **same**: Identifier found in `flex_attention.py`
- **scale**: Identifier found in `flex_attention.py`
- **score**: Identifier found in `flex_attention.py`
- **score_mod**: Identifier found in `flex_attention.py`
- **score_mod_other_buffers**: Identifier found in `flex_attention.py`
- **scores**: Identifier found in `flex_attention.py`
- **select_algorithm**: Identifier found in `flex_attention.py`
- **seq_kv_divisible**: Identifier found in `flex_attention.py`
- **seq_len_kv**: Identifier found in `flex_attention.py`
- **seq_len_q**: Identifier found in `flex_attention.py`
- **seq_q_divisible**: Identifier found in `flex_attention.py`
- **set_head_dim_values**: Identifier found in `flex_attention.py`
- **setdefault**: Identifier found in `flex_attention.py`
- **shape**: Identifier found in `flex_attention.py`
- **shapes**: Identifier found in `flex_attention.py`
- **since**: Identifier found in `flex_attention.py`
- **size**: Identifier found in `flex_attention.py`
- **sizevars**: Identifier found in `flex_attention.py`
- **skip**: Identifier found in `flex_attention.py`
- **small_dqk**: Identifier found in `flex_attention.py`
- **small_dv**: Identifier found in `flex_attention.py`
- **solution**: Identifier found in `flex_attention.py`
- **some**: Identifier found in `flex_attention.py`
- **source**: Identifier found in `flex_attention.py`
- **specialization**: Identifier found in `flex_attention.py`
- **specific**: Identifier found in `flex_attention.py`
- **startswith**: Identifier found in `flex_attention.py`
- **static**: Identifier found in `flex_attention.py`
- **statically_known_true**: Identifier found in `flex_attention.py`
- **store_output**: Identifier found in `flex_attention.py`
- **stored**: Identifier found in `flex_attention.py`
- **stride**: Identifier found in `flex_attention.py`
- **strides**: Identifier found in `flex_attention.py`
- **structure**: Identifier found in `flex_attention.py`
- **subgraph**: Identifier found in `flex_attention.py`
- **subgraph_buffer**: Identifier found in `flex_attention.py`
- **subgraph_inps**: Identifier found in `flex_attention.py`
- **subgraph_outs**: Identifier found in `flex_attention.py`
- **subgraphs**: Identifier found in `flex_attention.py`
- **support**: Identifier found in `flex_attention.py`
- **supported**: Identifier found in `flex_attention.py`
- **symbols**: Identifier found in `flex_attention.py`
- **symints**: Identifier found in `flex_attention.py`
- **sympify**: Identifier found in `flex_attention.py`
- **sympy**: Identifier found in `flex_attention.py`

### T

- **TMA**: Identifier found in `flex_attention.py`
- **TODO**: Identifier found in `flex_attention.py`
- **TYPE_CHECKING**: Identifier found in `flex_attention.py`
- **Template**: Identifier found in `flex_attention.py`
- **TensorBox**: Identifier found in `flex_attention.py`
- **This**: Identifier found in `flex_attention.py`
- **Triton**: Identifier found in `flex_attention.py`
- **TritonTemplate**: Identifier found in `flex_attention.py`
- **TritonTemplates**: Identifier found in `flex_attention.py`
- **True**: Identifier found in `flex_attention.py`
- **target**: Identifier found in `flex_attention.py`
- **template**: Identifier found in `flex_attention.py`
- **template_heuristics**: Identifier found in `flex_attention.py`
- **templates**: Identifier found in `flex_attention.py`
- **tensor**: Identifier found in `flex_attention.py`
- **tensors**: Identifier found in `flex_attention.py`
- **tf32**: Identifier found in `flex_attention.py`
- **than**: Identifier found in `flex_attention.py`
- **that**: Identifier found in `flex_attention.py`
- **there**: Identifier found in `flex_attention.py`
- **these**: Identifier found in `flex_attention.py`
- **they**: Identifier found in `flex_attention.py`
- **this**: Identifier found in `flex_attention.py`
- **though**: Identifier found in `flex_attention.py`
- **times**: Identifier found in `flex_attention.py`
- **torch**: Identifier found in `flex_attention.py`
- **triton**: Identifier found in `flex_attention.py`
- **tuning**: Identifier found in `flex_attention.py`
- **tuple**: Identifier found in `flex_attention.py`

### U

- **USE**: Identifier found in `flex_attention.py`
- **USE_TMA**: Identifier found in `flex_attention.py`
- **Union**: Identifier found in `flex_attention.py`
- **Using**: Identifier found in `flex_attention.py`

### V

- **ValueError**: Identifier found in `flex_attention.py`

