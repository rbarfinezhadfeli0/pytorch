# Documentation: fake_quantize.py

## File Metadata
- **Path**: `torch/quantization/fake_quantize.py`
- **Size**: 1015 bytes
- **Lines**: 32
- **Extension**: .py
- **Type**: Regular file

## Original Source

```py
# flake8: noqa: F401
r"""
This file is in the process of migration to `torch/ao/quantization`, and
is kept here for compatibility while the migration process is ongoing.
If you are adding a new entry/functionality, please, add it to the
`torch/ao/quantization/fake_quantize.py`, while adding an import statement
here.
"""

from torch.ao.quantization.fake_quantize import (
    _is_fake_quant_script_module,
    _is_per_channel,
    _is_per_tensor,
    _is_symmetric_quant,
    default_fake_quant,
    default_fixed_qparams_range_0to1_fake_quant,
    default_fixed_qparams_range_neg1to1_fake_quant,
    default_fused_act_fake_quant,
    default_fused_per_channel_wt_fake_quant,
    default_fused_wt_fake_quant,
    default_histogram_fake_quant,
    default_per_channel_weight_fake_quant,
    default_weight_fake_quant,
    disable_fake_quant,
    disable_observer,
    enable_fake_quant,
    enable_observer,
    FakeQuantize,
    FakeQuantizeBase,
    FixedQParamsFakeQuantize,
    FusedMovingAvgObsFakeQuantize,
)

```

## High-Level Overview

This file is part of the PyTorch repository. It is a Python source file that may contain classes, functions, and module-level code.

## Detailed Walkthrough


## Key Components

The file contains 73 words across 32 lines of code/text.

## Usage & Examples

This file is part of the larger PyTorch codebase. For usage examples, refer to related test files and documentation.

## Performance & Security Notes

- File size: 1015 bytes
- Complexity: Standard

## Related Files

See the folder index for related files in the same directory.

## Testing

Refer to the PyTorch test suite for test coverage of this file.

---
*Generated by Repo Book Generator v1.0*
