# Keywords: _attention.py

## Keyword Index

### A

- **ABC**: Identifier found in `_attention.py`
- **ALL_GATHER**: Identifier found in `_attention.py`
- **ALL_TO_ALL**: Identifier found in `_attention.py`
- **API**: Identifier found in `_attention.py`
- **APIs**: Identifier found in `_attention.py`
- **ATen**: Identifier found in `_attention.py`
- **Allgather**: Identifier found in `_attention.py`
- **Although**: Identifier found in `_attention.py`
- **Apply**: Identifier found in `_attention.py`
- **Args**: Identifier found in `_attention.py`
- **ArgsType**: Identifier found in `_attention.py`
- **AsyncCollectiveTensor**: Identifier found in `_attention.py`
- **AttentionType**: Identifier found in `_attention.py`
- **abstractmethod**: Identifier found in `_attention.py`
- **accessing**: Identifier found in `_attention.py`
- **according**: Identifier found in `_attention.py`
- **accum_dtype**: Identifier found in `_attention.py`
- **accumulation**: Identifier found in `_attention.py`
- **accuracy**: Identifier found in `_attention.py`
- **achieve**: Identifier found in `_attention.py`
- **across**: Identifier found in `_attention.py`
- **actions**: Identifier found in `_attention.py`
- **add**: Identifier found in `_attention.py`
- **added**: Identifier found in `_attention.py`
- **additional**: Identifier found in `_attention.py`
- **after**: Identifier found in `_attention.py`
- **algorithm**: Identifier found in `_attention.py`
- **all_args**: Identifier found in `_attention.py`
- **all_gather_tensor**: Identifier found in `_attention.py`
- **all_to_all**: Identifier found in `_attention.py`
- **allgather**: Identifier found in `_attention.py`
- **alltoall**: Identifier found in `_attention.py`
- **along**: Identifier found in `_attention.py`
- **already**: Identifier found in `_attention.py`
- **also**: Identifier found in `_attention.py`
- **always**: Identifier found in `_attention.py`
- **append**: Identifier found in `_attention.py`
- **applied**: Identifier found in `_attention.py`
- **approach**: Identifier found in `_attention.py`
- **appropriately**: Identifier found in `_attention.py`
- **arg**: Identifier found in `_attention.py`
- **args**: Identifier found in `_attention.py`
- **args_list**: Identifier found in `_attention.py`
- **argument**: Identifier found in `_attention.py`
- **assert**: Identifier found in `_attention.py`
- **assuming**: Identifier found in `_attention.py`
- **aten**: Identifier found in `_attention.py`
- **attending**: Identifier found in `_attention.py`
- **attention**: Identifier found in `_attention.py`
- **attention_type**: Identifier found in `_attention.py`
- **attn_bias**: Identifier found in `_attention.py`
- **auto**: Identifier found in `_attention.py`
- **available**: Identifier found in `_attention.py`
- **avoid**: Identifier found in `_attention.py`

### B

- **B**: Identifier found in `_attention.py`
- **BLOCK_SIZE**: Identifier found in `_attention.py`
- **Balance**: Identifier found in `_attention.py`
- **Batch**: Identifier found in `_attention.py`
- **BlockMask**: Identifier found in `_attention.py`
- **BlockMasks**: Identifier found in `_attention.py`
- **Both**: Identifier found in `_attention.py`
- **Buffers**: Identifier found in `_attention.py`
- **b**: Identifier found in `_attention.py`
- **back**: Identifier found in `_attention.py`
- **backend**: Identifier found in `_attention.py`
- **backward**: Identifier found in `_attention.py`
- **balance**: Identifier found in `_attention.py`
- **balanced**: Identifier found in `_attention.py`
- **balancer**: Identifier found in `_attention.py`
- **balancing**: Identifier found in `_attention.py`
- **batch**: Identifier found in `_attention.py`
- **batches**: Identifier found in `_attention.py`
- **because**: Identifier found in `_attention.py`
- **been**: Identifier found in `_attention.py`
- **before**: Identifier found in `_attention.py`
- **behavior**: Identifier found in `_attention.py`
- **being**: Identifier found in `_attention.py`
- **below**: Identifier found in `_attention.py`
- **better**: Identifier found in `_attention.py`
- **bias**: Identifier found in `_attention.py`
- **bite**: Identifier found in `_attention.py`
- **blk_idx**: Identifier found in `_attention.py`
- **blob**: Identifier found in `_attention.py`
- **block**: Identifier found in `_attention.py`
- **block_idx**: Identifier found in `_attention.py`
- **block_lse**: Identifier found in `_attention.py`
- **block_mask**: Identifier found in `_attention.py`
- **block_offset**: Identifier found in `_attention.py`
- **block_out**: Identifier found in `_attention.py`
- **block_size**: Identifier found in `_attention.py`
- **bool**: Identifier found in `_attention.py`
- **both**: Identifier found in `_attention.py`
- **breaking**: Identifier found in `_attention.py`
- **buffer**: Identifier found in `_attention.py`
- **buffer_seq_dims**: Identifier found in `_attention.py`
- **buffers**: Identifier found in `_attention.py`

### C

- **CPBuffer**: Identifier found in `_attention.py`
- **CPBufferContainer**: Identifier found in `_attention.py`
- **CPBufferSeqDims**: Identifier found in `_attention.py`
- **Calculate**: Identifier found in `_attention.py`
- **Callable**: Identifier found in `_attention.py`
- **Cannot**: Identifier found in `_attention.py`
- **Causal**: Identifier found in `_attention.py`
- **Consequently**: Identifier found in `_attention.py`
- **Consider**: Identifier found in `_attention.py`
- **Context**: Identifier found in `_attention.py`
- **ContextParallel**: Identifier found in `_attention.py`
- **Creates**: Identifier found in `_attention.py`
- **Current**: Identifier found in `_attention.py`
- **Currently**: Identifier found in `_attention.py`
- **c10d**: Identifier found in `_attention.py`
- **calculate**: Identifier found in `_attention.py`
- **calculated**: Identifier found in `_attention.py`
- **call**: Identifier found in `_attention.py`
- **call_maps**: Identifier found in `_attention.py`
- **called**: Identifier found in `_attention.py`
- **cannot**: Identifier found in `_attention.py`
- **case**: Identifier found in `_attention.py`
- **cases**: Identifier found in `_attention.py`
- **cast**: Identifier found in `_attention.py`
- **causal**: Identifier found in `_attention.py`
- **chain**: Identifier found in `_attention.py`
- **change**: Identifier found in `_attention.py`
- **chunk**: Identifier found in `_attention.py`
- **chunked**: Identifier found in `_attention.py`
- **chunks**: Identifier found in `_attention.py`
- **class**: Identifier found in `_attention.py`
- **clone**: Identifier found in `_attention.py`
- **close**: Identifier found in `_attention.py`
- **code**: Identifier found in `_attention.py`
- **collections**: Identifier found in `_attention.py`
- **collective**: Identifier found in `_attention.py`
- **communication**: Identifier found in `_attention.py`
- **comparison**: Identifier found in `_attention.py`
- **compile**: Identifier found in `_attention.py`
- **compiled_create_block_mask**: Identifier found in `_attention.py`
- **complete**: Identifier found in `_attention.py`
- **computation**: Identifier found in `_attention.py`
- **computations**: Identifier found in `_attention.py`
- **compute_log_sumexp**: Identifier found in `_attention.py`
- **compute_mesh**: Identifier found in `_attention.py`
- **computes**: Identifier found in `_attention.py`
- **concatenated**: Identifier found in `_attention.py`
- **configurations**: Identifier found in `_attention.py`
- **configured**: Identifier found in `_attention.py`
- **consecutive**: Identifier found in `_attention.py`
- **constraint**: Identifier found in `_attention.py`
- **contain**: Identifier found in `_attention.py`
- **containing**: Identifier found in `_attention.py`
- **contains**: Identifier found in `_attention.py`
- **context**: Identifier found in `_attention.py`
- **context_parallel**: Identifier found in `_attention.py`
- **context_parallel_unshard**: Identifier found in `_attention.py`
- **contextlib**: Identifier found in `_attention.py`
- **contextmanager**: Identifier found in `_attention.py`
- **contiguous**: Identifier found in `_attention.py`
- **continue**: Identifier found in `_attention.py`
- **convention**: Identifier found in `_attention.py`
- **convert_to_f32**: Identifier found in `_attention.py`
- **copy_**: Identifier found in `_attention.py`
- **correct**: Identifier found in `_attention.py`
- **correctly**: Identifier found in `_attention.py`
- **correctness**: Identifier found in `_attention.py`
- **corresponding**: Identifier found in `_attention.py`
- **corresponds**: Identifier found in `_attention.py`
- **cp_group_size**: Identifier found in `_attention.py`
- **cp_mesh**: Identifier found in `_attention.py`
- **cp_rank**: Identifier found in `_attention.py`
- **cp_world_size**: Identifier found in `_attention.py`
- **create_block_mask**: Identifier found in `_attention.py`
- **creates**: Identifier found in `_attention.py`
- **cuDNN**: Identifier found in `_attention.py`
- **cum_seq_k**: Identifier found in `_attention.py`
- **cum_seq_q**: Identifier found in `_attention.py`
- **curr_buffer**: Identifier found in `_attention.py`
- **current**: Identifier found in `_attention.py`
- **currently**: Identifier found in `_attention.py`
- **curve**: Identifier found in `_attention.py`
- **custom_ops**: Identifier found in `_attention.py`

### D

- **DTensor**: Identifier found in `_attention.py`
- **Device**: Identifier found in `_attention.py`
- **DeviceMesh**: Identifier found in `_attention.py`
- **Disable**: Identifier found in `_attention.py`
- **Disables**: Identifier found in `_attention.py`
- **Dispatching**: Identifier found in `_attention.py`
- **data_batch_size**: Identifier found in `_attention.py`
- **dataclass**: Identifier found in `_attention.py`
- **dataclasses**: Identifier found in `_attention.py`
- **debug**: Identifier found in `_attention.py`
- **default**: Identifier found in `_attention.py`
- **defaults**: Identifier found in `_attention.py`
- **definitions**: Identifier found in `_attention.py`
- **depend**: Identifier found in `_attention.py`
- **depends**: Identifier found in `_attention.py`
- **deprecate**: Identifier found in `_attention.py`
- **detailed**: Identifier found in `_attention.py`
- **determined**: Identifier found in `_attention.py`
- **device**: Identifier found in `_attention.py`
- **device_mesh**: Identifier found in `_attention.py`
- **device_type**: Identifier found in `_attention.py`
- **diagram**: Identifier found in `_attention.py`
- **dict**: Identifier found in `_attention.py`
- **different**: Identifier found in `_attention.py`
- **dim**: Identifier found in `_attention.py`
- **dimension**: Identifier found in `_attention.py`
- **dimensionality**: Identifier found in `_attention.py`
- **dimensions**: Identifier found in `_attention.py`
- **discuss**: Identifier found in `_attention.py`
- **dispatch**: Identifier found in `_attention.py`
- **dispatcher**: Identifier found in `_attention.py`
- **dist**: Identifier found in `_attention.py`
- **distribute_tensor**: Identifier found in `_attention.py`
- **distributed**: Identifier found in `_attention.py`
- **distributed_c10d**: Identifier found in `_attention.py`
- **divisible**: Identifier found in `_attention.py`
- **dkv_rotater**: Identifier found in `_attention.py`
- **does**: Identifier found in `_attention.py`
- **doesn**: Identifier found in `_attention.py`
- **done**: Identifier found in `_attention.py`
- **dout**: Identifier found in `_attention.py`
- **dropout_p**: Identifier found in `_attention.py`
- **dsts**: Identifier found in `_attention.py`
- **dtype**: Identifier found in `_attention.py`
- **dynamic**: Identifier found in `_attention.py`
- **dynamically**: Identifier found in `_attention.py`

### E

- **Either**: Identifier found in `_attention.py`
- **Enable**: Identifier found in `_attention.py`
- **Enables**: Identifier found in `_attention.py`
- **Enum**: Identifier found in `_attention.py`
- **Examples**: Identifier found in `_attention.py`
- **Experimental**: Identifier found in `_attention.py`
- **each**: Identifier found in `_attention.py`
- **efficient**: Identifier found in `_attention.py`
- **either**: Identifier found in `_attention.py`
- **element**: Identifier found in `_attention.py`
- **elements**: Identifier found in `_attention.py`
- **elif**: Identifier found in `_attention.py`
- **else**: Identifier found in `_attention.py`
- **embedding**: Identifier found in `_attention.py`
- **enable**: Identifier found in `_attention.py`
- **enable_load_balance**: Identifier found in `_attention.py`
- **enabled**: Identifier found in `_attention.py`
- **enables**: Identifier found in `_attention.py`
- **ensure**: Identifier found in `_attention.py`
- **ensuring**: Identifier found in `_attention.py`
- **entries**: Identifier found in `_attention.py`
- **enum**: Identifier found in `_attention.py`
- **enumerate**: Identifier found in `_attention.py`
- **error**: Identifier found in `_attention.py`
- **errors**: Identifier found in `_attention.py`
- **example**: Identifier found in `_attention.py`
- **exchange_buffers**: Identifier found in `_attention.py`
- **exchanged**: Identifier found in `_attention.py`
- **exists**: Identifier found in `_attention.py`
- **exits**: Identifier found in `_attention.py`
- **exitsing_custom_ops**: Identifier found in `_attention.py`
- **expand**: Identifier found in `_attention.py`
- **expclitly**: Identifier found in `_attention.py`
- **expects**: Identifier found in `_attention.py`
- **experimental**: Identifier found in `_attention.py`
- **explanation**: Identifier found in `_attention.py`
- **explicitly**: Identifier found in `_attention.py`
- **extra**: Identifier found in `_attention.py`
- **extract**: Identifier found in `_attention.py`

### F

- **FLEX**: Identifier found in `_attention.py`
- **False**: Identifier found in `_attention.py`
- **First**: Identifier found in `_attention.py`
- **FlexAttention**: Identifier found in `_attention.py`
- **feature**: Identifier found in `_attention.py`
- **fegin**: Identifier found in `_attention.py`
- **figure**: Identifier found in `_attention.py`
- **finishes**: Identifier found in `_attention.py`
- **first**: Identifier found in `_attention.py`
- **flash**: Identifier found in `_attention.py`
- **flat_buffers**: Identifier found in `_attention.py`
- **flat_seq_dims**: Identifier found in `_attention.py`
- **flat_sharded_buffers**: Identifier found in `_attention.py`
- **flatten**: Identifier found in `_attention.py`
- **flex_attention**: Identifier found in `_attention.py`
- **flex_cp_allgather**: Identifier found in `_attention.py`
- **flex_input_fn**: Identifier found in `_attention.py`
- **float**: Identifier found in `_attention.py`
- **float32**: Identifier found in `_attention.py`
- **fn_module**: Identifier found in `_attention.py`
- **follow**: Identifier found in `_attention.py`
- **follows**: Identifier found in `_attention.py`
- **from**: Identifier found in `_attention.py`
- **from_local**: Identifier found in `_attention.py`
- **ft_c**: Identifier found in `_attention.py`
- **full**: Identifier found in `_attention.py`
- **fullgraph**: Identifier found in `_attention.py`
- **function**: Identifier found in `_attention.py`
- **functional**: Identifier found in `_attention.py`
- **functools**: Identifier found in `_attention.py`
- **future**: Identifier found in `_attention.py`

### G

- **Generator**: Identifier found in `_attention.py`
- **Global**: Identifier found in `_attention.py`
- **gather**: Identifier found in `_attention.py`
- **gather_dim**: Identifier found in `_attention.py`
- **gathers**: Identifier found in `_attention.py`
- **generalized**: Identifier found in `_attention.py`
- **generate**: Identifier found in `_attention.py`
- **generated**: Identifier found in `_attention.py`
- **getLogger**: Identifier found in `_attention.py`
- **get_group**: Identifier found in `_attention.py`
- **get_local_rank**: Identifier found in `_attention.py`
- **get_rank**: Identifier found in `_attention.py`
- **get_world_size**: Identifier found in `_attention.py`
- **github**: Identifier found in `_attention.py`
- **given**: Identifier found in `_attention.py`
- **gives**: Identifier found in `_attention.py`
- **global**: Identifier found in `_attention.py`
- **global_key**: Identifier found in `_attention.py`
- **global_value**: Identifier found in `_attention.py`
- **going**: Identifier found in `_attention.py`
- **grad**: Identifier found in `_attention.py`
- **grad_input_mask**: Identifier found in `_attention.py`
- **grad_key**: Identifier found in `_attention.py`
- **grad_key_**: Identifier found in `_attention.py`
- **grad_out**: Identifier found in `_attention.py`
- **grad_out_**: Identifier found in `_attention.py`
- **grad_out_name**: Identifier found in `_attention.py`
- **grad_query**: Identifier found in `_attention.py`
- **grad_query_**: Identifier found in `_attention.py`
- **grad_value**: Identifier found in `_attention.py`
- **grad_value_**: Identifier found in `_attention.py`
- **gradient**: Identifier found in `_attention.py`
- **gradients**: Identifier found in `_attention.py`
- **group**: Identifier found in `_attention.py`

### H

- **H**: Identifier found in `_attention.py`
- **Head**: Identifier found in `_attention.py`
- **However**: Identifier found in `_attention.py`
- **half**: Identifier found in `_attention.py`
- **handle**: Identifier found in `_attention.py`
- **handles**: Identifier found in `_attention.py`
- **handling**: Identifier found in `_attention.py`
- **happen**: Identifier found in `_attention.py`
- **hardcoding**: Identifier found in `_attention.py`
- **have**: Identifier found in `_attention.py`
- **having**: Identifier found in `_attention.py`
- **heads**: Identifier found in `_attention.py`
- **help**: Identifier found in `_attention.py`
- **helper**: Identifier found in `_attention.py`
- **https**: Identifier found in `_attention.py`

### I

- **IS_CAUSAL**: Identifier found in `_attention.py`
- **InputFnType**: Identifier found in `_attention.py`
- **Iteration**: Identifier found in `_attention.py`
- **i**: Identifier found in `_attention.py`
- **identical**: Identifier found in `_attention.py`
- **idx**: Identifier found in `_attention.py`
- **idx_batch_size**: Identifier found in `_attention.py`
- **idx_post_rearrange**: Identifier found in `_attention.py`
- **idx_pre_rearrange**: Identifier found in `_attention.py`
- **ignore**: Identifier found in `_attention.py`
- **ignored**: Identifier found in `_attention.py`
- **illustrate**: Identifier found in `_attention.py`
- **implementation**: Identifier found in `_attention.py`
- **implements**: Identifier found in `_attention.py`
- **import**: Identifier found in `_attention.py`
- **improve**: Identifier found in `_attention.py`
- **include**: Identifier found in `_attention.py`
- **incur**: Identifier found in `_attention.py`
- **index**: Identifier found in `_attention.py`
- **index_select**: Identifier found in `_attention.py`
- **indicate**: Identifier found in `_attention.py`
- **indices**: Identifier found in `_attention.py`
- **info**: Identifier found in `_attention.py`
- **infos**: Identifier found in `_attention.py`
- **inner_fn**: Identifier found in `_attention.py`
- **input**: Identifier found in `_attention.py`
- **input_fn**: Identifier found in `_attention.py`
- **inputs**: Identifier found in `_attention.py`
- **internal**: Identifier found in `_attention.py`
- **internally**: Identifier found in `_attention.py`
- **is_causal**: Identifier found in `_attention.py`
- **is_causal_behavior**: Identifier found in `_attention.py`
- **isinstance**: Identifier found in `_attention.py`

### K

- **KV_LEN**: Identifier found in `_attention.py`
- **KwargsType**: Identifier found in `_attention.py`

### L

- **L14695**: Identifier found in `_attention.py`
- **LSE**: Identifier found in `_attention.py`
- **List**: Identifier found in `_attention.py`
- **Load**: Identifier found in `_attention.py`
- **Local**: Identifier found in `_attention.py`

### M

- **MODULE_WRAPPER**: Identifier found in `_attention.py`
- **MONKEY_PATCH**: Identifier found in `_attention.py`
- **Mapping**: Identifier found in `_attention.py`
- **Mask**: Identifier found in `_attention.py`
- **Module**: Identifier found in `_attention.py`
- **ModuleType**: Identifier found in `_attention.py`
- **Must**: Identifier found in `_attention.py`

### N

- **NOTE**: Identifier found in `_attention.py`
- **NOT_IS_CAUSAL**: Identifier found in `_attention.py`
- **Need**: Identifier found in `_attention.py`
- **None**: Identifier found in `_attention.py`
- **NotImplementedError**: Identifier found in `_attention.py`
- **Note**: Identifier found in `_attention.py`
- **Number**: Identifier found in `_attention.py`

### O

- **Only**: Identifier found in `_attention.py`
- **OpInfo**: Identifier found in `_attention.py`
- **OpOverload**: Identifier found in `_attention.py`
- **Optional**: Identifier found in `_attention.py`
- **Otherwise**: Identifier found in `_attention.py`
- **OutputFnType**: Identifier found in `_attention.py`

### P

- **Parallel**: Identifier found in `_attention.py`
- **ParallelStyle**: Identifier found in `_attention.py`
- **Parameter**: Identifier found in `_attention.py`
- **Parameters**: Identifier found in `_attention.py`
- **ProcessGroup**: Identifier found in `_attention.py`
- **Protocol**: Identifier found in `_attention.py`
- **PyTorch**: Identifier found in `_attention.py`

### Q

- **QKV**: Identifier found in `_attention.py`
- **Q_LEN**: Identifier found in `_attention.py`
- **Q_SHARD_LEN**: Identifier found in `_attention.py`

### R

- **ROUND_ROBIN_CYCLE**: Identifier found in `_attention.py`
- **Raises**: Identifier found in `_attention.py`
- **Rank0**: Identifier found in `_attention.py`
- **Rank1**: Identifier found in `_attention.py`
- **Restore**: Identifier found in `_attention.py`
- **Returns**: Identifier found in `_attention.py`
- **Round**: Identifier found in `_attention.py`
- **RuntimeError**: Identifier found in `_attention.py`

### S

- **SDPA**: Identifier found in `_attention.py`
- **SKIP**: Identifier found in `_attention.py`
- **Second**: Identifier found in `_attention.py`
- **Send**: Identifier found in `_attention.py`
- **Sequence**: Identifier found in `_attention.py`
- **Shard**: Identifier found in `_attention.py`
- **Support**: Identifier found in `_attention.py`

### T

- **TODO**: Identifier found in `_attention.py`
- **Tensor**: Identifier found in `_attention.py`
- **These**: Identifier found in `_attention.py`
- **This**: Identifier found in `_attention.py`
- **True**: Identifier found in `_attention.py`
- **TypeAlias**: Identifier found in `_attention.py`

### U

- **Unknown**: Identifier found in `_attention.py`
- **Unshard**: Identifier found in `_attention.py`
- **Users**: Identifier found in `_attention.py`

### V

- **ValueError**: Identifier found in `_attention.py`

### W

- **Wait**: Identifier found in `_attention.py`
- **Warning**: Identifier found in `_attention.py`
- **When**: Identifier found in `_attention.py`
- **Whether**: Identifier found in `_attention.py`
- **While**: Identifier found in `_attention.py`
- **Without**: Identifier found in `_attention.py`

### _

- **_**: Identifier found in `_attention.py`
- **_AllGatherRotater**: Identifier found in `_attention.py`
- **_AllToAllRotater**: Identifier found in `_attention.py`
- **_AttentionOp**: Identifier found in `_attention.py`
- **_CausalBehavior**: Identifier found in `_attention.py`
- **_ContextParallel**: Identifier found in `_attention.py`
- **_DispatchMode**: Identifier found in `_attention.py`
- **_RingRotater**: Identifier found in `_attention.py`
- **_RotateMethod**: Identifier found in `_attention.py`
- **_SDPAMerger**: Identifier found in `_attention.py`
- **__all__**: Identifier found in `_attention.py`
- **__call__**: Identifier found in `_attention.py`
- **__init__**: Identifier found in `_attention.py`
- **_aggregated_buffer**: Identifier found in `_attention.py`
- **_apply**: Identifier found in `_attention.py`
- **_buffer**: Identifier found in `_attention.py`
- **_compiled_create_block_mask**: Identifier found in `_attention.py`
- **_context_parallel_buffers**: Identifier found in `_attention.py`
- **_context_parallel_shard**: Identifier found in `_attention.py`
- **_convert_to_f32**: Identifier found in `_attention.py`
- **_cp_options**: Identifier found in `_attention.py`
- **_create_cp_block_mask**: Identifier found in `_attention.py`
- **_create_rotater**: Identifier found in `_attention.py`
- **_custom_op_handlers**: Identifier found in `_attention.py`
- **_disable_context_parallel_dispatcher**: Identifier found in `_attention.py`
- **_disable_context_parallel_dispatcher_impl**: Identifier found in `_attention.py`
- **_disable_cp_dtensor_dispatcher**: Identifier found in `_attention.py`
- **_dispatch_mode**: Identifier found in `_attention.py`
- **_distribute_function**: Identifier found in `_attention.py`
- **_enable_context_parallel_dispatcher**: Identifier found in `_attention.py`
- **_enable_context_parallel_dispatcher_impl**: Identifier found in `_attention.py`
- **_enable_cp_dtensor_dispatcher**: Identifier found in `_attention.py`
- **_idx**: Identifier found in `_attention.py`
- **_is_causal_behavior**: Identifier found in `_attention.py`
- **_lse**: Identifier found in `_attention.py`
- **_lse_dtype**: Identifier found in `_attention.py`
- **_maybe_wait**: Identifier found in `_attention.py`
- **_merge_one**: Identifier found in `_attention.py`
- **_out**: Identifier found in `_attention.py`
- **_out_dtype**: Identifier found in `_attention.py`
- **_partial_update**: Identifier found in `_attention.py`
- **_pg**: Identifier found in `_attention.py`
- **_restore_function**: Identifier found in `_attention.py`
- **_rewrite_mask_mod**: Identifier found in `_attention.py`
- **_scaled_dot_product_ring_cudnn_attention**: Identifier found in `_attention.py`
- **_scaled_dot_product_ring_cudnn_attention_backward**: Identifier found in `_attention.py`
- **_scaled_dot_product_ring_efficient_attention**: Identifier found in `_attention.py`
- **_scaled_dot_product_ring_efficient_attention_backward**: Identifier found in `_attention.py`
- **_scaled_dot_product_ring_flash_attention**: Identifier found in `_attention.py`
- **_scaled_dot_product_ring_flash_attention_backward**: Identifier found in `_attention.py`
- **_sdpa_handler**: Identifier found in `_attention.py`
- **_seq_dim**: Identifier found in `_attention.py`
- **_should_lse_squeeze**: Identifier found in `_attention.py`
- **_templated_ring_attention**: Identifier found in `_attention.py`
- **_templated_ring_attention_backward**: Identifier found in `_attention.py`

