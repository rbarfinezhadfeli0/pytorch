# Documentation: `torch/distributed/tensor/experimental/_attention.py`

## File Metadata

- **Path**: `torch/distributed/tensor/experimental/_attention.py`
- **Size**: 1,229 bytes (1.20 KB)
- **Type**: Python Source Code
- **Extension**: `.py`

## File Purpose

This is a python source code that is part of the PyTorch project.

## Original Source

```python
# Copyright (c) Meta Platforms, Inc. and affiliates
# Backward compatibility stub - this module has been moved to _context_parallel/_attention.py

from ._context_parallel._attention import (
    _CausalBehavior,
    _context_parallel_shard,
    _ContextParallel,
    _cp_options,
    _disable_context_parallel_dispatcher,
    _enable_context_parallel_dispatcher,
    _is_causal_behavior,
    _RotateMethod,
    _templated_ring_attention,
    context_parallel,
    context_parallel_unshard,
    set_rotate_method,
)
from ._context_parallel._load_balancer import (
    _HeadTailLoadBalancer,
    _LoadBalancer,
    _PerDocumentHeadTailLoadBalancer,
    _PTRRLoadBalancer,
)


# TODO(fegin): add deprecation message once the final interfaces are concluded.
__all__ = [
    "_CausalBehavior",
    "_context_parallel_shard",
    "_ContextParallel",
    "_cp_options",
    "_disable_context_parallel_dispatcher",
    "_enable_context_parallel_dispatcher",
    "_is_causal_behavior",
    "_RotateMethod",
    "_templated_ring_attention",
    "context_parallel",
    "context_parallel_unshard",
    "set_rotate_method",
    "_HeadTailLoadBalancer",
    "_LoadBalancer",
    "_PerDocumentHeadTailLoadBalancer",
    "_PTRRLoadBalancer",
]

```



## High-Level Overview


This Python file contains 0 class(es) and 0 function(s).

## Detailed Analysis

### Code Structure


*For complete code details, see the Original Source section above.*


## Architecture & Design

### Role in PyTorch Architecture

This file is located in `torch/distributed/tensor/experimental`, which is part of the **core PyTorch library**.



## Dependencies

### Import Dependencies

*No imports detected.*


## Code Patterns & Idioms

### Common Patterns

*No specific patterns automatically detected.*


## Performance Considerations

### Performance Notes

- This file appears to involve **GPU/parallel computing** capabilities.

*Detailed performance analysis requires profiling and benchmarking.*


## Security & Safety

### Security Considerations

- No obvious security concerns detected in automated analysis.

*Manual security review is recommended for production code.*


## Testing & Usage

### Testing

Test files for this module may be located in the `test/` directory.

### Usage Examples

*See the source code and related test files for usage examples.*


## Related Files

### Related Files

Files in the same folder (`torch/distributed/tensor/experimental`):

- [`__init__.py_docs.md`](./__init__.py_docs.md)
- [`_tp_transform.py_docs.md`](./_tp_transform.py_docs.md)
- [`_func_map.py_docs.md`](./_func_map.py_docs.md)
- [`_register_sharding.py_docs.md`](./_register_sharding.py_docs.md)


## Cross-References

- **File Documentation**: `_attention.py_docs.md`
- **Keyword Index**: `_attention.py_kw.md`
- **Folder Index**: `index.md`
- **Folder Documentation**: `doc.md`

---

*Generated by PyTorch Repository Documentation System*
