# Documentation: torch/distributed/optim

## Purpose

This directory contains 17 file(s) and 0 subdirectory(ies).

## Contents

### Files

- `__init__.py`
- `_deprecation_warning.py`
- `apply_optimizer_in_backward.py`
- `functional_adadelta.py`
- `functional_adagrad.py`
- `functional_adam.py`
- `functional_adamax.py`
- `functional_adamw.py`
- `functional_rmsprop.py`
- `functional_rprop.py`
- `functional_sgd.py`
- `named_optimizer.py`
- `optimizer.py`
- `post_localSGD_optimizer.py`
- `utils.py`
- `zero_redundancy_optimizer.py`
- `zero_redundancy_optimizer.pyi`

---
*Generated by Repo Book Generator v1.0*
