# Documentation: `torch/csrc/api/include/torch/optim/schedulers/reduce_on_plateau_scheduler.h`

## File Metadata

- **Path**: `torch/csrc/api/include/torch/optim/schedulers/reduce_on_plateau_scheduler.h`
- **Size**: 1,380 bytes (1.35 KB)
- **Type**: C/C++ Header File
- **Extension**: `.h`

## File Purpose

This is a c/c++ header file that is part of the PyTorch project.

## Original Source

```c
#pragma once

#include <torch/optim/optimizer.h>
#include <torch/optim/schedulers/lr_scheduler.h>

#include <torch/csrc/Export.h>

#include <cmath>

namespace torch::optim {

class TORCH_API ReduceLROnPlateauScheduler {
 public:
  enum SchedulerMode { min, max };
  enum ThresholdMode { rel, abs };
  ReduceLROnPlateauScheduler(
      Optimizer& optimizer,
      SchedulerMode mode = min,
      float factor = 0.1,
      int patience = 10,
      double threshold = 1e-4,
      ThresholdMode threshold_mode = rel,
      int cooldown = 0,
      const std::vector<float>& min_lr = std::vector<float>(),
      double eps = 1e-8,
      bool verbose = false);

  virtual ~ReduceLROnPlateauScheduler() = default;

  void step(float metric);

 private:
  void reset();
  void reduce_lr(int epoch);
  bool in_cooldown() const;
  bool is_better(float a);
  void init_is_better(
      SchedulerMode mode,
      double threshold,
      ThresholdMode threshold_mode);

  // NOLINTNEXTLINE(cppcoreguidelines-avoid-const-or-ref-data-members)
  Optimizer& optimizer;
  SchedulerMode mode{};
  float mode_worse{};
  float factor;
  int patience;
  double threshold{};
  ThresholdMode threshold_mode{};
  int cooldown{};
  int cooldown_counter{};
  std::vector<float> min_lrs;
  double eps;
  float best{};
  bool verbose;
  int last_epoch{};
  int num_bad_epochs{};
};
} // namespace torch::optim

```



## High-Level Overview


This C++ file contains approximately 1 class(es)/struct(s) and 6 function(s).

## Detailed Analysis

### Code Structure

**Namespaces**: `torch`

**Classes/Structs**: `TORCH_API`


*For complete code details, see the Original Source section above.*


## Architecture & Design

### Role in PyTorch Architecture

This file is located in `torch/csrc/api/include/torch/optim/schedulers`, which is part of the **core PyTorch library**.



## Dependencies

### Import Dependencies

This file includes:

- `torch/optim/optimizer.h`
- `torch/optim/schedulers/lr_scheduler.h`
- `torch/csrc/Export.h`
- `cmath`


## Code Patterns & Idioms

### Common Patterns

*No specific patterns automatically detected.*


## Performance Considerations

### Performance Notes


*Detailed performance analysis requires profiling and benchmarking.*


## Security & Safety

### Security Considerations

- No obvious security concerns detected in automated analysis.

*Manual security review is recommended for production code.*


## Testing & Usage

### Testing

Test files for this module may be located in the `test/` directory.

### Usage Examples

*See the source code and related test files for usage examples.*


## Related Files

### Related Files

Files in the same folder (`torch/csrc/api/include/torch/optim/schedulers`):

- [`step_lr.h_docs.md`](./step_lr.h_docs.md)
- [`lr_scheduler.h_docs.md`](./lr_scheduler.h_docs.md)


## Cross-References

- **File Documentation**: `reduce_on_plateau_scheduler.h_docs.md`
- **Keyword Index**: `reduce_on_plateau_scheduler.h_kw.md`
- **Folder Index**: `index.md`
- **Folder Documentation**: `doc.md`

---

*Generated by PyTorch Repository Documentation System*
