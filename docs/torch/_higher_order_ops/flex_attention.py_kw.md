# Keywords: flex_attention.py

## Keyword Index

### A

- **AOTConfig**: Identifier found in `flex_attention.py`
- **Appease**: Identifier found in `flex_attention.py`
- **Args**: Identifier found in `flex_attention.py`
- **Autograd**: Identifier found in `flex_attention.py`
- **about**: Identifier found in `flex_attention.py`
- **access**: Identifier found in `flex_attention.py`
- **active**: Identifier found in `flex_attention.py`
- **actual**: Identifier found in `flex_attention.py`
- **actual_grad**: Identifier found in `flex_attention.py`
- **actual_grad_key**: Identifier found in `flex_attention.py`
- **actual_grad_query**: Identifier found in `flex_attention.py`
- **actual_grad_score_mod_captured**: Identifier found in `flex_attention.py`
- **actual_grad_value**: Identifier found in `flex_attention.py`
- **against**: Identifier found in `flex_attention.py`
- **aliases**: Identifier found in `flex_attention.py`
- **allow_non_fake_inputs**: Identifier found in `flex_attention.py`
- **allowed_subclasses**: Identifier found in `flex_attention.py`
- **along**: Identifier found in `flex_attention.py`
- **already**: Identifier found in `flex_attention.py`
- **also**: Identifier found in `flex_attention.py`
- **always**: Identifier found in `flex_attention.py`
- **any_buffer_requires_grad**: Identifier found in `flex_attention.py`
- **anything**: Identifier found in `flex_attention.py`
- **aot_autograd**: Identifier found in `flex_attention.py`
- **aot_config**: Identifier found in `flex_attention.py`
- **aot_id**: Identifier found in `flex_attention.py`
- **applies**: Identifier found in `flex_attention.py`
- **apply**: Identifier found in `flex_attention.py`
- **arange**: Identifier found in `flex_attention.py`
- **args**: Identifier found in `flex_attention.py`
- **argument**: Identifier found in `flex_attention.py`
- **as_strided**: Identifier found in `flex_attention.py`
- **assert**: Identifier found in `flex_attention.py`
- **asserted**: Identifier found in `flex_attention.py`
- **assured**: Identifier found in `flex_attention.py`
- **attach**: Identifier found in `flex_attention.py`
- **attention**: Identifier found in `flex_attention.py`
- **attribute**: Identifier found in `flex_attention.py`
- **autograd**: Identifier found in `flex_attention.py`
- **autograd_not_implemented**: Identifier found in `flex_attention.py`
- **avoid**: Identifier found in `flex_attention.py`

### B

- **Backward**: Identifier found in `flex_attention.py`
- **BaseFunctionalizeAPI**: Identifier found in `flex_attention.py`
- **Bkv**: Identifier found in `flex_attention.py`
- **BlockMask**: Identifier found in `flex_attention.py`
- **Bq**: Identifier found in `flex_attention.py`
- **b**: Identifier found in `flex_attention.py`
- **back**: Identifier found in `flex_attention.py`
- **backend**: Identifier found in `flex_attention.py`
- **backward**: Identifier found in `flex_attention.py`
- **backwards**: Identifier found in `flex_attention.py`
- **base**: Identifier found in `flex_attention.py`
- **based**: Identifier found in `flex_attention.py`
- **batch**: Identifier found in `flex_attention.py`
- **batch_size**: Identifier found in `flex_attention.py`
- **batched**: Identifier found in `flex_attention.py`
- **because**: Identifier found in `flex_attention.py`
- **before**: Identifier found in `flex_attention.py`
- **block_mask**: Identifier found in `flex_attention.py`
- **block_mask_unwrapped**: Identifier found in `flex_attention.py`
- **bool**: Identifier found in `flex_attention.py`
- **both**: Identifier found in `flex_attention.py`
- **broadcast**: Identifier found in `flex_attention.py`
- **broadcasted**: Identifier found in `flex_attention.py`
- **broadcasted_grad_key**: Identifier found in `flex_attention.py`
- **broadcasted_grad_value**: Identifier found in `flex_attention.py`
- **buffer**: Identifier found in `flex_attention.py`
- **buffers**: Identifier found in `flex_attention.py`
- **bw_compiler**: Identifier found in `flex_attention.py`
- **bw_example_vals**: Identifier found in `flex_attention.py`
- **bw_graph**: Identifier found in `flex_attention.py`

### C

- **Callable**: Identifier found in `flex_attention.py`
- **Captured**: Identifier found in `flex_attention.py`
- **CompositeExplicitAutograd**: Identifier found in `flex_attention.py`
- **Create**: Identifier found in `flex_attention.py`
- **cacheable**: Identifier found in `flex_attention.py`
- **call**: Identifier found in `flex_attention.py`
- **call_function**: Identifier found in `flex_attention.py`
- **calling**: Identifier found in `flex_attention.py`
- **capture**: Identifier found in `flex_attention.py`
- **captured_buffers_in_dim**: Identifier found in `flex_attention.py`
- **care**: Identifier found in `flex_attention.py`
- **cast**: Identifier found in `flex_attention.py`
- **change**: Identifier found in `flex_attention.py`
- **check**: Identifier found in `flex_attention.py`
- **checked**: Identifier found in `flex_attention.py`
- **checkpoint**: Identifier found in `flex_attention.py`
- **circular**: Identifier found in `flex_attention.py`
- **class**: Identifier found in `flex_attention.py`
- **collections**: Identifier found in `flex_attention.py`
- **compiled**: Identifier found in `flex_attention.py`
- **compiler**: Identifier found in `flex_attention.py`
- **compute**: Identifier found in `flex_attention.py`
- **compute_q_blocks**: Identifier found in `flex_attention.py`
- **computed**: Identifier found in `flex_attention.py`
- **computes**: Identifier found in `flex_attention.py`
- **constant**: Identifier found in `flex_attention.py`
- **construct**: Identifier found in `flex_attention.py`
- **contiguous**: Identifier found in `flex_attention.py`
- **contiguous_format**: Identifier found in `flex_attention.py`
- **convert**: Identifier found in `flex_attention.py`
- **copy_**: Identifier found in `flex_attention.py`
- **correctly**: Identifier found in `flex_attention.py`
- **create**: Identifier found in `flex_attention.py`
- **create_fw_bw_graph**: Identifier found in `flex_attention.py`
- **create_joint**: Identifier found in `flex_attention.py`
- **create_proxy**: Identifier found in `flex_attention.py`
- **creates**: Identifier found in `flex_attention.py`
- **current_stride**: Identifier found in `flex_attention.py`

### D

- **Defines**: Identifier found in `flex_attention.py`
- **DispatchKey**: Identifier found in `flex_attention.py`
- **Duplicate**: Identifier found in `flex_attention.py`
- **data**: Identifier found in `flex_attention.py`
- **decompositions**: Identifier found in `flex_attention.py`
- **default**: Identifier found in `flex_attention.py`
- **deferred_error**: Identifier found in `flex_attention.py`
- **dependencies**: Identifier found in `flex_attention.py`
- **detect_fake_mode**: Identifier found in `flex_attention.py`
- **detected**: Identifier found in `flex_attention.py`
- **device**: Identifier found in `flex_attention.py`
- **dict**: Identifier found in `flex_attention.py`
- **dim**: Identifier found in `flex_attention.py`
- **dimension**: Identifier found in `flex_attention.py`
- **dimensions**: Identifier found in `flex_attention.py`
- **disable_functional_mode**: Identifier found in `flex_attention.py`
- **disable_proxy_modes_tracing**: Identifier found in `flex_attention.py`
- **dispatches**: Identifier found in `flex_attention.py`
- **divide**: Identifier found in `flex_attention.py`
- **dtype**: Identifier found in `flex_attention.py`
- **dummy_aot_config**: Identifier found in `flex_attention.py`
- **during**: Identifier found in `flex_attention.py`

### E

- **Each**: Identifier found in `flex_attention.py`
- **Eager**: Identifier found in `flex_attention.py`
- **Expected**: Identifier found in `flex_attention.py`
- **each**: Identifier found in `flex_attention.py`
- **eager**: Identifier found in `flex_attention.py`
- **else**: Identifier found in `flex_attention.py`
- **empty_like**: Identifier found in `flex_attention.py`
- **empty_strided**: Identifier found in `flex_attention.py`
- **enabled**: Identifier found in `flex_attention.py`
- **error**: Identifier found in `flex_attention.py`
- **example**: Identifier found in `flex_attention.py`
- **example_flat_out**: Identifier found in `flex_attention.py`
- **example_grad**: Identifier found in `flex_attention.py`
- **example_out**: Identifier found in `flex_attention.py`
- **example_vals**: Identifier found in `flex_attention.py`
- **existing**: Identifier found in `flex_attention.py`
- **expand**: Identifier found in `flex_attention.py`
- **experimental**: Identifier found in `flex_attention.py`

### F

- **FakeTensor**: Identifier found in `flex_attention.py`
- **FakeTensorMode**: Identifier found in `flex_attention.py`
- **False**: Identifier found in `flex_attention.py`
- **Fill**: Identifier found in `flex_attention.py`
- **FlexAttentionAutogradOp**: Identifier found in `flex_attention.py`
- **FlexAttentionBackwardHOP**: Identifier found in `flex_attention.py`
- **FlexAttentionHOP**: Identifier found in `flex_attention.py`
- **From**: Identifier found in `flex_attention.py`
- **Function**: Identifier found in `flex_attention.py`
- **FunctionalTensor**: Identifier found in `flex_attention.py`
- **fake**: Identifier found in `flex_attention.py`
- **fake_mode**: Identifier found in `flex_attention.py`
- **fake_tensor**: Identifier found in `flex_attention.py`
- **fallback**: Identifier found in `flex_attention.py`
- **fill**: Identifier found in `flex_attention.py`
- **fill_order**: Identifier found in `flex_attention.py`
- **first**: Identifier found in `flex_attention.py`
- **flex_attention**: Identifier found in `flex_attention.py`
- **flex_attention_autograd**: Identifier found in `flex_attention.py`
- **flex_attention_backward**: Identifier found in `flex_attention.py`
- **flex_attention_backward_fake_tensor_mode**: Identifier found in `flex_attention.py`
- **flex_attention_backward_functionalize**: Identifier found in `flex_attention.py`
- **flex_attention_backward_proxy_torch_dispatch_mode**: Identifier found in `flex_attention.py`
- **flex_attention_fake_impl**: Identifier found in `flex_attention.py`
- **flex_attention_functionalize**: Identifier found in `flex_attention.py`
- **flex_attention_proxy_torch_dispatch_mode**: Identifier found in `flex_attention.py`
- **float**: Identifier found in `flex_attention.py`
- **float32**: Identifier found in `flex_attention.py`
- **float64**: Identifier found in `flex_attention.py`
- **formula**: Identifier found in `flex_attention.py`
- **forward**: Identifier found in `flex_attention.py`
- **forwards**: Identifier found in `flex_attention.py`
- **fp32**: Identifier found in `flex_attention.py`
- **free**: Identifier found in `flex_attention.py`
- **from**: Identifier found in `flex_attention.py`
- **full_kv_indices**: Identifier found in `flex_attention.py`
- **full_kv_num_blocks**: Identifier found in `flex_attention.py`
- **full_q_indices**: Identifier found in `flex_attention.py`
- **full_q_num_blocks**: Identifier found in `flex_attention.py`
- **fully**: Identifier found in `flex_attention.py`
- **function**: Identifier found in `flex_attention.py`
- **functional_fw_graph**: Identifier found in `flex_attention.py`
- **functional_joint_graph**: Identifier found in `flex_attention.py`
- **functional_score_mod**: Identifier found in `flex_attention.py`
- **functional_tensor**: Identifier found in `flex_attention.py`
- **functionalization**: Identifier found in `flex_attention.py`
- **functionalize**: Identifier found in `flex_attention.py`
- **fw_args**: Identifier found in `flex_attention.py`
- **fw_bw**: Identifier found in `flex_attention.py`
- **fw_compiler**: Identifier found in `flex_attention.py`
- **fw_example_vals**: Identifier found in `flex_attention.py`
- **fw_graph**: Identifier found in `flex_attention.py`
- **fw_out**: Identifier found in `flex_attention.py`
- **fw_with_masks**: Identifier found in `flex_attention.py`

### G

- **G**: Identifier found in `flex_attention.py`
- **GQA**: Identifier found in `flex_attention.py`
- **Gradient**: Identifier found in `flex_attention.py`
- **GraphModule**: Identifier found in `flex_attention.py`
- **get_fill_order**: Identifier found in `flex_attention.py`
- **get_fresh_qualname**: Identifier found in `flex_attention.py`
- **given**: Identifier found in `flex_attention.py`
- **grad**: Identifier found in `flex_attention.py`
- **gradOut**: Identifier found in `flex_attention.py`
- **grad_key**: Identifier found in `flex_attention.py`
- **grad_logsumexp**: Identifier found in `flex_attention.py`
- **grad_logsumexp_unwrapped**: Identifier found in `flex_attention.py`
- **grad_max_scores**: Identifier found in `flex_attention.py`
- **grad_out**: Identifier found in `flex_attention.py`
- **grad_out_unwrapped**: Identifier found in `flex_attention.py`
- **grad_query**: Identifier found in `flex_attention.py`
- **grad_score_mod**: Identifier found in `flex_attention.py`
- **grad_score_mod_captured**: Identifier found in `flex_attention.py`
- **grad_scores**: Identifier found in `flex_attention.py`
- **grad_softmax_scores**: Identifier found in `flex_attention.py`
- **grad_value**: Identifier found in `flex_attention.py`
- **grads**: Identifier found in `flex_attention.py`
- **graph**: Identifier found in `flex_attention.py`
- **graph_module**: Identifier found in `flex_attention.py`
- **graphs**: Identifier found in `flex_attention.py`
- **guard**: Identifier found in `flex_attention.py`

### H

- **HOP**: Identifier found in `flex_attention.py`
- **HOPs**: Identifier found in `flex_attention.py`
- **HigherOrderOperator**: Identifier found in `flex_attention.py`
- **However**: Identifier found in `flex_attention.py`
- **h**: Identifier found in `flex_attention.py`
- **has_user_subclass**: Identifier found in `flex_attention.py`
- **hasattr**: Identifier found in `flex_attention.py`
- **have**: Identifier found in `flex_attention.py`
- **head**: Identifier found in `flex_attention.py`
- **heads**: Identifier found in `flex_attention.py`
- **here**: Identifier found in `flex_attention.py`
- **hint**: Identifier found in `flex_attention.py`
- **however**: Identifier found in `flex_attention.py`

### I

- **Implementation**: Identifier found in `flex_attention.py`
- **Initialize**: Identifier found in `flex_attention.py`
- **Iterate**: Identifier found in `flex_attention.py`
- **ignore**: Identifier found in `flex_attention.py`
- **impl**: Identifier found in `flex_attention.py`
- **implementation**: Identifier found in `flex_attention.py`
- **import**: Identifier found in `flex_attention.py`
- **imports**: Identifier found in `flex_attention.py`
- **index_values**: Identifier found in `flex_attention.py`
- **inductor**: Identifier found in `flex_attention.py`
- **initial**: Identifier found in `flex_attention.py`
- **inline**: Identifier found in `flex_attention.py`
- **innermost**: Identifier found in `flex_attention.py`
- **input**: Identifier found in `flex_attention.py`
- **input_requires_grad**: Identifier found in `flex_attention.py`
- **inputs**: Identifier found in `flex_attention.py`
- **interleave**: Identifier found in `flex_attention.py`
- **is_grad_enabled**: Identifier found in `flex_attention.py`
- **isinstance**: Identifier found in `flex_attention.py`

### J

- **joint**: Identifier found in `flex_attention.py`
- **joint_f**: Identifier found in `flex_attention.py`
- **joint_graph**: Identifier found in `flex_attention.py`
- **joint_score_mod**: Identifier found in `flex_attention.py`
- **just**: Identifier found in `flex_attention.py`

### K

- **KV_BLOCK_SIZE**: Identifier found in `flex_attention.py`
- **keep_inference_input_mutations**: Identifier found in `flex_attention.py`
- **keepdim**: Identifier found in `flex_attention.py`
- **kernel**: Identifier found in `flex_attention.py`
- **kernel_options**: Identifier found in `flex_attention.py`
- **key**: Identifier found in `flex_attention.py`
- **key_unwrapped**: Identifier found in `flex_attention.py`
- **know**: Identifier found in `flex_attention.py`
- **kv_idx**: Identifier found in `flex_attention.py`
- **kv_indices**: Identifier found in `flex_attention.py`
- **kv_lengths**: Identifier found in `flex_attention.py`
- **kv_num_blocks**: Identifier found in `flex_attention.py`

### L

- **Length**: Identifier found in `flex_attention.py`
- **List**: Identifier found in `flex_attention.py`
- **lambda**: Identifier found in `flex_attention.py`
- **length**: Identifier found in `flex_attention.py`
- **level**: Identifier found in `flex_attention.py`
- **list**: Identifier found in `flex_attention.py`
- **log2**: Identifier found in `flex_attention.py`
- **logsumexp**: Identifier found in `flex_attention.py`
- **logsumexp_unwrapped**: Identifier found in `flex_attention.py`

### M

- **Mode**: Identifier found in `flex_attention.py`
- **Mutations**: Identifier found in `flex_attention.py`
- **m**: Identifier found in `flex_attention.py`
- **make_fx**: Identifier found in `flex_attention.py`
- **mark_non_differentiable**: Identifier found in `flex_attention.py`
- **mask**: Identifier found in `flex_attention.py`
- **mask_example_vals**: Identifier found in `flex_attention.py`
- **mask_graph**: Identifier found in `flex_attention.py`
- **mask_mod**: Identifier found in `flex_attention.py`
- **mask_mod_in_dim_buffers**: Identifier found in `flex_attention.py`
- **mask_mod_other_buffers**: Identifier found in `flex_attention.py`
- **mask_mod_other_buffers_unwrapped**: Identifier found in `flex_attention.py`
- **mask_qualname**: Identifier found in `flex_attention.py`
- **mask_scores**: Identifier found in `flex_attention.py`
- **masked**: Identifier found in `flex_attention.py`
- **masked_out_rows**: Identifier found in `flex_attention.py`
- **masked_rows**: Identifier found in `flex_attention.py`
- **match**: Identifier found in `flex_attention.py`
- **math**: Identifier found in `flex_attention.py`
- **math_attention**: Identifier found in `flex_attention.py`
- **matrix**: Identifier found in `flex_attention.py`
- **max_scores**: Identifier found in `flex_attention.py`
- **memory_format**: Identifier found in `flex_attention.py`
- **missing**: Identifier found in `flex_attention.py`
- **mode**: Identifier found in `flex_attention.py`
- **module**: Identifier found in `flex_attention.py`
- **multiply**: Identifier found in `flex_attention.py`
- **must**: Identifier found in `flex_attention.py`
- **mutate**: Identifier found in `flex_attention.py`
- **mutates**: Identifier found in `flex_attention.py`
- **mutations**: Identifier found in `flex_attention.py`
- **mypy**: Identifier found in `flex_attention.py`

### N

- **None**: Identifier found in `flex_attention.py`
- **NotImplemented**: Identifier found in `flex_attention.py`
- **Note**: Identifier found in `flex_attention.py`
- **n**: Identifier found in `flex_attention.py`
- **name**: Identifier found in `flex_attention.py`
- **need**: Identifier found in `flex_attention.py`
- **new_empty**: Identifier found in `flex_attention.py`
- **new_out**: Identifier found in `flex_attention.py`
- **new_zeros**: Identifier found in `flex_attention.py`
- **next**: Identifier found in `flex_attention.py`
- **node_args**: Identifier found in `flex_attention.py`
- **none_grads**: Identifier found in `flex_attention.py`
- **num_heads**: Identifier found in `flex_attention.py`
- **num_params_buffers**: Identifier found in `flex_attention.py`

### O

- **Only**: Identifier found in `flex_attention.py`
- **Optional**: Identifier found in `flex_attention.py`
- **Other**: Identifier found in `flex_attention.py`
- **omitted**: Identifier found in `flex_attention.py`
- **only**: Identifier found in `flex_attention.py`
- **operator**: Identifier found in `flex_attention.py`
- **optional_grad**: Identifier found in `flex_attention.py`
- **order**: Identifier found in `flex_attention.py`
- **orders**: Identifier found in `flex_attention.py`
- **other**: Identifier found in `flex_attention.py`
- **other_buffers**: Identifier found in `flex_attention.py`
- **out**: Identifier found in `flex_attention.py`
- **out_dims**: Identifier found in `flex_attention.py`
- **out_proxy**: Identifier found in `flex_attention.py`
- **out_requires_grad**: Identifier found in `flex_attention.py`
- **out_shape**: Identifier found in `flex_attention.py`
- **out_strides**: Identifier found in `flex_attention.py`
- **out_unwrapped**: Identifier found in `flex_attention.py`
- **output**: Identifier found in `flex_attention.py`
- **outputs**: Identifier found in `flex_attention.py`
- **over**: Identifier found in `flex_attention.py`
- **overlords**: Identifier found in `flex_attention.py`
- **override**: Identifier found in `flex_attention.py`

### P

- **Please**: Identifier found in `flex_attention.py`
- **ProxyTorchDispatchMode**: Identifier found in `flex_attention.py`
- **partition_fn**: Identifier found in `flex_attention.py`
- **pass**: Identifier found in `flex_attention.py`
- **passed**: Identifier found in `flex_attention.py`
- **path**: Identifier found in `flex_attention.py`
- **perform**: Identifier found in `flex_attention.py`
- **permute**: Identifier found in `flex_attention.py`
- **permuted**: Identifier found in `flex_attention.py`
- **populating**: Identifier found in `flex_attention.py`
- **post_mod_scores**: Identifier found in `flex_attention.py`
- **pre_dispatch**: Identifier found in `flex_attention.py`
- **precision**: Identifier found in `flex_attention.py`
- **prefix**: Identifier found in `flex_attention.py`
- **produce**: Identifier found in `flex_attention.py`
- **proxy**: Identifier found in `flex_attention.py`
- **proxy_args**: Identifier found in `flex_attention.py`
- **proxy_mode**: Identifier found in `flex_attention.py`
- **proxy_tensor**: Identifier found in `flex_attention.py`
- **py_autograd_impl**: Identifier found in `flex_attention.py`
- **py_functionalize_impl**: Identifier found in `flex_attention.py`
- **py_impl**: Identifier found in `flex_attention.py`
- **pyrefly**: Identifier found in `flex_attention.py`
- **python**: Identifier found in `flex_attention.py`
- **pytree**: Identifier found in `flex_attention.py`

### Q

- **Q_BLOCK_SIZE**: Identifier found in `flex_attention.py`
- **q_idx**: Identifier found in `flex_attention.py`
- **q_indices**: Identifier found in `flex_attention.py`
- **q_num_blocks**: Identifier found in `flex_attention.py`
- **qk_head_dim**: Identifier found in `flex_attention.py`
- **qualname**: Identifier found in `flex_attention.py`
- **query**: Identifier found in `flex_attention.py`
- **query_lengths**: Identifier found in `flex_attention.py`
- **query_strides**: Identifier found in `flex_attention.py`
- **query_unwrapped**: Identifier found in `flex_attention.py`

### R

- **Reduce**: Identifier found in `flex_attention.py`
- **Registers**: Identifier found in `flex_attention.py`
- **Returns**: Identifier found in `flex_attention.py`
- **Rework**: Identifier found in `flex_attention.py`
- **RuntimeError**: Identifier found in `flex_attention.py`
- **raise**: Identifier found in `flex_attention.py`
- **range**: Identifier found in `flex_attention.py`
- **redirect_to_mode**: Identifier found in `flex_attention.py`
- **redispatch_to_next**: Identifier found in `flex_attention.py`
- **redispatching**: Identifier found in `flex_attention.py`
- **reenter_make_fx**: Identifier found in `flex_attention.py`
- **register_fake**: Identifier found in `flex_attention.py`
- **register_module**: Identifier found in `flex_attention.py`
- **repeat**: Identifier found in `flex_attention.py`
- **repeat_interleave**: Identifier found in `flex_attention.py`
- **replay**: Identifier found in `flex_attention.py`
- **require**: Identifier found in `flex_attention.py`
- **requires**: Identifier found in `flex_attention.py`
- **requires_grad**: Identifier found in `flex_attention.py`
- **respect**: Identifier found in `flex_attention.py`
- **return**: Identifier found in `flex_attention.py`
- **root**: Identifier found in `flex_attention.py`
- **rows**: Identifier found in `flex_attention.py`
- **rules**: Identifier found in `flex_attention.py`
- **runs**: Identifier found in `flex_attention.py`

### S

- **SAC**: Identifier found in `flex_attention.py`
- **SDPA**: Identifier found in `flex_attention.py`
- **Sequence**: Identifier found in `flex_attention.py`
- **Start**: Identifier found in `flex_attention.py`
- **SymInt**: Identifier found in `flex_attention.py`
- **same**: Identifier found in `flex_attention.py`
- **save_tensors_and_symints_for_backward**: Identifier found in `flex_attention.py`
- **saved_tensors_and_symints**: Identifier found in `flex_attention.py`
- **scale**: Identifier found in `flex_attention.py`
- **score**: Identifier found in `flex_attention.py`
- **score_graph**: Identifier found in `flex_attention.py`
- **score_mod**: Identifier found in `flex_attention.py`
- **score_mod_other_buffer_grads**: Identifier found in `flex_attention.py`
- **score_mod_other_buffers**: Identifier found in `flex_attention.py`
- **score_mod_other_buffers_unwrapped**: Identifier found in `flex_attention.py`
- **scores**: Identifier found in `flex_attention.py`
- **sdpa_dense**: Identifier found in `flex_attention.py`
- **sdpa_dense_backward**: Identifier found in `flex_attention.py`
- **sdpa_mask**: Identifier found in `flex_attention.py`
- **sdpa_score**: Identifier found in `flex_attention.py`
- **self**: Identifier found in `flex_attention.py`
- **seq_len_kv**: Identifier found in `flex_attention.py`
- **seq_len_q**: Identifier found in `flex_attention.py`
- **set_original_aten_op**: Identifier found in `flex_attention.py`
- **shape**: Identifier found in `flex_attention.py`
- **should**: Identifier found in `flex_attention.py`
- **since**: Identifier found in `flex_attention.py`
- **size**: Identifier found in `flex_attention.py`
- **sizes**: Identifier found in `flex_attention.py`
- **skip**: Identifier found in `flex_attention.py`
- **softmax_scores**: Identifier found in `flex_attention.py`
- **someone**: Identifier found in `flex_attention.py`
- **space**: Identifier found in `flex_attention.py`
- **staticmethod**: Identifier found in `flex_attention.py`
- **storage_offset**: Identifier found in `flex_attention.py`
- **stored**: Identifier found in `flex_attention.py`
- **straight**: Identifier found in `flex_attention.py`
- **stride**: Identifier found in `flex_attention.py`
- **strided**: Identifier found in `flex_attention.py`
- **strides**: Identifier found in `flex_attention.py`
- **suffix**: Identifier found in `flex_attention.py`
- **sum_scores**: Identifier found in `flex_attention.py`
- **sumexp**: Identifier found in `flex_attention.py`
- **super**: Identifier found in `flex_attention.py`
- **support**: Identifier found in `flex_attention.py`
- **supported**: Identifier found in `flex_attention.py`
- **suspend_functionalization**: Identifier found in `flex_attention.py`

### T

- **TODO**: Identifier found in `flex_attention.py`
- **Tensor**: Identifier found in `flex_attention.py`
- **Then**: Identifier found in `flex_attention.py`
- **There**: Identifier found in `flex_attention.py`
- **This**: Identifier found in `flex_attention.py`
- **Trace**: Identifier found in `flex_attention.py`
- **Tracer**: Identifier found in `flex_attention.py`
- **Traces**: Identifier found in `flex_attention.py`
- **TransformGetItemToIndex**: Identifier found in `flex_attention.py`
- **True**: Identifier found in `flex_attention.py`
- **template**: Identifier found in `flex_attention.py`
- **tensor**: Identifier found in `flex_attention.py`
- **tensors**: Identifier found in `flex_attention.py`
- **that**: Identifier found in `flex_attention.py`
- **them**: Identifier found in `flex_attention.py`
- **then**: Identifier found in `flex_attention.py`
- **these**: Identifier found in `flex_attention.py`
- **this**: Identifier found in `flex_attention.py`
- **those**: Identifier found in `flex_attention.py`
- **through**: Identifier found in `flex_attention.py`
- **times**: Identifier found in `flex_attention.py`
- **torch**: Identifier found in `flex_attention.py`

### U

- **Union**: Identifier found in `flex_attention.py`
- **UnsupportedAliasMutationException**: Identifier found in `flex_attention.py`

### W

- **Write**: Identifier found in `flex_attention.py`

### _

- **__call__**: Identifier found in `flex_attention.py`
- **__init__**: Identifier found in `flex_attention.py`
- **_construct_strides**: Identifier found in `flex_attention.py`
- **_from_fun**: Identifier found in `flex_attention.py`
- **_fw_graph**: Identifier found in `flex_attention.py`
- **_joint_graph**: Identifier found in `flex_attention.py`
- **_mask_graph**: Identifier found in `flex_attention.py`
- **_math_attention_inner**: Identifier found in `flex_attention.py`
- **_maybe_new_buffer**: Identifier found in `flex_attention.py`
- **_permute_strides**: Identifier found in `flex_attention.py`
- **_q_head_dim**: Identifier found in `flex_attention.py`
- **_score_mod_other_buffers_len**: Identifier found in `flex_attention.py`

