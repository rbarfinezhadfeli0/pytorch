# Subtree Keyword Index: `torch/nn/attention/`

## Scope

This index covers all files within `torch/nn/attention/` and all its subdirectories (recursively).

## Keywords


### __init__

- [`torch/nn/attention/__init__.py`](./__init__.py_docs.md)
- [`torch/nn/attention/experimental/__init__.py`](../../../torch/nn/attention/experimental/__init__.py_docs.md)

### _fa4

- [`torch/nn/attention/_fa4.py`](./_fa4.py_docs.md)

### _paged_attention

- [`torch/nn/attention/experimental/_paged_attention.py`](../../../torch/nn/attention/experimental/_paged_attention.py_docs.md)

### _registry

- [`torch/nn/attention/_registry.py`](./_registry.py_docs.md)

### _utils

- [`torch/nn/attention/_utils.py`](./_utils.py_docs.md)

### bias

- [`torch/nn/attention/bias.py`](./bias.py_docs.md)

### files-.py

- [`torch/nn/attention/__init__.py`](./__init__.py_docs.md)
- [`torch/nn/attention/_registry.py`](./_registry.py_docs.md)
- [`torch/nn/attention/_fa4.py`](./_fa4.py_docs.md)
- [`torch/nn/attention/_utils.py`](./_utils.py_docs.md)
- [`torch/nn/attention/bias.py`](./bias.py_docs.md)
- [`torch/nn/attention/flex_attention.py`](./flex_attention.py_docs.md)
- [`torch/nn/attention/varlen.py`](./varlen.py_docs.md)
- [`torch/nn/attention/experimental/__init__.py`](../../../torch/nn/attention/experimental/__init__.py_docs.md)
- [`torch/nn/attention/experimental/_paged_attention.py`](../../../torch/nn/attention/experimental/_paged_attention.py_docs.md)

### flex_attention

- [`torch/nn/attention/flex_attention.py`](./flex_attention.py_docs.md)

### varlen

- [`torch/nn/attention/varlen.py`](./varlen.py_docs.md)


---

*Generated by PyTorch Repository Documentation System*
