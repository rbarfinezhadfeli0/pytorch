# Keywords: evaluate_model_metrics.py

## Keyword Index

### A

- **Args**: Identifier found in `evaluate_model_metrics.py`
- **ArgumentParser**: Identifier found in `evaluate_model_metrics.py`
- **accuracy**: Identifier found in `evaluate_model_metrics.py`
- **accuracy_score**: Identifier found in `evaluate_model_metrics.py`
- **add_argument**: Identifier found in `evaluate_model_metrics.py`
- **all_metrics**: Identifier found in `evaluate_model_metrics.py`
- **allow**: Identifier found in `evaluate_model_metrics.py`
- **append**: Identifier found in `evaluate_model_metrics.py`
- **argparse**: Identifier found in `evaluate_model_metrics.py`
- **args**: Identifier found in `evaluate_model_metrics.py`
- **array**: Identifier found in `evaluate_model_metrics.py`
- **average_precision_score**: Identifier found in `evaluate_model_metrics.py`
- **axis**: Identifier found in `evaluate_model_metrics.py`

### B

- **block**: Identifier found in `evaluate_model_metrics.py`
- **break**: Identifier found in `evaluate_model_metrics.py`

### C

- **concatenate**: Identifier found in `evaluate_model_metrics.py`
- **contains**: Identifier found in `evaluate_model_metrics.py`
- **cuda**: Identifier found in `evaluate_model_metrics.py`

### D

- **DataFrame**: Identifier found in `evaluate_model_metrics.py`
- **data**: Identifier found in `evaluate_model_metrics.py`
- **dataloader**: Identifier found in `evaluate_model_metrics.py`
- **dataset**: Identifier found in `evaluate_model_metrics.py`
- **defs**: Identifier found in `evaluate_model_metrics.py`
- **detach**: Identifier found in `evaluate_model_metrics.py`
- **device**: Identifier found in `evaluate_model_metrics.py`
- **dict**: Identifier found in `evaluate_model_metrics.py`
- **dictionary**: Identifier found in `evaluate_model_metrics.py`
- **dlrm**: Identifier found in `evaluate_model_metrics.py`
- **dlrm_s_pytorch**: Identifier found in `evaluate_model_metrics.py`
- **dlrm_utils**: Identifier found in `evaluate_model_metrics.py`
- **dlrm_wrap**: Identifier found in `evaluate_model_metrics.py`
- **dumps**: Identifier found in `evaluate_model_metrics.py`

### E

- **Evaluate**: Identifier found in `evaluate_model_metrics.py`
- **Evaluates**: Identifier found in `evaluate_model_metrics.py`
- **early**: Identifier found in `evaluate_model_metrics.py`
- **else**: Identifier found in `evaluate_model_metrics.py`
- **enumerate**: Identifier found in `evaluate_model_metrics.py`
- **evaluate_metrics**: Identifier found in `evaluate_model_metrics.py`
- **evaluates**: Identifier found in `evaluate_model_metrics.py`
- **evaluation**: Identifier found in `evaluate_model_metrics.py`
- **exceeded**: Identifier found in `evaluate_model_metrics.py`
- **exit**: Identifier found in `evaluate_model_metrics.py`

### F

- **False**: Identifier found in `evaluate_model_metrics.py`
- **Fetch**: Identifier found in `evaluate_model_metrics.py`
- **f1_score**: Identifier found in `evaluate_model_metrics.py`
- **fetch_model**: Identifier found in `evaluate_model_metrics.py`
- **file**: Identifier found in `evaluate_model_metrics.py`
- **filename**: Identifier found in `evaluate_model_metrics.py`
- **forward**: Identifier found in `evaluate_model_metrics.py`
- **from**: Identifier found in `evaluate_model_metrics.py`
- **function**: Identifier found in `evaluate_model_metrics.py`

### H

- **happens**: Identifier found in `evaluate_model_metrics.py`

### I

- **ignore**: Identifier found in `evaluate_model_metrics.py`
- **import**: Identifier found in `evaluate_model_metrics.py`
- **index**: Identifier found in `evaluate_model_metrics.py`
- **inference**: Identifier found in `evaluate_model_metrics.py`
- **inference_and_evaluation**: Identifier found in `evaluate_model_metrics.py`
- **is_available**: Identifier found in `evaluate_model_metrics.py`
- **items**: Identifier found in `evaluate_model_metrics.py`
- **iterrows**: Identifier found in `evaluate_model_metrics.py`

### K

- **key**: Identifier found in `evaluate_model_metrics.py`

### L

- **lS_i_test**: Identifier found in `evaluate_model_metrics.py`
- **lS_o_test**: Identifier found in `evaluate_model_metrics.py`
- **lambda**: Identifier found in `evaluate_model_metrics.py`
- **levels**: Identifier found in `evaluate_model_metrics.py`
- **list**: Identifier found in `evaluate_model_metrics.py`
- **loader**: Identifier found in `evaluate_model_metrics.py`
- **log_loss**: Identifier found in `evaluate_model_metrics.py`

### M

- **Model**: Identifier found in `evaluate_model_metrics.py`
- **Module**: Identifier found in `evaluate_model_metrics.py`
- **make_test_data_loader**: Identifier found in `evaluate_model_metrics.py`
- **metadata**: Identifier found in `evaluate_model_metrics.py`
- **metric_function**: Identifier found in `evaluate_model_metrics.py`
- **metric_name**: Identifier found in `evaluate_model_metrics.py`
- **metrics**: Identifier found in `evaluate_model_metrics.py`
- **metrics_dict**: Identifier found in `evaluate_model_metrics.py`
- **model**: Identifier found in `evaluate_model_metrics.py`
- **model_metrics**: Identifier found in `evaluate_model_metrics.py`
- **model_path**: Identifier found in `evaluate_model_metrics.py`
- **model_performance**: Identifier found in `evaluate_model_metrics.py`
- **mypy**: Identifier found in `evaluate_model_metrics.py`

### N

- **Note**: Identifier found in `evaluate_model_metrics.py`
- **nbatches**: Identifier found in `evaluate_model_metrics.py`
- **ndevices**: Identifier found in `evaluate_model_metrics.py`
- **norm**: Identifier found in `evaluate_model_metrics.py`
- **norms**: Identifier found in `evaluate_model_metrics.py`
- **numpy**: Identifier found in `evaluate_model_metrics.py`

### O

- **object**: Identifier found in `evaluate_model_metrics.py`

### P

- **Perform**: Identifier found in `evaluate_model_metrics.py`
- **pandas**: Identifier found in `evaluate_model_metrics.py`
- **parse_args**: Identifier found in `evaluate_model_metrics.py`
- **parser**: Identifier found in `evaluate_model_metrics.py`
- **pass**: Identifier found in `evaluate_model_metrics.py`
- **path**: Identifier found in `evaluate_model_metrics.py`
- **precision**: Identifier found in `evaluate_model_metrics.py`
- **precision_score**: Identifier found in `evaluate_model_metrics.py`
- **present**: Identifier found in `evaluate_model_metrics.py`
- **print**: Identifier found in `evaluate_model_metrics.py`
- **processed**: Identifier found in `evaluate_model_metrics.py`
- **processed_data_file**: Identifier found in `evaluate_model_metrics.py`

### R

- **raw_data_file**: Identifier found in `evaluate_model_metrics.py`
- **read_csv**: Identifier found in `evaluate_model_metrics.py`
- **recall**: Identifier found in `evaluate_model_metrics.py`
- **recall_score**: Identifier found in `evaluate_model_metrics.py`
- **return**: Identifier found in `evaluate_model_metrics.py`
- **returns**: Identifier found in `evaluate_model_metrics.py`
- **rewritten**: Identifier found in `evaluate_model_metrics.py`
- **roc_auc**: Identifier found in `evaluate_model_metrics.py`
- **roc_auc_score**: Identifier found in `evaluate_model_metrics.py`
- **round**: Identifier found in `evaluate_model_metrics.py`

### S

- **S_test**: Identifier found in `evaluate_model_metrics.py`
- **saved**: Identifier found in `evaluate_model_metrics.py`
- **scores**: Identifier found in `evaluate_model_metrics.py`
- **shapes**: Identifier found in `evaluate_model_metrics.py`
- **sklearn**: Identifier found in `evaluate_model_metrics.py`
- **sl**: Identifier found in `evaluate_model_metrics.py`
- **sparse**: Identifier found in `evaluate_model_metrics.py`
- **sparse_block_shape**: Identifier found in `evaluate_model_metrics.py`
- **sparse_model_metadata**: Identifier found in `evaluate_model_metrics.py`
- **sparse_model_metrics**: Identifier found in `evaluate_model_metrics.py`
- **sparsified**: Identifier found in `evaluate_model_metrics.py`
- **sparsity**: Identifier found in `evaluate_model_metrics.py`
- **sparsity_level**: Identifier found in `evaluate_model_metrics.py`
- **such**: Identifier found in `evaluate_model_metrics.py`

### T

- **T_test**: Identifier found in `evaluate_model_metrics.py`
- **This**: Identifier found in `evaluate_model_metrics.py`
- **targets**: Identifier found in `evaluate_model_metrics.py`
- **test**: Identifier found in `evaluate_model_metrics.py`
- **testBatch**: Identifier found in `evaluate_model_metrics.py`
- **test_data_loader**: Identifier found in `evaluate_model_metrics.py`
- **test_dataloader**: Identifier found in `evaluate_model_metrics.py`
- **that**: Identifier found in `evaluate_model_metrics.py`
- **to_csv**: Identifier found in `evaluate_model_metrics.py`
- **torch**: Identifier found in `evaluate_model_metrics.py`
- **type**: Identifier found in `evaluate_model_metrics.py`

### U

- **unpack_batch**: Identifier found in `evaluate_model_metrics.py`
- **untyped**: Identifier found in `evaluate_model_metrics.py`
- **user**: Identifier found in `evaluate_model_metrics.py`

### V

- **value**: Identifier found in `evaluate_model_metrics.py`
- **various**: Identifier found in `evaluate_model_metrics.py`
- **version**: Identifier found in `evaluate_model_metrics.py`

### W

- **which**: Identifier found in `evaluate_model_metrics.py`

### X

- **X_test**: Identifier found in `evaluate_model_metrics.py`

### Y

- **y_pred**: Identifier found in `evaluate_model_metrics.py`
- **y_score**: Identifier found in `evaluate_model_metrics.py`
- **y_true**: Identifier found in `evaluate_model_metrics.py`

### Z

- **Z_test**: Identifier found in `evaluate_model_metrics.py`

### _

- **_**: Identifier found in `evaluate_model_metrics.py`
- **__name__**: Identifier found in `evaluate_model_metrics.py`

